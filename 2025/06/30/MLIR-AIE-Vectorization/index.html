<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="article">
<meta property="og:title" content="MLIR-AIE Vectorization">
<meta property="og:url" content="http://example.com/2025/06/30/MLIR-AIE-Vectorization/index.html">
<meta property="og:site_name" content="Leon&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/image-20250616093524804.png">
<meta property="article:published_time" content="2025-06-30T11:43:05.000Z">
<meta property="article:modified_time" content="2025-07-01T09:05:36.970Z">
<meta property="article:author" content="Leon Dou">
<meta property="article:tag" content="mlir">
<meta property="article:tag" content="basics">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/image-20250616093524804.png">

<link rel="canonical" href="http://example.com/2025/06/30/MLIR-AIE-Vectorization/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>MLIR-AIE Vectorization | Leon's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Leon's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">分享一点有趣的技术</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/micropuma" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/06/30/MLIR-AIE-Vectorization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Leon Dou">
      <meta itemprop="description" content="关注领域：体系结构，编译技术">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leon's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          MLIR-AIE Vectorization
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-06-30 19:43:05" itemprop="dateCreated datePublished" datetime="2025-06-30T19:43:05+08:00">2025-06-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-07-01 17:05:36" itemprop="dateModified" datetime="2025-07-01T17:05:36+08:00">2025-07-01</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BC%96%E8%AF%91%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">编译技术</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BC%96%E8%AF%91%E6%8A%80%E6%9C%AF/mlir/" itemprop="url" rel="index"><span itemprop="name">mlir</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BC%96%E8%AF%91%E6%8A%80%E6%9C%AF/mlir/basics/" itemprop="url" rel="index"><span itemprop="name">basics</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>21k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>19 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><img src="/images/image-20250616093524804.png" alt="image-20250616093524804"></p>
<span id="more"></span>

<blockquote>
<p>这篇博客主要解读AMD的mlir-aie开源项目针对vectorization提出的编译优化方法实现。主要关注<code>aie-vectorize</code>这个优化pass。</p>
</blockquote>
<h2 id="Pass-Pipeline"><a href="#Pass-Pipeline" class="headerlink" title="Pass Pipeline"></a><font color = brown>Pass Pipeline</font></h2><h3 id="VectorState"><a href="#VectorState" class="headerlink" title="VectorState"></a><font color = green>VectorState</font></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A struct to pack the global state required for vectorization at one place.</span></span><br><span class="line"><span class="comment">// Local to this translation unit.</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">VectState</span> &#123;</span><br><span class="line">  <span class="comment">// A vector of all the reuse intervals created. Class IntervalReuse represents</span></span><br><span class="line">  <span class="comment">// the cluster of data access (with reuse potential) along the vectorized</span></span><br><span class="line">  <span class="comment">// dimension of each array, It clusters together reads that have a potential</span></span><br><span class="line">  <span class="comment">// of vector-level data reuse. Therefore, array accesses A[i][j:j+8] and</span></span><br><span class="line">  <span class="comment">// A[i+2][j:j+8] will map to different IntervalReuse objects.</span></span><br><span class="line">  SmallVector&lt;IntervalReuse *, <span class="number">16</span>&gt; reuseIntervals;</span><br><span class="line">  <span class="comment">// Map from a transfer_read operation to the IntervalReuse object it belongs</span></span><br><span class="line">  <span class="comment">// to.</span></span><br><span class="line">  mlir::DenseMap&lt;Operation *, IntervalReuse *&gt; opToIntervalMap;</span><br><span class="line">  <span class="comment">// Map from a transfer_read operation to its linearized access expression.</span></span><br><span class="line">  <span class="comment">// Linearized expression for access A[i][j], where A is of dimensionality MxN</span></span><br><span class="line">  <span class="comment">// is (i*N+j). We assume that the innermost dimension is the vectorized</span></span><br><span class="line">  <span class="comment">// dimension.</span></span><br><span class="line">  mlir::DenseMap&lt;Operation *, AffineExpr&gt; linearizedAccess;</span><br><span class="line">  <span class="comment">// A map from an index (of array access) to an expr dim map (e.g., i-&gt;d0). We</span></span><br><span class="line">  <span class="comment">// need this to create the correct linearized expressions for all the array</span></span><br><span class="line">  <span class="comment">// accesses in the function.</span></span><br><span class="line">  mlir::DenseMap&lt;Value, AffineExpr&gt; indexToExprDimMap;</span><br><span class="line">  <span class="comment">// For each transfer_read operation, a map from its container basic block to</span></span><br><span class="line">  <span class="comment">// the enclosing for/while loops. This helps us identify two instructions</span></span><br><span class="line">  <span class="comment">// that are nested together, even if they belong to different basic blocks.</span></span><br><span class="line">  mlir::DenseMap&lt;Block *, SmallVector&lt;Operation *, <span class="number">8</span>&gt;&gt; blockToEnclosingLoops;</span><br><span class="line">  <span class="comment">// This is specific to 8x8 scheme. For an 8x8 scheme, every mul/fma is</span></span><br><span class="line">  <span class="comment">// replaced by two mul/fmas in AIE dialect. So we keep track of the pair.</span></span><br><span class="line">  mlir::DenseMap&lt;Operation *, Operation *&gt; pairedOp;</span><br><span class="line">  <span class="comment">// If we fuse a representative mul/fma op with another fma op to exploit the</span></span><br><span class="line">  <span class="comment">// column topology of the AIE intrinsic, then cache, for the representative</span></span><br><span class="line">  <span class="comment">// op, the compile-time constant access distance between their two operands.</span></span><br><span class="line">  <span class="comment">// The first(second) offset of the pair represents the access distance</span></span><br><span class="line">  <span class="comment">// between the first(second) operands of the representative op and the the</span></span><br><span class="line">  <span class="comment">// fused op(s). This access distance will be used to compute the xstep/zstep</span></span><br><span class="line">  <span class="comment">// attribute.</span></span><br><span class="line">  mlir::DenseMap&lt;Operation *, std::pair&lt;<span class="type">int32_t</span>, <span class="type">int32_t</span>&gt;&gt; opToColOffsets;</span><br><span class="line">  <span class="comment">// Map from the sext op to the def op of the sext operand.</span></span><br><span class="line">  mlir::DenseMap&lt;Operation *, Operation *&gt; sextTruncDefMap;</span><br><span class="line">  <span class="comment">// A set of operations that are msc (fmsub) ops. We do not differentiate</span></span><br><span class="line">  <span class="comment">// between mac and msc ops at vector dialect level. The only op in vector</span></span><br><span class="line">  <span class="comment">// dialect is just FMA op.</span></span><br><span class="line">  llvm::SmallSet&lt;Operation *, <span class="number">8</span>&gt; mscOps;</span><br><span class="line">  <span class="comment">// Used to build and insert all the new operations created.</span></span><br><span class="line">  OpBuilder builder;</span><br><span class="line">  <span class="comment">// The shift val for ups and srs intinsics. This value should be between 0</span></span><br><span class="line">  <span class="comment">// and 63.</span></span><br><span class="line">  <span class="type">int8_t</span> shift;</span><br><span class="line">  <span class="comment">// The zero offset, indicating the position of recurring 0 in the input</span></span><br><span class="line">  <span class="comment">// filter. The counting starts at 1. For example, if the filter array is</span></span><br><span class="line">  <span class="comment">// &#123;1,2,3,0,4,5,6,0,7,8,9,0&#125;, then zeroOffset=4.</span></span><br><span class="line">  <span class="type">int32_t</span> zeroOffset;</span><br><span class="line">  <span class="comment">// The duplicate count, indicating the number of times a value is duplicated</span></span><br><span class="line">  <span class="comment">// in the filter. The filter values must be duplicated at least twice for the</span></span><br><span class="line">  <span class="comment">// i8xi8 scheme. An example of filter for i8xi8 scheme is &#123;0,0,1,1,2,2,3,3&#125;,</span></span><br><span class="line">  <span class="comment">// with dupFactor=2.</span></span><br><span class="line">  <span class="type">int32_t</span> dupFactor;</span><br><span class="line"></span><br><span class="line">  <span class="type">bool</span> unalignedLoadsCheck, aieml;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Constructors</span></span><br><span class="line">  <span class="built_in">VectState</span>(MLIRContext *context, <span class="type">int8_t</span> s, <span class="type">int32_t</span> z, <span class="type">int32_t</span> d,</span><br><span class="line">            <span class="type">bool</span> unalignedLoadsCheck, <span class="type">bool</span> aieml)</span><br><span class="line">      : <span class="built_in">builder</span>(context), <span class="built_in">shift</span>(s), <span class="built_in">zeroOffset</span>(z), <span class="built_in">dupFactor</span>(d),</span><br><span class="line">        <span class="built_in">unalignedLoadsCheck</span>(unalignedLoadsCheck), <span class="built_in">aieml</span>(aieml) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">IntervalReuse *<span class="title">getIntervalForOperation</span><span class="params">(Operation *op)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="Interval-Reuse"><a href="#Interval-Reuse" class="headerlink" title="Interval Reuse"></a><font color = green>Interval Reuse</font></h3><p>整个向量化的一大重点是向量寄存器复用合并。这部分在源码中主要数据结构在<code>IntervalReuse.cpp</code>和<code>IntervalReuse.h</code>两个文件中。这一小节重点分析间断重用分析算法的具体实现。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//===- IntervalReuse.h - AIE Vector Data Reuse Computation ------*- C++ -*-===//</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// This file is licensed under the Apache License v2.0 with LLVM Exceptions.</span></span><br><span class="line"><span class="comment">// See https://llvm.org/LICENSE.txt for license information.</span></span><br><span class="line"><span class="comment">// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// (c) Copyright 2022 Xilinx Inc.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//===----------------------------------------------------------------------===//</span></span><br><span class="line"><span class="comment">// Class to compute potential data reuse in AIE vectors</span></span><br><span class="line"><span class="comment">//===----------------------------------------------------------------------===//</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> AIE_DIALECT_AIEVEC_TRANSFORMS_INTERVALREUSE_H</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> AIE_DIALECT_AIEVEC_TRANSFORMS_INTERVALREUSE_H</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;aie/Dialect/AIEVec/AIEVecUtils.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;utility&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> xilinx::aievec &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这个class是AMD提供的一个很重要的优化点，重用interval。这个优化点在vyasa中提出。</span></span><br><span class="line"><span class="comment">// The IntervalReuse class.</span></span><br><span class="line"><span class="comment">// This class captures the potential data reuse in the AIE vector. Each load</span></span><br><span class="line"><span class="comment">// from memory (coming from transfer_read op) will exclusively belong to one of</span></span><br><span class="line"><span class="comment">// the IntervalReuse object. Note that in AIE, the minimum vector size is</span></span><br><span class="line"><span class="comment">// 128-bit, and they are aligned to the vector size boundary.</span></span><br><span class="line"><span class="comment">// Let A and B be NxN arrays of 32-bit values. We assume no aliasing. Consider</span></span><br><span class="line"><span class="comment">// the following three cases, where we want to determine which IntervalReuse</span></span><br><span class="line"><span class="comment">// object the two read op accesses within the same loop nest will be mapped to:</span></span><br><span class="line"><span class="comment">// 1. Accesses A[i][j:j+8] and A[i][j+1:j+9]: they exhibit data reuse if we load</span></span><br><span class="line"><span class="comment">// the range  A[j:j+16] from memory into a 512-bit vector. Therefore, these two</span></span><br><span class="line"><span class="comment">// read ops will belong to the same IntervalReuse object.</span></span><br><span class="line"><span class="comment">// 2. Accesses A[i][j:j+8] and A[i+1][j:j+8]: there is no non-trivial</span></span><br><span class="line"><span class="comment">// vector-level reuse possible for these accesses, and they must belong to</span></span><br><span class="line"><span class="comment">// different IntervalReuse objects.</span></span><br><span class="line"><span class="comment">// 3. Accesses A[i][j:j+8] and B[i][j:j+8]: there is no possible reuse, since</span></span><br><span class="line"><span class="comment">// the read ops access different arrays. Therefore, these two read ops must</span></span><br><span class="line"><span class="comment">// belong to different IntervalReuse objects.</span></span><br><span class="line"><span class="comment">// We want to correctly map read ops to IntervalReuse object in all these three</span></span><br><span class="line"><span class="comment">// cases.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 理解Interval分析中的base以及memref的含义</span></span><br><span class="line"><span class="comment">// 只有同样的memref和base的访问才有可能重用数据。memref是指向数组的指针，base是指向数组元素的偏移量。</span></span><br><span class="line"><span class="comment">// The class contains &#x27;memref&#x27; and &#x27;base&#x27; to disambiguate reuse. &#x27;memref&#x27;</span></span><br><span class="line"><span class="comment">// differentiates different arrays. For example, &#x27;memref&#x27; for arrays A and B</span></span><br><span class="line"><span class="comment">// will be different. For accesses coming from the same array, &#x27;base&#x27; helps in</span></span><br><span class="line"><span class="comment">// disambiguation. &#x27;base&#x27; is just the linearized base expression of the access.</span></span><br><span class="line"><span class="comment">// The linearized expression for A[i][j] is i*N+j. We decompose it into base</span></span><br><span class="line"><span class="comment">// (i*N+j), and offset 0. In contrast, the linearized expression for</span></span><br><span class="line"><span class="comment">// A[i+1][j+2] is (i+1)*N+j+2, and we decompose it into base (i+1)*N+j, and</span></span><br><span class="line"><span class="comment">// offset 2. Basically, we abstract away the constant offset from the</span></span><br><span class="line"><span class="comment">// linearized access expression to form the base.</span></span><br><span class="line"><span class="comment">// Given a vector of IntervalReuse objects, we just search for an object with</span></span><br><span class="line"><span class="comment">// matching &#x27;memref&#x27; and &#x27;base&#x27; to group the read ops that can potentially</span></span><br><span class="line"><span class="comment">// reuse data in vector.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 记录读取了多大数据范围</span></span><br><span class="line"><span class="comment">// &#x27;extentMap&#x27; stores the extent of data that an op reads. We store the extent</span></span><br><span class="line"><span class="comment">// in bits. For example, the extent for operation reading A[i][j:j+8] is</span></span><br><span class="line"><span class="comment">// [0,256].</span></span><br><span class="line"><span class="comment">// load会强制aligned到512位边界</span></span><br><span class="line"><span class="comment">// The &#x27;read access extent&#x27; corresponds to the aligned chunk of data that an</span></span><br><span class="line"><span class="comment">// operation loads. For example, an 8-lane, 32-bit vector load from A[i+7:i+15]</span></span><br><span class="line"><span class="comment">// would have read access extent [0:512], whereas under same conditions, the</span></span><br><span class="line"><span class="comment">// vector load from A[i+9:i+17] would have read access extent [512:768]. Note</span></span><br><span class="line"><span class="comment">// how the extents are aligned to vector size boundary.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// &#x27;intervals&#x27; merges overlapping intervals to give the view of actual AIE</span></span><br><span class="line"><span class="comment">// vectors that need to be created. Since AIE only allows aligned vector loads,</span></span><br><span class="line"><span class="comment">// each interval is aligned to vector size. Continuing with the previous</span></span><br><span class="line"><span class="comment">// example, the two extents [0,256] and [128,512] overlap. Therefore these will</span></span><br><span class="line"><span class="comment">// be merged together to form a single interval [0,512]. The entries into</span></span><br><span class="line"><span class="comment">// &#x27;intervals&#x27; are sorted, so given an op, we can find its interval by doing</span></span><br><span class="line"><span class="comment">// binary search with the op&#x27;s extent as key (e.g, searching for [128,256] in</span></span><br><span class="line"><span class="comment">// &#123;[0,512],[512,1024]&#125;).</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IntervalReuse</span> &#123;</span><br><span class="line">  <span class="comment">// differentiate arrays (e.g., A vs. B)</span></span><br><span class="line">  <span class="comment">// memref用来区别A和B两个数组</span></span><br><span class="line">  mlir::Value memref;</span><br><span class="line">  <span class="comment">// differentiate accesses coming from the same array, but with different base</span></span><br><span class="line">  <span class="comment">// expression along the non-vectorized dimension (e.g., A[i+1][j:j+8] vs.</span></span><br><span class="line">  <span class="comment">// A[i][j:j+8];</span></span><br><span class="line">  <span class="comment">// 同一数组的不同访问，base是线性化的表达式</span></span><br><span class="line">  mlir::AffineExpr base;</span><br><span class="line">  <span class="comment">// A map from each read operation to the extent of bits it reads (aligned to</span></span><br><span class="line">  <span class="comment">// vector size).</span></span><br><span class="line">  <span class="comment">// 读操作的extent是以位为单位的，aligned到vector size边界（512bits）</span></span><br><span class="line">  llvm::DenseMap&lt;mlir::Operation *, std::pair&lt;<span class="type">int32_t</span>, <span class="type">int32_t</span>&gt;&gt; extentMap;</span><br><span class="line">  <span class="comment">// 无overlap的intervals列表</span></span><br><span class="line">  <span class="comment">// Disjoint intervals of all the data accesses (i.e., read bits). Each</span></span><br><span class="line">  <span class="comment">// interval entry corresponds to memory load into an AIE vec.</span></span><br><span class="line">  llvm::SmallVector&lt;std::pair&lt;<span class="type">int32_t</span>, <span class="type">int32_t</span>&gt;, <span class="number">8</span>&gt; intervals;</span><br><span class="line">  <span class="comment">// lmul为例，LHS是RHS的两倍</span></span><br><span class="line">  <span class="comment">// Identify all the vectors that are only used as LHS operands of mul/mac op.</span></span><br><span class="line">  <span class="comment">// The LHS operand of mul/mac ops have specific size requirement.</span></span><br><span class="line">  llvm::SmallVector&lt;<span class="type">bool</span>, <span class="number">8</span>&gt; vecIsLHSOperand;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Return true if this array access comes from the same array</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">sameMemRef</span><span class="params">(mlir::Value m)</span> </span>&#123; <span class="keyword">return</span> memref == m; &#125;</span><br><span class="line">  <span class="comment">// Return true if this array access has the same invariant base</span></span><br><span class="line">  <span class="comment">// expression.</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">sameInvariantIndices</span><span class="params">(mlir::AffineExpr b)</span> </span>&#123; <span class="keyword">return</span> base == b; &#125;</span><br><span class="line">  <span class="comment">// 目前只有同一loop下的operation才会去做overlap分析。</span></span><br><span class="line">  <span class="comment">// Return true if this array access is enclosed within the same loop nest as</span></span><br><span class="line">  <span class="comment">// other accesses belonging to the same IntervalReuse object.</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">sameEnclosingLoops</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      mlir::Operation *op,</span></span></span><br><span class="line"><span class="params"><span class="function">      llvm::DenseMap&lt;mlir::Block *, llvm::SmallVector&lt;mlir::Operation *, <span class="number">8</span>&gt;&gt;</span></span></span><br><span class="line"><span class="params"><span class="function">          &amp;blockToEnclosingLoops)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 显示维护intervals，operation通过索引的方式找寻到对应的interval</span></span><br><span class="line">  <span class="comment">// For an operation, get the index into intervals that subsumes the</span></span><br><span class="line">  <span class="comment">// operation&#x27;s access extent.</span></span><br><span class="line">  <span class="function"><span class="type">size_t</span> <span class="title">getIntervalIndex</span><span class="params">(mlir::Operation *op)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// Return true if this read operation has a potential data reuse with other</span></span><br><span class="line">  <span class="comment">// read operations in this IntervalReuse.</span></span><br><span class="line">  <span class="comment">// 判断该operation在当前同一loop下是否有可重用寄存器</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">potentialReuse</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      mlir::vector::TransferReadOp readOp, mlir::AffineExpr invariantBase,</span></span></span><br><span class="line"><span class="params"><span class="function">      llvm::DenseMap&lt;mlir::Block *, llvm::SmallVector&lt;mlir::Operation *, <span class="number">8</span>&gt;&gt;</span></span></span><br><span class="line"><span class="params"><span class="function">          &amp;blockToEnclosingLoops)</span></span>;</span><br><span class="line">  <span class="comment">// Insert the access extent of this read operation into intervals</span></span><br><span class="line">  <span class="comment">// 必须对齐到AIE向量最小size：128bits</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">insertInterval</span><span class="params">(mlir::vector::TransferReadOp readOp,</span></span></span><br><span class="line"><span class="params"><span class="function">                      llvm::DenseMap&lt;mlir::Operation *, IntervalReuse *&gt;</span></span></span><br><span class="line"><span class="params"><span class="function">                          &amp;dataAccessToIntervalMap,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">int32_t</span> offset, <span class="type">int32_t</span> forLoopStepSize,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">bool</span> isSplat = <span class="literal">false</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">unsigned</span> minVecSize = <span class="number">128</span> <span class="comment">/*min AIE vec size*/</span>)</span></span>;</span><br><span class="line">  <span class="comment">// 获取一个operation的访问范围，应该要做对齐</span></span><br><span class="line">  <span class="comment">// For a read operation, return the width of the interval its access extent</span></span><br><span class="line">  <span class="comment">// belongs to. The interval width corresponds to the size of the vector that</span></span><br><span class="line">  <span class="comment">// will hold the load from read operation.</span></span><br><span class="line">  <span class="function"><span class="type">int32_t</span> <span class="title">getIntervalWidth</span><span class="params">(mlir::Operation *op)</span></span>;</span><br><span class="line">  <span class="comment">// Get the read access extent of this read operation. The returned value</span></span><br><span class="line">  <span class="comment">// indicates the start and end offsets of the access from the base (in bits).</span></span><br><span class="line">  <span class="function">std::pair&lt;<span class="type">int32_t</span>, <span class="type">int32_t</span>&gt; <span class="title">getAccessExtent</span><span class="params">(mlir::Operation *op)</span></span>;</span><br><span class="line">  <span class="comment">// Set the read access extent of this read operation.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">setAccessExtent</span><span class="params">(mlir::Operation *op,</span></span></span><br><span class="line"><span class="params"><span class="function">                       std::pair&lt;<span class="type">int32_t</span>, <span class="type">int32_t</span>&gt; &amp;extent)</span></span>;</span><br><span class="line">  <span class="comment">// Get the interval that contains this read operation&#x27;s extent</span></span><br><span class="line">  <span class="function">std::pair&lt;<span class="type">int32_t</span>, <span class="type">int32_t</span>&gt; <span class="title">getInterval</span><span class="params">(mlir::Operation *op)</span></span>;</span><br><span class="line">  <span class="comment">// Given that the read operation &#x27;op&#x27; is only LHS operand of some mul/mac</span></span><br><span class="line">  <span class="comment">// op, mark the vector that will load its access extent.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">markLHSOperandVec</span><span class="params">(mlir::Operation *op)</span></span>;</span><br><span class="line">  <span class="comment">// If the interval corresponds to a vector that is marked as the exclusive</span></span><br><span class="line">  <span class="comment">// LHS operand of some mul/mac op, and if its size is &lt;= 256, try to coalesce</span></span><br><span class="line">  <span class="comment">// it with the next interval.</span></span><br><span class="line">  <span class="comment">// interval相临，并且mac/mul操作的LHS操作数是256位的向量时，尝试合并</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">coalesceIntervals</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="comment">// Constructors</span></span><br><span class="line">  <span class="built_in">IntervalReuse</span>(mlir::vector::TransferReadOp readOp, mlir::AffineExpr b)</span><br><span class="line">      : <span class="built_in">memref</span>(readOp.<span class="built_in">getSource</span>()), <span class="built_in">base</span>(b) &#123;&#125;</span><br><span class="line">  <span class="built_in">IntervalReuse</span>() : <span class="built_in">memref</span>(<span class="literal">nullptr</span>), <span class="built_in">base</span>(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125; <span class="comment">// namespace xilinx::aievec</span></span><br><span class="line"><span class="comment">// end namespace xilinx</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// AIE_DIALECT_AIEVEC_TRANSFORMS_INTERVALREUSE_H</span></span></span><br></pre></td></tr></table></figure>

<h3 id="VecState"><a href="#VecState" class="headerlink" title="VecState"></a><font color = green>VecState</font></h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">VectState</span> &#123;</span><br><span class="line">  <span class="comment">// A vector of all the reuse intervals created. Class IntervalReuse represents</span></span><br><span class="line">  <span class="comment">// the cluster of data access (with reuse potential) along the vectorized</span></span><br><span class="line">  <span class="comment">// dimension of each array, It clusters together reads that have a potential</span></span><br><span class="line">  <span class="comment">// of vector-level data reuse. Therefore, array accesses A[i][j:j+8] and</span></span><br><span class="line">  <span class="comment">// A[i+2][j:j+8] will map to different IntervalReuse objects.</span></span><br><span class="line">  SmallVector&lt;IntervalReuse *, <span class="number">16</span>&gt; reuseIntervals;</span><br><span class="line">  <span class="comment">// Map from a transfer_read operation to the IntervalReuse object it belongs</span></span><br><span class="line">  <span class="comment">// to.</span></span><br><span class="line">  mlir::DenseMap&lt;Operation *, IntervalReuse *&gt; opToIntervalMap;</span><br><span class="line">  <span class="comment">// Map from a transfer_read operation to its linearized access expression.</span></span><br><span class="line">  <span class="comment">// Linearized expression for access A[i][j], where A is of dimensionality MxN</span></span><br><span class="line">  <span class="comment">// is (i*N+j). We assume that the innermost dimension is the vectorized</span></span><br><span class="line">  <span class="comment">// dimension.</span></span><br><span class="line">  mlir::DenseMap&lt;Operation *, AffineExpr&gt; linearizedAccess;</span><br><span class="line">  <span class="comment">// A map from an index (of array access) to an expr dim map (e.g., i-&gt;d0). We</span></span><br><span class="line">  <span class="comment">// need this to create the correct linearized expressions for all the array</span></span><br><span class="line">  <span class="comment">// accesses in the function.</span></span><br><span class="line">  mlir::DenseMap&lt;Value, AffineExpr&gt; indexToExprDimMap;</span><br><span class="line">  <span class="comment">// For each transfer_read operation, a map from its container basic block to</span></span><br><span class="line">  <span class="comment">// the enclosing for/while loops. This helps us identify two instructions</span></span><br><span class="line">  <span class="comment">// that are nested together, even if they belong to different basic blocks.</span></span><br><span class="line">  mlir::DenseMap&lt;Block *, SmallVector&lt;Operation *, <span class="number">8</span>&gt;&gt; blockToEnclosingLoops;</span><br><span class="line">  <span class="comment">// This is specific to 8x8 scheme. For an 8x8 scheme, every mul/fma is</span></span><br><span class="line">  <span class="comment">// replaced by two mul/fmas in AIE dialect. So we keep track of the pair.</span></span><br><span class="line">  mlir::DenseMap&lt;Operation *, Operation *&gt; pairedOp;</span><br><span class="line">  <span class="comment">// If we fuse a representative mul/fma op with another fma op to exploit the</span></span><br><span class="line">  <span class="comment">// column topology of the AIE intrinsic, then cache, for the representative</span></span><br><span class="line">  <span class="comment">// op, the compile-time constant access distance between their two operands.</span></span><br><span class="line">  <span class="comment">// The first(second) offset of the pair represents the access distance</span></span><br><span class="line">  <span class="comment">// between the first(second) operands of the representative op and the the</span></span><br><span class="line">  <span class="comment">// fused op(s). This access distance will be used to compute the xstep/zstep</span></span><br><span class="line">  <span class="comment">// attribute.</span></span><br><span class="line">  mlir::DenseMap&lt;Operation *, std::pair&lt;<span class="type">int32_t</span>, <span class="type">int32_t</span>&gt;&gt; opToColOffsets;</span><br><span class="line">  <span class="comment">// Map from the sext op to the def op of the sext operand.</span></span><br><span class="line">  mlir::DenseMap&lt;Operation *, Operation *&gt; sextTruncDefMap;</span><br><span class="line">  <span class="comment">// A set of operations that are msc (fmsub) ops. We do not differentiate</span></span><br><span class="line">  <span class="comment">// between mac and msc ops at vector dialect level. The only op in vector</span></span><br><span class="line">  <span class="comment">// dialect is just FMA op.</span></span><br><span class="line">  llvm::SmallSet&lt;Operation *, <span class="number">8</span>&gt; mscOps;</span><br><span class="line">  <span class="comment">// Used to build and insert all the new operations created.</span></span><br><span class="line">  OpBuilder builder;</span><br><span class="line">  <span class="comment">// The shift val for ups and srs intinsics. This value should be between 0</span></span><br><span class="line">  <span class="comment">// and 63.</span></span><br><span class="line">  <span class="type">int8_t</span> shift;</span><br><span class="line">  <span class="comment">// The zero offset, indicating the position of recurring 0 in the input</span></span><br><span class="line">  <span class="comment">// filter. The counting starts at 1. For example, if the filter array is</span></span><br><span class="line">  <span class="comment">// &#123;1,2,3,0,4,5,6,0,7,8,9,0&#125;, then zeroOffset=4.</span></span><br><span class="line">  <span class="type">int32_t</span> zeroOffset;</span><br><span class="line">  <span class="comment">// The duplicate count, indicating the number of times a value is duplicated</span></span><br><span class="line">  <span class="comment">// in the filter. The filter values must be duplicated at least twice for the</span></span><br><span class="line">  <span class="comment">// i8xi8 scheme. An example of filter for i8xi8 scheme is &#123;0,0,1,1,2,2,3,3&#125;,</span></span><br><span class="line">  <span class="comment">// with dupFactor=2.</span></span><br><span class="line">  <span class="type">int32_t</span> dupFactor;</span><br><span class="line"></span><br><span class="line">  <span class="type">bool</span> unalignedLoadsCheck, aieml;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Constructors</span></span><br><span class="line">  <span class="built_in">VectState</span>(MLIRContext *context, <span class="type">int8_t</span> s, <span class="type">int32_t</span> z, <span class="type">int32_t</span> d,</span><br><span class="line">            <span class="type">bool</span> unalignedLoadsCheck, <span class="type">bool</span> aieml)</span><br><span class="line">      : <span class="built_in">builder</span>(context), <span class="built_in">shift</span>(s), <span class="built_in">zeroOffset</span>(z), <span class="built_in">dupFactor</span>(d),</span><br><span class="line">        <span class="built_in">unalignedLoadsCheck</span>(unalignedLoadsCheck), <span class="built_in">aieml</span>(aieml) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">IntervalReuse *<span class="title">getIntervalForOperation</span><span class="params">(Operation *op)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>





<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// -----// IR Dump After AIEInnerUnroll (aie-inner-unroll) //----- //</span></span><br><span class="line"><span class="keyword">module</span> &#123;</span><br><span class="line">  func.func @<span class="built_in">conv2d</span>(%arg0: memref&lt;?x64xi16&gt;, %arg1: memref&lt;?x3xi16&gt;, %arg2: memref&lt;?x32xi16&gt;) attributes &#123;llvm.linkage = <span class="meta">#llvm.linkage<span class="string">&lt;external&gt;</span>&#125; &#123;</span></span><br><span class="line">    %c0_i32 = arith.constant <span class="number">0</span> : i32</span><br><span class="line">    %c0 = arith.constant <span class="number">0</span> : index</span><br><span class="line">    %<span class="number">0</span> = aievec.upd %arg1[%c0, %c0] &#123;index = <span class="number">0</span> : i8, offset = <span class="number">0</span> : i32&#125; : memref&lt;?x3xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;</span><br><span class="line">    %c0_0 = arith.constant <span class="number">0</span> : index</span><br><span class="line">    %c32 = arith.constant <span class="number">32</span> : index</span><br><span class="line">    %c1 = arith.constant <span class="number">1</span> : index</span><br><span class="line">    scf.<span class="keyword">for</span> %arg3 = %c0_0 to %c32 step %c1 &#123;</span><br><span class="line">      %c1_1 = arith.constant <span class="number">1</span> : index</span><br><span class="line">      %<span class="number">1</span> = arith.addi %arg3, %c1_1 : index</span><br><span class="line">      %c2 = arith.constant <span class="number">2</span> : index</span><br><span class="line">      %<span class="number">2</span> = arith.addi %arg3, %c2 : index</span><br><span class="line">      %c0_2 = arith.constant <span class="number">0</span> : index</span><br><span class="line">      %c32_3 = arith.constant <span class="number">32</span> : index</span><br><span class="line">      %c16 = arith.constant <span class="number">16</span> : index</span><br><span class="line">      %c32_4 = arith.constant <span class="number">32</span> : index</span><br><span class="line">      %<span class="number">3</span> = aievec.upd %arg0[%arg3, %c0_2] &#123;index = <span class="number">0</span> : i8, offset = <span class="number">0</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">4</span> = aievec.upd %arg0[%arg3, %c0_2], %<span class="number">3</span> &#123;index = <span class="number">1</span> : i8, offset = <span class="number">256</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">5</span> = aievec_aie<span class="number">1.</span>mul %<span class="number">4</span>, %<span class="number">0</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;0&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;0&quot;</span>, zstep = <span class="string">&quot;1&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">6</span> = aievec_aie<span class="number">1.</span>mac %<span class="number">4</span>, %<span class="number">0</span>, %<span class="number">5</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;2&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;2&quot;</span>, zstep = <span class="string">&quot;13&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">7</span> = aievec.upd %arg0[%<span class="number">1</span>, %c0_2] &#123;index = <span class="number">0</span> : i8, offset = <span class="number">0</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">8</span> = aievec.upd %arg0[%<span class="number">1</span>, %c0_2], %<span class="number">7</span> &#123;index = <span class="number">1</span> : i8, offset = <span class="number">256</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">9</span> = aievec_aie<span class="number">1.</span>mac %<span class="number">8</span>, %<span class="number">0</span>, %<span class="number">6</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;0&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;3&quot;</span>, zstep = <span class="string">&quot;1&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">10</span> = aievec_aie<span class="number">1.</span>mac %<span class="number">8</span>, %<span class="number">0</span>, %<span class="number">9</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;2&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;5&quot;</span>, zstep = <span class="string">&quot;10&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">11</span> = aievec.upd %arg0[%<span class="number">2</span>, %c0_2] &#123;index = <span class="number">0</span> : i8, offset = <span class="number">0</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">12</span> = aievec.upd %arg0[%<span class="number">2</span>, %c0_2], %<span class="number">11</span> &#123;index = <span class="number">1</span> : i8, offset = <span class="number">256</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">13</span> = aievec_aie<span class="number">1.</span>mac %<span class="number">12</span>, %<span class="number">0</span>, %<span class="number">10</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;0&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;6&quot;</span>, zstep = <span class="string">&quot;1&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">14</span> = aievec_aie<span class="number">1.</span>mac %<span class="number">12</span>, %<span class="number">0</span>, %<span class="number">13</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;2&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;8&quot;</span>, zstep = <span class="string">&quot;7&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">15</span> = aievec.srs %<span class="number">14</span>, %c0_i32 : vector&lt;<span class="number">16</span>xi48&gt;, i32, vector&lt;<span class="number">16</span>xi16&gt;</span><br><span class="line">      vector.transfer_write %<span class="number">15</span>, %arg2[%arg3, %c0_2] : vector&lt;<span class="number">16</span>xi16&gt;, memref&lt;?x32xi16&gt;</span><br><span class="line">      %c1_5 = arith.constant <span class="number">1</span> : index</span><br><span class="line">      %<span class="number">16</span> = arith.muli %c16, %c1_5 : index</span><br><span class="line">      %<span class="number">17</span> = arith.addi %c0_2, %<span class="number">16</span> : index</span><br><span class="line">      %<span class="number">18</span> = aievec.upd %arg0[%arg3, %<span class="number">17</span>] &#123;index = <span class="number">0</span> : i8, offset = <span class="number">0</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">19</span> = aievec.upd %arg0[%arg3, %<span class="number">17</span>], %<span class="number">18</span> &#123;index = <span class="number">1</span> : i8, offset = <span class="number">256</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">20</span> = aievec_aie<span class="number">1.</span>mul %<span class="number">19</span>, %<span class="number">0</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;0&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;0&quot;</span>, zstep = <span class="string">&quot;1&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">21</span> = aievec_aie<span class="number">1.</span>mac %<span class="number">19</span>, %<span class="number">0</span>, %<span class="number">20</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;2&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;2&quot;</span>, zstep = <span class="string">&quot;13&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">22</span> = aievec.upd %arg0[%<span class="number">1</span>, %<span class="number">17</span>] &#123;index = <span class="number">0</span> : i8, offset = <span class="number">0</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">23</span> = aievec.upd %arg0[%<span class="number">1</span>, %<span class="number">17</span>], %<span class="number">22</span> &#123;index = <span class="number">1</span> : i8, offset = <span class="number">256</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">24</span> = aievec_aie<span class="number">1.</span>mac %<span class="number">23</span>, %<span class="number">0</span>, %<span class="number">21</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;0&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;3&quot;</span>, zstep = <span class="string">&quot;1&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">25</span> = aievec_aie<span class="number">1.</span>mac %<span class="number">23</span>, %<span class="number">0</span>, %<span class="number">24</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;2&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;5&quot;</span>, zstep = <span class="string">&quot;10&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">26</span> = aievec.upd %arg0[%<span class="number">2</span>, %<span class="number">17</span>] &#123;index = <span class="number">0</span> : i8, offset = <span class="number">0</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">27</span> = aievec.upd %arg0[%<span class="number">2</span>, %<span class="number">17</span>], %<span class="number">26</span> &#123;index = <span class="number">1</span> : i8, offset = <span class="number">256</span> : i32&#125; : memref&lt;?x64xi16&gt;, vector&lt;<span class="number">32</span>xi16&gt;</span><br><span class="line">      %<span class="number">28</span> = aievec_aie<span class="number">1.</span>mac %<span class="number">27</span>, %<span class="number">0</span>, %<span class="number">25</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;0&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;6&quot;</span>, zstep = <span class="string">&quot;1&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">29</span> = aievec_aie<span class="number">1.</span>mac %<span class="number">27</span>, %<span class="number">0</span>, %<span class="number">28</span> &#123;xoffsets = <span class="string">&quot;0x03020100&quot;</span>, xoffsets_hi = <span class="string">&quot;0x07060504&quot;</span>, xsquare = <span class="string">&quot;0x2110&quot;</span>, xstart = <span class="string">&quot;2&quot;</span>, zoffsets = <span class="string">&quot;0&quot;</span>, zoffsets_hi = <span class="string">&quot;0&quot;</span>, zstart = <span class="string">&quot;8&quot;</span>, zstep = <span class="string">&quot;7&quot;</span>&#125; : vector&lt;<span class="number">32</span>xi16&gt;, vector&lt;<span class="number">16</span>xi16&gt;, vector&lt;<span class="number">16</span>xi48&gt;</span><br><span class="line">      %<span class="number">30</span> = aievec.srs %<span class="number">29</span>, %c0_i32 : vector&lt;<span class="number">16</span>xi48&gt;, i32, vector&lt;<span class="number">16</span>xi16&gt;</span><br><span class="line">      vector.transfer_write %<span class="number">30</span>, %arg2[%arg3, %<span class="number">17</span>] : vector&lt;<span class="number">16</span>xi16&gt;, memref&lt;?x32xi16&gt;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/mlir/" rel="tag"># mlir</a>
              <a href="/tags/basics/" rel="tag"># basics</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/06/19/Triton-%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE-md/" rel="prev" title="Triton 开源项目.md">
      <i class="fa fa-chevron-left"></i> Triton 开源项目.md
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/07/14/Efficient-C-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" rel="next" title="Efficient C++阅读笔记">
      Efficient C++阅读笔记 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Pass-Pipeline"><span class="nav-number">1.</span> <span class="nav-text">Pass Pipeline</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#VectorState"><span class="nav-number">1.1.</span> <span class="nav-text">VectorState</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Interval-Reuse"><span class="nav-number">1.2.</span> <span class="nav-text">Interval Reuse</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#VecState"><span class="nav-number">1.3.</span> <span class="nav-text">VecState</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Leon Dou</p>
  <div class="site-description" itemprop="description">关注领域：体系结构，编译技术</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">29</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leon Dou</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">309k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">4:41</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : 'Ov23liFsw1lTgh0R8s8H',
      clientSecret: '1f947cb0d107ba1ffbcad8c25688c075224fff36',
      repo        : 'micropuma.github.io',
      owner       : 'micropuma',
      admin       : ['micropuma'],
      id          : '9890db69e8f2c56c7f1ee1dda88e7744',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>
</body>
</html>
