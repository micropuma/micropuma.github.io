<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="article">
<meta property="og:title" content="Paper reading: Astitch compiler">
<meta property="og:url" content="http://example.com/2025/12/15/Paper-reading-Astitch-compiler/index.html">
<meta property="og:site_name" content="Leon&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/image-20251215154331216.png">
<meta property="og:image" content="http://example.com/images/image-20251215184223040.png">
<meta property="og:image" content="http://example.com/images/image-20251215190312500.png">
<meta property="og:image" content="http://example.com/images/image-20251215193455487.png">
<meta property="og:image" content="http://example.com/images/image-20251215194059484.png">
<meta property="og:image" content="http://example.com/images/image-20251215195033815.png">
<meta property="og:image" content="http://example.com/images/image-20251215200743746.png">
<meta property="og:image" content="http://example.com/images/image-20251215202915563.png">
<meta property="og:image" content="http://example.com/images/image-20251215204126724.png">
<meta property="og:image" content="http://example.com/images/image-20251215210840266.png">
<meta property="og:image" content="http://example.com/images/image-20251216001641489.png">
<meta property="og:image" content="http://example.com/images/image-20251215210235442.png">
<meta property="article:published_time" content="2025-12-15T07:41:46.000Z">
<meta property="article:modified_time" content="2026-01-02T13:33:59.988Z">
<meta property="article:author" content="Leon Dou">
<meta property="article:tag" content="论文阅读">
<meta property="article:tag" content="前沿科技">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/image-20251215154331216.png">

<link rel="canonical" href="http://example.com/2025/12/15/Paper-reading-Astitch-compiler/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Paper reading: Astitch compiler | Leon's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Leon's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">分享一点有趣的技术</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/micropuma" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/15/Paper-reading-Astitch-compiler/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Leon Dou">
      <meta itemprop="description" content="关注领域：体系结构，编译技术">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leon's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Paper reading: Astitch compiler
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-12-15 15:41:46" itemprop="dateCreated datePublished" datetime="2025-12-15T15:41:46+08:00">2025-12-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2026-01-02 21:33:59" itemprop="dateModified" datetime="2026-01-02T21:33:59+08:00">2026-01-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文阅读</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/%E5%89%8D%E6%B2%BF%E7%A7%91%E6%8A%80/" itemprop="url" rel="index"><span itemprop="name">前沿科技</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>7.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>7 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><img src="/images/image-20251215154331216.png" alt="image-20251215154331216"></p>
<span id="more"></span>

<blockquote>
<p>这一专题主要是记录我的paper阅读过程，按照不同前沿方向进行整理，以求理清不同前沿方向基本概念框架，目前进展和局限瓶颈，促进自己的编译研究工作。 </p>
<p>本次分享<a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3503222.3507723">AStitch: Enabling a New Multi-dimensional Optimization Space for Memory-Intensive ML Training and Inference on Modern SIMT Architectures</a>，是阿里PAI部分工作。</p>
</blockquote>
<h2 id="TLDR"><a href="#TLDR" class="headerlink" title="TLDR"></a><font color = brown>TLDR</font></h2><p>TLDR章节尝试用最简的话阐述清楚paper的动机，方法与贡献。   </p>
<h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a><font color = green>动机</font></h3><p>Astitch的动机十分简单，基于作者的如下两个observation：  </p>
<ul>
<li>现有的XLA，tensor-rt等编译加速技术无法针对访存密集算子做高效融合。  </li>
<li>大模型时代（transformer based），访存密集算子在整个模型计算图中数量占比高，性能占比也很高，逐渐成为训练推理的性能瓶颈。</li>
</ul>
<p>进一步深入分析XLA&#x2F;Tensor-RT等编译器，论文中总结出了如下几个核心问题：  </p>
<ul>
<li>访存密集算子的<strong>依赖关系是two-level</strong>的（element-level和operator-level），fusion更加困难。XLA&#x2F;TVM等编译器往往引入大量重复计算开销，或是干脆直接不融合，性能提升很小。</li>
<li>AI编译器服务一个模型必须是<strong>JIT模式</strong>，前期大量的AOT优化工作没有实际生产意义。 </li>
<li>tensor有<strong>大量非常规形状</strong>，XLA&#x2F;TVM的代码生成往往没法自适应shape形状生成高效的线程映射代码。</li>
</ul>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a><font color = green>方法</font></h3><p>基于上述动机和核心问题，Astitch做了如下尝试：  </p>
<ul>
<li>整个编译器是JIT模式。即TensorFlow&#x2F;Pytorch自动圈图，Astitch编译优化后再由TensorFlow&#x2F;Pytorch的runtime发射运行。</li>
<li>Astitch提出的Stitch访存密集优化：  <ol>
<li><strong>针对不同类型operators，提出四类融合策略</strong>。</li>
<li><strong>多层级的数据重用技术</strong>。具体有thread reg，shared memory和global memory三个层级。 </li>
<li><strong>自适应thread mapping技术</strong>。解决cuda blocks数量过少，或单个block计算量太小没法打满threads两种情况。</li>
</ol>
</li>
<li>最终的Astitch，支持训练+推理优化。</li>
</ul>
<blockquote>
<p>本篇paper提供docker环境，经测试是可复现的。Astitch技术也应用于阿里的BladeDISC开源编译器项目。对BladeDISC项目感兴趣的可以参考<a target="_blank" rel="noopener" href="https://github.com/alibaba/BladeDISC">BladeDISC github</a>以及<a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3617327">BladeDISC paper</a>。</p>
</blockquote>
<h2 id="Deep-Dive"><a href="#Deep-Dive" class="headerlink" title="Deep Dive"></a><font color = Brown>Deep Dive</font></h2><p>从四个小节来详细解读Astitch paper： </p>
<ul>
<li>背景  </li>
<li>瓶颈分析  </li>
<li>Astitch的关键技术  </li>
<li>工程实现框架与细节</li>
</ul>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a><font color = green>背景</font></h3><p>Astitch部分的背景其实十分简单，整个叙事如下：  </p>
<ol>
<li><p><strong>访存密集算子值得关注!!!</strong> </p>
<p>transfomer时代下，模型往往有大量的访存密集算子。对于GPU这样的硬件加速器，访问存储算子逐渐成为主要的开销，原因如下：  </p>
<ul>
<li>相比访存算子，计算密集算子往往有高效的手写算子库，或是大量前期算子融合编译工作，性能上有保障。  </li>
<li>访存密集算子涉及大量的off-chip存储访问。（:key:Astitch的核心关注点）</li>
<li>访存密集算子量大且不好融合，带来巨大的kernel launch以及context switch开销。（:ghost:微软的Rammer等工作关注这些非计算开销）</li>
</ul>
<p>论文中进一步给访存密集算子分类，分为（1）逐元素算子（2）规约算子。其中逐元素算子又进一步分为light-weight（add &#x2F; sub这种硬件上实现简单的计算）和heavy-weight（tanh这种复合计算）。值得注意的是，broadcast算子算作逐元素算子。  </p>
<blockquote>
<p><img src="/images/image-20251215184223040.png" alt="image-20251215184223040"></p>
<p>论文对Bert等模型做了perf，得出截图中的结论，可以看到reduce算子，broadcast算子的占比相当高，表明论文研究的问题是有意义的。</p>
</blockquote>
</li>
<li><p><strong>XLA&#x2F;TVM等SOTA编译器算子融合能力十分局限</strong>  </p>
<blockquote>
<p>论文中一个很有意思的观点：算子融合能力取决于后端代码生成能力。只有在编译器后端能够针对特定pattern生成高效的代码（比如面向GPU生成GPU IR），前端融合才有价值。</p>
</blockquote>
<p>目前XLA&#x2F;TVM的代码生成，只支持将producer元素one to one inline到consumer，大量潜在的访存密集融合难以支持。如下图所示，XLA的融合可以归结为kLoop和kInput融合，条件比较苛刻。对于XLA融合感兴趣读者建议参考<a target="_blank" rel="noopener" href="http://arxiv.org/abs/2301.13062">Operator Fusion in XLA: Analysis and Evaluation</a>。</p>
<p><img src="/images/image-20251215190312500.png" alt="image-20251215190312500"></p>
</li>
</ol>
<h3 id="瓶颈分析"><a href="#瓶颈分析" class="headerlink" title="瓶颈分析"></a><font color = green>瓶颈分析</font></h3><p>这一部分强烈建议读者阅读paper的section2.3，对于理解算子融合和算子生成瓶颈大有帮助。论文中总结处两大瓶颈</p>
<h4 id="瓶颈1：算子间存在两层依赖关系，高效融合很困难"><a href="#瓶颈1：算子间存在两层依赖关系，高效融合很困难" class="headerlink" title="瓶颈1：算子间存在两层依赖关系，高效融合很困难"></a>瓶颈1：算子间存在两层依赖关系，高效融合很困难</h4><p>该瓶颈依赖于如下观察：  </p>
<p><img src="/images/image-20251215193455487.png" alt="image-20251215193455487"></p>
<p>上图展示了一个计算图中的两个不同层级的依赖关系。A-&gt;B这种依赖是operator层级的依赖。而右图中element-wise-&gt;reduce-&gt;broadcast出了operator层级依赖，还存在element层级依赖，即一个element元素会被broadcast（one to many），也会被reduce（many to one）。operator依赖和element依赖同时存在，使得编译分析优化异常棘手。  </p>
<p>接下来分别针对两个level，分析TVM和XLA在融合上的瓶颈。  </p>
<ol>
<li><p>Element level融合缺陷  </p>
<p>XLA&#x2F;TVM对于两种典型的element依赖pattern，无法做到高效融合：（1）reduce op -&gt; consumer融合（2）计算量大的逐元素 -&gt; broadcast。  </p>
<img src="/images/image-20251215194059484.png" alt="image-20251215194059484" style="zoom:50%;" />

<p>上图是论文中的case，其结构很简单：逐元素（light-weight） -&gt; 广播 -&gt; 逐元素（heavy-weight）。如果你是GPU kernel开发专家，你一定会把逐元素的结果存到shared memory，使得广播的每个thread能够高效获取结果。<strong>可惜的是，XLA&#x2F;TVM仅仅支持per thread register共享数据，这种one-to-many通过shared memory的方式对于目前SOTA编译器是out of scope的</strong>。</p>
<p>因此，XLA&#x2F;TVM有两种策略：  </p>
<ul>
<li><strong>duplicate计算然后融合</strong>。即add算子操作的每个element，都需要经过power处理，直接选择每个线程重复做一遍power计算。power计算是heavy-weight，开销无法忽略。而大模型中时常出现的一个场景是reduce后接broadcast（layer norm！！！），reduce极其占计算时间，这种duplicate操作根本无法接受。  </li>
<li><strong>单纯跳过</strong>。这种方案导致碎片化的kernel launch，大量的non-computation overhead！！！。</li>
</ul>
</li>
<li><p>operator level，和element-level的fusion一样，会导致重复计算问题。</p>
</li>
</ol>
<h4 id="瓶颈2：动态shape，不规则shape导致低效代码生成"><a href="#瓶颈2：动态shape，不规则shape导致低效代码生成" class="headerlink" title="瓶颈2：动态shape，不规则shape导致低效代码生成"></a>瓶颈2：动态shape，不规则shape导致低效代码生成</h4><p><img src="/images/image-20251215195033815.png" alt="image-20251215195033815"></p>
<p>如上是论文中的case，主要分为两个问题：（1）block块过小（2）block数过少。  </p>
<p>对于问题1，一个例子是DIEN模型中出现的将一个&lt;750000，32&gt; 归约到&lt;750000&gt;这样的pattern。关键问题是：  </p>
<ul>
<li>太多blocks，750000个。但是GPU能够并行运行的block数目是受限的，并行性很差。  </li>
<li>每个block里的threads总共完成32个数据规约，计算任务过于小，block内部资源也无法打满。</li>
</ul>
<p>对于问题2，transfomer模型中的极端case是对&lt;64,30000&gt;做行规约。以V100gpu为例，关键问题是：  </p>
<ul>
<li>编译自动生成64个threadblocks，每个block 1024 threads。</li>
<li>V100gpu支持160blocks并行，硬件资源利用极低。</li>
</ul>
<h3 id="Astitch关键技术"><a href="#Astitch关键技术" class="headerlink" title="Astitch关键技术"></a><font color = green>Astitch关键技术</font></h3><p>详细剖析目前算子融合瓶颈后，Astitch给出了它的解决方案：多层级数据重用策略（应对瓶颈1） + 自适应线程映射（应对瓶颈2）。</p>
<h4 id="多层级数据重用策略"><a href="#多层级数据重用策略" class="headerlink" title="多层级数据重用策略"></a>多层级数据重用策略</h4><p>Astitch首先定义了operator-stitch抽象，用来给每个operator做归类：  </p>
<p><img src="/images/image-20251215200743746.png" alt="image-20251215200743746"></p>
<ul>
<li>independent：operator间无依赖，怎么融合都行  </li>
<li>local scheme：逐元素依赖，consumer直接用producer生成的每个thread的寄存器即可 （至此XLA&#x2F;TVM均支持）</li>
<li>Region scheme：适用于一个算子的<strong>某个元素输出</strong>会被 <strong>多个后续算子的元素使用</strong>这一情景。该策略支持一个 thread block内算出来的中间数据被block内多个线程复用。<font color = red>强制producer和consumer使用同一个thread block，即<strong>thread block 局部性</strong>。</font></li>
<li>Global scheme：所有中间结果写入全局内存，不强制要求producer和consumer使用同一个thread block。任何算子可用此策略进行缝合。</li>
</ul>
<p>后两个策略涉及tradeoff：<strong>并行度 vs. 局部性</strong>。如果使用Region策略，需要将相关线程装入一个block，可能无法打满GPU资源（原本可以用更多的thread blocks来获取更好地并行性）。因此针对不同场景，编译器需要能够自动做出选择（工程实践章节会重点展开论述）。</p>
<p>上述四个策略，使得Astitch在面对Operator-level&#x2F;Element-level的数据重用场景，都能高效融合（借助于shared memory和global memory做缓存）。如下是论文中的case，论文没有对每个op如何选取策略做详细解释，仅做演示例子：  </p>
<p><img src="/images/image-20251215202915563.png" alt="image-20251215202915563"></p>
<p>具体的收益如下：  </p>
<ul>
<li>XLA 4次kernel launch，TVM 3次kernel launch（TVM能够融合R.1和Pw.1），而Astitch仅需1次kernel launch。降低kernel launch overhead，降低context switch overhead。  </li>
<li>R.1和Pw.1的融合，Astitch采用regional scheme，而TVM采用duplicate computation，显著的计算开销。</li>
</ul>
<p>overhead如下：  </p>
<ul>
<li>融合R.1和Pw.1用的shared memory，需要在thread block内做线程级别同步。</li>
<li>其他global scheme，需要做thread blocks间同步。<strong>注意，这对于thread blocks个数有明确限制，超过GPU上限（160 for V100），会引入死锁。</strong></li>
</ul>
<h4 id="自适应线程映射技术"><a href="#自适应线程映射技术" class="headerlink" title="自适应线程映射技术"></a>自适应线程映射技术</h4><p>这一块Astitch做的工作很好理解，提出Task-packing和Task-splitting策略，解决瓶颈2的两个问题。   </p>
<p><img src="/images/image-20251215204126724.png" alt="image-20251215204126724"></p>
<ul>
<li><p>packing分为两个维度：横向和纵向。  </p>
<ul>
<li><p>横向packing解决block size过小问题。</p>
<p>例子是将&lt;750000, 32&gt;数据块，原本是一个thread block处理一行32个元素，做横向打包，变成&lt;? , 32x32&gt;，即一个thread block现在处理1024个元素。映射到线程上，32个线程处理一行数据（&lt;750000，32&gt;数据块shape不变，变的是thread映射），共处理32行（即&lt;750000， 32&gt; 变成 &lt;750000&#x2F;32块， 32行， 32列&gt;）。一个warp处理一行，做reduction是极其高效的。  </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Thread block (1024 threads)</span><br><span class="line">│</span><br><span class="line">├── threads 0–31     → row 0</span><br><span class="line">├── threads 32–63    → row 1</span><br><span class="line">├── threads 64–95    → row 2</span><br><span class="line">...</span><br><span class="line">├── threads 992–1023 → row 31</span><br></pre></td></tr></table></figure>

<p>:cry:文笔不行，写的很乱，勿喷。</p>
</li>
<li><p>纵向packing解决block数太多的问题。block太多的问题是如果一批thread blocks没法在同一wave上完成，则没法做thread blocks同步。解决方案是将多个block的任务变成一个block内顺序执行的任务。</p>
</li>
</ul>
</li>
<li><p>Task-splitting解决的问题是block数目太少。以&lt;64,30000&gt;行规约为例，可以变成&lt;128，150000&gt;，即launch128个block做行规约，然后block之间还需要做跨block规约。  </p>
<blockquote>
<p>:question:思考一下为啥这种是划算的：  </p>
<ol>
<li>block数目过少，则很多SM是空置的，而调度的SM计算量很大，需要做30000 partial sum。</li>
<li>task-splitting后，产生的overhead是跨block做规约，只需要算两个数相加，整体计算overhead相比每个block算30000 partial sum还是划算的。</li>
<li>具体问题具体分析，如何界定reduction列数是否值得split？后续需深入CUDA reduction算子性能分析。</li>
</ol>
</blockquote>
</li>
</ul>
<h3 id="工程实现"><a href="#工程实现" class="headerlink" title="工程实现"></a><font color = green>工程实现</font></h3><blockquote>
<p>Astitch提出的各种技术，面临和其他算子融合编译器（TASO？）一样的工程困境：</p>
<p>优化plan组合爆炸，导致编译确定plan pipeline时间巨长。搜索一小时获取极致优化，纯学术产物，没有任何实际生产价值。Astitch针对这个问题做了大量观察和思考，得以工程上平衡编译速度是实际性能。</p>
</blockquote>
<p>工程实现环节主要解答如下几个问题：  </p>
<ol>
<li>如何决定哪些operators组成一个stitch region？  </li>
<li>thread mapping具体如何实现？  </li>
<li>融合出的kernel如何确定launch时候的grid size和block size？</li>
<li>如何做成编译器的pass pipeline？如何工程化？</li>
</ol>
<h4 id="划分stitch区域"><a href="#划分stitch区域" class="headerlink" title="划分stitch区域"></a>划分stitch区域</h4><p>这一部分重点是：</p>
<ul>
<li>确定哪些operators组成访存密集子图，即stitch区域。</li>
<li>确定stitch区域中的dominant operator，后续整个stitich区域的thread mapping完全取决于该dominant operator。</li>
</ul>
<img src="/images/image-20251215210840266.png" alt="image-20251215210840266" style="zoom: 67%;" />

<p>具体步骤如下：  </p>
<ol>
<li><p>用BFS做图遍历得到访存密集子图 ，并表示成一个stitch op。</p>
</li>
<li><p>做子图合并。遍历stitch op，如果两个stitich op没有依赖，则可以合并成一个大的stitch op。注意合并的另一条件是不能形成环。一个stitch op最终就是一个cuda kernel。  </p>
</li>
<li><p>确定dominant op。</p>
<blockquote>
<p>论文中选择reduce op以及heavy-weight逐元素+broadcast为潜在dominant操作。</p>
<ul>
<li>因为逐个元素，或是light-weight逐元素+broadcast（duplicate是合适的），可以用local策略，local策略的thread mapping可以传播的，没必要做dominant。</li>
<li>倾向于reduce为dominant op，因为reduce需要高并行度，thread mapping应该优先考虑reduce的需求。</li>
</ul>
</blockquote>
</li>
<li><p>dominant 融合 </p>
<p>当两个dominant op之间全是element-wise op，则一个dominant op的thread mapping确定，另一个也确定。退化选择方面，优先确保reduce op是dominant。  </p>
</li>
<li><p>dominant op当做锚点，生成stitch region</p>
</li>
</ol>
<blockquote>
<p>:key:takeaway：  </p>
<ul>
<li>dominant op&#x2F;sub dominant op需要后续选择是regional&#x2F;global，其他op都是local策略。</li>
</ul>
</blockquote>
<h4 id="Thread-Mapping实现"><a href="#Thread-Mapping实现" class="headerlink" title="Thread Mapping实现"></a>Thread Mapping实现</h4><p>这一块也涉及两个发现：</p>
<ul>
<li><p>**thread mapping存在传播机制：**和stich策略分配一样，作者发现只需对dominant op做好线程映射，同一stitch区域其他operator的线程mapping存在传播机制。</p>
<blockquote>
<p>对于dominant op的thread mapping，以reduction op为例，Astitch使用如下机制：  </p>
<ul>
<li>如果行数（rows）&lt; 每 wave 允许的 block，并且每行数据很多（&gt;1024），做task splitting。  </li>
<li>反之task packing，尽量打满每个thread block处理的数据（生成尽量大的block）。</li>
</ul>
</blockquote>
</li>
<li><p><strong>thread mapping传播过程中，可以同步完成对每个operator的stitch策略的选取</strong>：<font color = red>这一点基于一个共识：是thread register fusion，还是shared memory fusion亦或是global memory fusion，都依赖于两个operator的线程映射是哪种match。</font>Astitch针对shared memory stitch策略，还引入两种机制：（1）被动的block局部性检查；（2）主动的block局部性自适应。</p>
<p><img src="/images/image-20251216001641489.png" alt="image-20251216001641489"></p>
</li>
</ul>
<h4 id="资源感知的-GPU-Kernel-启动配置"><a href="#资源感知的-GPU-Kernel-启动配置" class="headerlink" title="资源感知的 GPU Kernel 启动配置"></a>资源感知的 GPU Kernel 启动配置</h4><p>这一块比较有趣。首选是Astitch的大尺寸stitch融合面临的一个重要难题：  </p>
<blockquote>
<p>AStitch 要求 GPU kernel 的启动配置必须满足一个关键约束：<strong>同一 wave 中活跃的 thread-block 数量不能超过硬件允许的最大值</strong>，记为：C-blocks-per-wave。这是因为 AStitch 在 stitch 后的 kernel 内部使用了 <strong>global barrier（全局同步）</strong>，而全局同步对并发 block 数量有严格限制。</p>
</blockquote>
<p>但现实中，存在一个“先有鸡还是先有蛋”的问题：<code>C_blocks-per-wave</code> 依赖于：</p>
<ul>
<li>寄存器使用量</li>
<li>共享内存使用量</li>
<li>block size</li>
</ul>
<p>而而这些信息 <strong>只有在编译完成后才能准确得到</strong>。因此，AStitch 无法在优化阶段直接获取准确的 <code>C_blocks-per-wave</code>。  </p>
<p>:question:如何解决  </p>
<ol>
<li>AStitch 采用一种“<strong>假设–放松–应用</strong>”的寄存器约束策略：先假设一个很小的寄存器使用上限（如 32），据此结合共享内存使用和最大 block size（如 1024）计算 <code>C_blocks-per-wave</code>，以降低全局同步开销；</li>
<li>然后判断并行度是否主要受共享内存而非寄存器限制，若是则反推出允许的<strong>最大寄存器使用量</strong>并放松约束；最后在生成 GPU IR 时通过编译器注解施加该寄存器上限。</li>
<li>在AStitch实验中未观察到寄存器溢出问题。</li>
</ol>
<blockquote>
<p>这一块值得更加深入地探讨和研究。具体如下：  </p>
<ul>
<li>启发算法背后原理？  </li>
<li>启发算法如何保证soundness？</li>
<li>是否可以形式化？</li>
</ul>
</blockquote>
<h4 id="工程上pipeline组建细节"><a href="#工程上pipeline组建细节" class="headerlink" title="工程上pipeline组建细节"></a>工程上pipeline组建细节</h4><p><img src="/images/image-20251215210235442.png" alt="image-20251215210235442"></p>
<p>上述图十分清晰的展示了整个pipeline的布局。大多数passes我们都详细解读过，内存优化没有详细讨论，因为比较朴素：  </p>
<ul>
<li>借助于支配树，在数据流模型上做memory的live range分析。Astitch能够追求最大程度的operators间内存复用。  </li>
<li>如果一个regional的operators需要的共享内存超出GPU限制，则在这一阶段退化成global策略。</li>
</ul>
<h2 id="我的一些疑问"><a href="#我的一些疑问" class="headerlink" title="我的一些疑问"></a><font color = brown>我的一些疑问</font></h2><ul>
<li>BladeDISC是阿里PAI后续的延伸工作，主要针对动态shape进行了更深入的研究（动态shape + Stitch融合）。后续结合BladeDISC开源源码进行分析。目前有如下疑点：  <ul>
<li>似乎GPU 生成默认没有开启Stitch，why？</li>
</ul>
</li>
<li>编译算子融合，推理端和训练端需要考虑的因素差异是哪些？</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/" rel="tag"># 论文阅读</a>
              <a href="/tags/%E5%89%8D%E6%B2%BF%E7%A7%91%E6%8A%80/" rel="tag"># 前沿科技</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/10/09/%E7%A1%AC%E4%BB%B6%E4%B8%93%E9%A2%98-data-orchastration/" rel="prev" title="硬件专题: data orchastration">
      <i class="fa fa-chevron-left"></i> 硬件专题: data orchastration
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#TLDR"><span class="nav-number">1.</span> <span class="nav-text">TLDR</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8A%A8%E6%9C%BA"><span class="nav-number">1.1.</span> <span class="nav-text">动机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-number">1.2.</span> <span class="nav-text">方法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deep-Dive"><span class="nav-number">2.</span> <span class="nav-text">Deep Dive</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%83%8C%E6%99%AF"><span class="nav-number">2.1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%93%B6%E9%A2%88%E5%88%86%E6%9E%90"><span class="nav-number">2.2.</span> <span class="nav-text">瓶颈分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%93%B6%E9%A2%881%EF%BC%9A%E7%AE%97%E5%AD%90%E9%97%B4%E5%AD%98%E5%9C%A8%E4%B8%A4%E5%B1%82%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%EF%BC%8C%E9%AB%98%E6%95%88%E8%9E%8D%E5%90%88%E5%BE%88%E5%9B%B0%E9%9A%BE"><span class="nav-number">2.2.1.</span> <span class="nav-text">瓶颈1：算子间存在两层依赖关系，高效融合很困难</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%93%B6%E9%A2%882%EF%BC%9A%E5%8A%A8%E6%80%81shape%EF%BC%8C%E4%B8%8D%E8%A7%84%E5%88%99shape%E5%AF%BC%E8%87%B4%E4%BD%8E%E6%95%88%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90"><span class="nav-number">2.2.2.</span> <span class="nav-text">瓶颈2：动态shape，不规则shape导致低效代码生成</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Astitch%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF"><span class="nav-number">2.3.</span> <span class="nav-text">Astitch关键技术</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E5%B1%82%E7%BA%A7%E6%95%B0%E6%8D%AE%E9%87%8D%E7%94%A8%E7%AD%96%E7%95%A5"><span class="nav-number">2.3.1.</span> <span class="nav-text">多层级数据重用策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E9%80%82%E5%BA%94%E7%BA%BF%E7%A8%8B%E6%98%A0%E5%B0%84%E6%8A%80%E6%9C%AF"><span class="nav-number">2.3.2.</span> <span class="nav-text">自适应线程映射技术</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B7%A5%E7%A8%8B%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.4.</span> <span class="nav-text">工程实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%88%92%E5%88%86stitch%E5%8C%BA%E5%9F%9F"><span class="nav-number">2.4.1.</span> <span class="nav-text">划分stitch区域</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Thread-Mapping%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.4.2.</span> <span class="nav-text">Thread Mapping实现</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B5%84%E6%BA%90%E6%84%9F%E7%9F%A5%E7%9A%84-GPU-Kernel-%E5%90%AF%E5%8A%A8%E9%85%8D%E7%BD%AE"><span class="nav-number">2.4.3.</span> <span class="nav-text">资源感知的 GPU Kernel 启动配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B7%A5%E7%A8%8B%E4%B8%8Apipeline%E7%BB%84%E5%BB%BA%E7%BB%86%E8%8A%82"><span class="nav-number">2.4.4.</span> <span class="nav-text">工程上pipeline组建细节</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%88%91%E7%9A%84%E4%B8%80%E4%BA%9B%E7%96%91%E9%97%AE"><span class="nav-number">3.</span> <span class="nav-text">我的一些疑问</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Leon Dou</p>
  <div class="site-description" itemprop="description">关注领域：体系结构，编译技术</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2026</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leon Dou</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">338k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">5:07</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : 'Ov23liFsw1lTgh0R8s8H',
      clientSecret: '1f947cb0d107ba1ffbcad8c25688c075224fff36',
      repo        : 'micropuma.github.io',
      owner       : 'micropuma',
      admin       : ['micropuma'],
      id          : '9beade4ca5550120cab27f9acc69ffd2',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>
</body>
</html>
