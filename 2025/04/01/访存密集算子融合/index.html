<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="article">
<meta property="og:title" content="访存密集算子融合">
<meta property="og:url" content="http://example.com/2025/04/01/%E8%AE%BF%E5%AD%98%E5%AF%86%E9%9B%86%E7%AE%97%E5%AD%90%E8%9E%8D%E5%90%88/index.html">
<meta property="og:site_name" content="Leon&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/image-20250331214150737.png">
<meta property="og:image" content="http://example.com/images/image-20250325195503234.png">
<meta property="og:image" content="http://example.com/images/2.png">
<meta property="og:image" content="http://example.com/images/1.png">
<meta property="og:image" content="http://example.com/images/3.png">
<meta property="og:image" content="http://example.com/images/4.png">
<meta property="og:image" content="http://example.com/images/4-1743436524621-10.png">
<meta property="og:image" content="http://example.com/images/image-20250326111430445.png">
<meta property="og:image" content="http://example.com/images/image-20250326114004653.png">
<meta property="og:image" content="http://example.com/images/image-20250327221745561.png">
<meta property="og:image" content="http://example.com/images/6.png">
<meta property="og:image" content="http://example.com/images/7.png">
<meta property="og:image" content="http://example.com/images/8.png">
<meta property="og:image" content="http://example.com/images/9.png">
<meta property="og:image" content="http://example.com/images/image-20250327184033247.png">
<meta property="article:published_time" content="2025-03-31T16:01:14.000Z">
<meta property="article:modified_time" content="2025-04-01T07:13:30.548Z">
<meta property="article:author" content="Leon Dou">
<meta property="article:tag" content="机器学习编译器">
<meta property="article:tag" content="mlir">
<meta property="article:tag" content="算子融合技术">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/image-20250331214150737.png">

<link rel="canonical" href="http://example.com/2025/04/01/%E8%AE%BF%E5%AD%98%E5%AF%86%E9%9B%86%E7%AE%97%E5%AD%90%E8%9E%8D%E5%90%88/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>访存密集算子融合 | Leon's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Leon's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">分享一点有趣的技术</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/micropuma" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/01/%E8%AE%BF%E5%AD%98%E5%AF%86%E9%9B%86%E7%AE%97%E5%AD%90%E8%9E%8D%E5%90%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Leon Dou">
      <meta itemprop="description" content="关注领域：体系结构，编译技术">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leon's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          访存密集算子融合
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-04-01 00:01:14 / 修改时间：15:13:30" itemprop="dateCreated datePublished" datetime="2025-04-01T00:01:14+08:00">2025-04-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BC%96%E8%AF%91%E6%8A%80%E6%9C%AF/" itemprop="url" rel="index"><span itemprop="name">编译技术</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BC%96%E8%AF%91%E6%8A%80%E6%9C%AF/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91/" itemprop="url" rel="index"><span itemprop="name">机器学习编译</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%BC%96%E8%AF%91%E6%8A%80%E6%9C%AF/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91/%E8%AE%BF%E5%AD%98%E4%BC%98%E5%8C%96/" itemprop="url" rel="index"><span itemprop="name">访存优化</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>21k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>19 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><img src="/images/image-20250331214150737.png" alt="image-20250331214150737"></p>
<span id="more"></span>

<blockquote>
<p>这是算子优化系列的第一篇，主要聚焦于存储密集型算子的融合优化。探讨这一主题的动机源于 BladeDISC 编译器，这个由阿里云开发的编译器专注于解决动态 shape 问题，并在大模型业务中实现了显著的优化。BladeDISC 的一大亮点是复用了 astitch 论文中提出的多元访存算子融合方法，因此，本文将对这一问题展开深入讨论，从两方面来分析：XLA传统融合和BladeDISC使用的stich融合。</p>
</blockquote>
<h2 id="XLA代码解析"><a href="#XLA代码解析" class="headerlink" title="XLA代码解析"></a><font color = brown>XLA代码解析</font></h2><p>在阿里的bladedisc的ppt中，可以看到如下总结：</p>
<p><img src="/images/image-20250325195503234.png" alt="image-20250325195503234"></p>
<p>先考虑从<code>mlir-hlo</code>项目入手，理解xla alike的fusion是如何做的。具体代码在<a target="_blank" rel="noopener" href="https://github.com/tensorflow/mlir-hlo/blob/1857b1eac21ef5b30b088ccc79ef2fa0e3161621/lib/Dialect/mhlo/transforms/mhlo_fusion.cc#L549">mhlo_fusion.cc</a>中。上述图片其实已经总结了XLA可以做的两种kernel fusion方式：<code>KLoop</code>和<code>KInput</code>。可以看出，<code>XLA</code>还是重点关注的算子pattern是比较简单的。</p>
<h3 id="Source-Code源码分析"><a href="#Source-Code源码分析" class="headerlink" title="Source Code源码分析"></a><font color = green>Source Code源码分析</font></h3><blockquote>
<p>核心原理是通过<strong>形状约束分析</strong>和图论中的<strong>边收缩算法</strong>，动态识别可融合的操作组，并生成高效的融合计划。</p>
<p><font color = red>形状约束是阿里团队提出的动态shape约束。</font></p>
</blockquote>
<p>该代码是典型的两阶段code，第一阶段分析出fusion plan，第二阶段应用fusion plan做相应的fusion：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">runOnOperation</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    FuncOp func = <span class="built_in">getOperation</span>();</span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">IsTargetFunc</span>(func)) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// process each block and do fusion within a block.</span></span><br><span class="line">    <span class="keyword">for</span> (Block&amp; block : func) &#123;</span><br><span class="line">      <span class="comment">// 收集一个block内部的所有operation list</span></span><br><span class="line">      SmallVector&lt;Operation*, <span class="number">4</span>&gt; op_list;</span><br><span class="line">      <span class="keyword">for</span> (Operation&amp; op : block) &#123;</span><br><span class="line">        op_list.<span class="built_in">push_back</span>(&amp;op);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="function">FusionPlanner <span class="title">planner</span><span class="params">(op_list)</span></span>;</span><br><span class="line">      llvm::Optional&lt;FusionPlan&gt; plan = planner.<span class="built_in">Run</span>();</span><br><span class="line">      <span class="keyword">if</span> (!plan) &#123;</span><br><span class="line">        <span class="built_in">emitError</span>(func.<span class="built_in">getLoc</span>(), <span class="string">&quot;can&#x27;t find a fusion plan&quot;</span>);</span><br><span class="line">        <span class="built_in">signalPassFailure</span>();</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (!<span class="built_in">ApplyFusionPlan</span>(*plan)) &#123;</span><br><span class="line">        <span class="built_in">emitError</span>(func.<span class="built_in">getLoc</span>(), <span class="string">&quot;apply fusion plan failed&quot;</span>);</span><br><span class="line">        <span class="built_in">signalPassFailure</span>();</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>上述代码段时整个pass的入口，也是整体流程控制。</p>
<ul>
<li><code>FusionPlanner planner(op_list)</code>针对一个block的oplist，初始化一个fusion plan。</li>
<li><code>planner.Run()</code>根据planner构建的图，做子图划分，生成潜在的fusion pattern集和。</li>
<li><code>ApplyFusionPlan</code>为第二阶段，将fusion pattern list用于代码改写，完成最终的fusion操作。</li>
</ul>
<p>接下来分别展开这三个函数。</p>
<h4 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h4><p>下面先来介绍一些辅助函数：</p>
<ol>
<li><p>首先，先明确<code>XLA Fusion</code>的几个<strong>基本数据结构概念</strong>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> FusionPattern = std::vector&lt;Operation*&gt;;</span><br><span class="line"><span class="keyword">using</span> FusionPlan = std::vector&lt;FusionPattern&gt;;</span><br></pre></td></tr></table></figure>

<p>FusionPattern是可融合的operation集和。FusionPlan是FusionPattern集和。</p>
</li>
<li><p><code>XLA</code>针对memory-intensive的算子，主要考虑如下两个算子：<code>ReduceOp</code>和<code>element-wiseOp</code>。分别有如下可能的融合方案：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// reduceOp主要判断，其operand的define point的op是否shape相同</span></span><br><span class="line"><span class="comment">// 如果相同，reduceOp考虑的模式是operand融合</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">IsFusibleWithOperand</span><span class="params">(Operation* op)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 相比IsFusibleWithConsumer，支持reduce op</span></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">IsMhlo</span>(op) &amp;&amp;</span><br><span class="line">         (op-&gt;<span class="built_in">hasTrait</span>&lt;::mlir::OpTrait::Elementwise&gt;() || <span class="built_in">isa</span>&lt;ReduceOp&gt;(op));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// element-wise操作或是常量操作，可以考虑是否可以和consumer融合</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">IsFusibleWithConsumer</span><span class="params">(Operation* op)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 必须是MHLO操作，并且是elementwise操作，或是常量操作</span></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">IsMhlo</span>(op) &amp;&amp; (op-&gt;<span class="built_in">hasTrait</span>&lt;::mlir::OpTrait::Elementwise&gt;() ||</span><br><span class="line">                        <span class="built_in">matchPattern</span>(op, <span class="built_in">m_Constant</span>()));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局的isFusible判断</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">IsFusible</span><span class="params">(Operation* op)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 只有常量操作或是能和consumer融合的操作才是可融合的，或是能和operand融合的操作</span></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">matchPattern</span>(op, <span class="built_in">m_Constant</span>()) || <span class="built_in">IsFusibleWithConsumer</span>(op) ||</span><br><span class="line">         <span class="built_in">IsFusibleWithOperand</span>(op);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>针对<code>FusionPattern</code>和其他block的交互：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">SmallVector&lt;Value, 4&gt; <span class="title">GetInputsOfFusionPattern</span><span class="params">(<span class="type">const</span> FusionPattern&amp; pattern)</span> </span>&#123;</span><br><span class="line">  SmallVector&lt;Value, <span class="number">4</span>&gt; inputs;</span><br><span class="line">  DenseSet&lt;Value&gt; input_set;</span><br><span class="line">  DenseSet&lt;Operation*&gt; op_set;</span><br><span class="line">  <span class="comment">// 收集一个fusion pattern里的所有operation</span></span><br><span class="line">  <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">    <span class="type">bool</span> inserted = op_set.<span class="built_in">insert</span>(op).second;</span><br><span class="line">    (<span class="type">void</span>)inserted;</span><br><span class="line">    <span class="built_in">assert</span>(inserted &amp;&amp; <span class="string">&quot;FusionPattern contains duplicate operations&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">    <span class="keyword">for</span> (Value operand : op-&gt;<span class="built_in">getOperands</span>()) &#123;</span><br><span class="line">      Operation* operand_op = operand.<span class="built_in">getDefiningOp</span>();</span><br><span class="line">      <span class="comment">// 如果defining op在pattern里，则跳过</span></span><br><span class="line">      <span class="comment">// 否则加入到inputs中，表示是该潜在的fusion pattern的输入</span></span><br><span class="line">      <span class="keyword">if</span> (op_set.<span class="built_in">find</span>(operand_op) != op_set.<span class="built_in">end</span>()) &#123;</span><br><span class="line">        <span class="comment">// skip if defining op is in the pattern</span></span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (input_set.<span class="built_in">insert</span>(operand).second) &#123;</span><br><span class="line">        inputs.<span class="built_in">push_back</span>(operand);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> inputs;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 收集融合操作中所有被外部使用的输出，作为融合后的输出</span></span><br><span class="line"><span class="function">SmallVector&lt;Value, 4&gt; <span class="title">GetOutputsOfFusionPattern</span><span class="params">(<span class="type">const</span> FusionPattern&amp; pattern)</span> </span>&#123;</span><br><span class="line">  SmallVector&lt;Value, <span class="number">4</span>&gt; outputs;</span><br><span class="line">  DenseSet&lt;Operation*&gt; op_set;</span><br><span class="line">  <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">    <span class="comment">// 检查是否有重复的operation</span></span><br><span class="line">    <span class="type">bool</span> inserted = op_set.<span class="built_in">insert</span>(op).second;</span><br><span class="line">    (<span class="type">void</span>)inserted;</span><br><span class="line">    <span class="built_in">assert</span>(inserted &amp;&amp; <span class="string">&quot;FusionPattern contains duplicate operations&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 尝试做融合的operation</span></span><br><span class="line">  <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">    <span class="keyword">for</span> (Value result : op-&gt;<span class="built_in">getResults</span>()) &#123;</span><br><span class="line">      <span class="comment">// 判断该operation是否result有被外部使用</span></span><br><span class="line">      <span class="type">bool</span> has_external_user = llvm::<span class="built_in">any_of</span>(</span><br><span class="line">          result.<span class="built_in">getUses</span>(),</span><br><span class="line">          [&amp;](OpOperand&amp; use) &#123; <span class="keyword">return</span> !op_set.<span class="built_in">count</span>(use.<span class="built_in">getOwner</span>()); &#125;);</span><br><span class="line">      <span class="comment">// 显示收集被外部使用的output</span></span><br><span class="line">      <span class="keyword">if</span> (has_external_user) &#123;</span><br><span class="line">        outputs.<span class="built_in">push_back</span>(result);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> outputs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上述两个函数支持获取FusionPattern的外部输入和输出。</p>
</li>
<li><p>合并两个<code>FusionPattern</code>，这个函数比较重要，其实就是发现可以合并融合的operation list，扩大单个fusion region：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">FusionPattern <span class="title">MergeFusionPattern</span><span class="params">(<span class="type">const</span> FusionPattern&amp; lhs,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 <span class="type">const</span> FusionPattern&amp; rhs)</span> </span>&#123;</span><br><span class="line">  <span class="function">FusionPattern <span class="title">pattern</span><span class="params">(lhs)</span></span>;</span><br><span class="line">  pattern.<span class="built_in">insert</span>(pattern.<span class="built_in">end</span>(), rhs.<span class="built_in">begin</span>(), rhs.<span class="built_in">end</span>());</span><br><span class="line">  <span class="keyword">return</span> pattern;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>并查集用于做shape推导，<font color = red>注意，XLA的fusion中，shape 推导是比较简单的</font>:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ShapeConstraintAnalysis</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ShapeConstraintAnalysis</span><span class="params">(<span class="type">const</span> SmallVectorImpl&lt;Operation*&gt;&amp; op_list)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">PropagateEquality</span>(op_list);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Returns true is `lhs` and `rhs` are supposed to have same shape.</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">HasSameShape</span><span class="params">(Value lhs, Value rhs)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 单纯判断两者在unionfind中的位置是否相同</span></span><br><span class="line">    <span class="keyword">return</span> impl_.<span class="built_in">isEquivalent</span>(<span class="built_in">ValueWrapper</span>(lhs), <span class="built_in">ValueWrapper</span>(rhs));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// shape equality propagation based on the shape constrains of</span></span><br><span class="line">  <span class="comment">// elementwise ops.</span></span><br><span class="line">  <span class="comment">// 针对elementwise操作，做shape相等传播</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">PropagateEquality</span><span class="params">(<span class="type">const</span> SmallVectorImpl&lt;Operation*&gt;&amp; op_list)</span> </span>&#123;</span><br><span class="line">    <span class="type">bool</span> converged = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">      converged = <span class="literal">true</span>;</span><br><span class="line">      <span class="comment">// 显示对两个value做unionfind</span></span><br><span class="line">      <span class="keyword">auto</span> update = [&amp;](Value lhs, Value rhs) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!impl_.<span class="built_in">isEquivalent</span>(<span class="built_in">ValueWrapper</span>(lhs), <span class="built_in">ValueWrapper</span>(rhs))) &#123;</span><br><span class="line">          <span class="comment">// 有更改，说明还没有完全收敛</span></span><br><span class="line">          converged = <span class="literal">false</span>;</span><br><span class="line">          impl_.<span class="built_in">unionSets</span>(<span class="built_in">ValueWrapper</span>(lhs), <span class="built_in">ValueWrapper</span>(rhs));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;;</span><br><span class="line">      <span class="keyword">for</span> (Operation* op : op_list) &#123;</span><br><span class="line">        <span class="comment">// 只对有InferShapeEqualityOpInterface trait的operation做shape相等传播</span></span><br><span class="line">        <span class="keyword">auto</span> op_fusibility = <span class="built_in">dyn_cast</span>&lt;InferShapeEqualityOpInterface&gt;(op);</span><br><span class="line">        <span class="keyword">if</span> (!op_fusibility) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> numInput = op-&gt;<span class="built_in">getNumOperands</span>();</span><br><span class="line">        <span class="type">int</span> numOutput = op-&gt;<span class="built_in">getNumResults</span>();</span><br><span class="line">        <span class="comment">// shape equality propagation between inputs.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> input1 = <span class="number">0</span>; input1 &lt; numInput; ++input1)</span><br><span class="line">          <span class="keyword">for</span> (<span class="type">int</span> input2 = input1 + <span class="number">1</span>; input2 &lt; numInput; ++input2)</span><br><span class="line">            <span class="comment">// 通过op_fusibility.inferInputsShapeEquality函数判断两个input是否shape相等</span></span><br><span class="line">            <span class="keyword">if</span> (op_fusibility.<span class="built_in">inferInputsShapeEquality</span>(input1, input2))</span><br><span class="line">              <span class="built_in">update</span>(op-&gt;<span class="built_in">getOperand</span>(input1), op-&gt;<span class="built_in">getOperand</span>(input2));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// shape equality propagation between outputs.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> output1 = <span class="number">0</span>; output1 &lt; numOutput; ++output1)</span><br><span class="line">          <span class="keyword">for</span> (<span class="type">int</span> output2 = output1 + <span class="number">1</span>; output2 &lt; numOutput; ++output2)</span><br><span class="line">            <span class="comment">// 同理，判断两个output是否shape相等</span></span><br><span class="line">            <span class="keyword">if</span> (op_fusibility.<span class="built_in">inferOutputsShapeEquality</span>(output1, output2))</span><br><span class="line">              <span class="built_in">update</span>(op-&gt;<span class="built_in">getResult</span>(output1), op-&gt;<span class="built_in">getResult</span>(output2));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// shape equality propagation between input and output.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> input = <span class="number">0</span>; input &lt; numInput; ++input)</span><br><span class="line">          <span class="keyword">for</span> (<span class="type">int</span> output = <span class="number">0</span>; output &lt; numOutput; ++output)</span><br><span class="line">            <span class="comment">// 最关键的步骤，判断input和output是否shape相等</span></span><br><span class="line">            <span class="keyword">if</span> (op_fusibility.<span class="built_in">inferInputOutputShapeEquality</span>(input, output))</span><br><span class="line">              <span class="comment">// 如果相等，则调用lambda函数，将两者做unionfind</span></span><br><span class="line">              <span class="built_in">update</span>(op-&gt;<span class="built_in">getOperand</span>(input), op-&gt;<span class="built_in">getResult</span>(output));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> (!converged);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// a UnionFind set</span></span><br><span class="line">  <span class="comment">// 使用LLVM提供的内置UF集和</span></span><br><span class="line">  EquivalenceClasses&lt;ValueWrapper&gt; impl_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="planner的初始化"><a href="#planner的初始化" class="headerlink" title="planner的初始化"></a>planner的初始化</h4><p>FusionPlanner的初始化逻辑是比较简单的：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FusionPlanner</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">FusionPlanner</span><span class="params">(<span class="type">const</span> SmallVectorImpl&lt;Operation*&gt;&amp; op_list)</span></span></span><br><span class="line"><span class="function">      : op_list_(op_list),</span></span><br><span class="line"><span class="function">        shape_analysis_(op_list),</span></span><br><span class="line"><span class="function">        cycle_detector_(op_list.size()) &#123;</span></span><br><span class="line">    <span class="comment">// 构建初始的cluster图</span></span><br><span class="line">    <span class="built_in">BuildNodeMap</span>();</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>主要干了如下事情：</p>
<ol>
<li>初始化op_list_，用于后续的fusion</li>
<li>初始化shape_analysis_工具，用于知道fusion的shape compatible analysis</li>
<li>初始化cycle detector，<code>XLA</code>的fusion中，一个条件是不能引入loop</li>
</ol>
<p>最后构建一个nodemap，构建一个cluster图，用于后续子图生成，op遍历。</p>
<p>成员变量如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> SmallVectorImpl&lt;Operation*&gt;&amp; op_list_;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Shape equality checker</span></span><br><span class="line">ShapeConstraintAnalysis shape_analysis_;</span><br><span class="line"></span><br><span class="line"><span class="comment">// op -&gt; node_id</span></span><br><span class="line">std::unordered_map&lt;Operation*, <span class="type">int</span>&gt; op_to_node_id_;</span><br><span class="line"></span><br><span class="line"><span class="comment">// make sure not introduce cycle after fusion</span></span><br><span class="line">GraphCycles cycle_detector_;</span><br><span class="line">std::vector&lt;std::unique_ptr&lt;Cluster&gt;&gt; cluster_storage_;</span><br><span class="line"></span><br><span class="line"><span class="comment">// a UnionFind set. Each set represents a (partial) fused pattern</span></span><br><span class="line"><span class="comment">// and has a leader as representation.</span></span><br><span class="line">EquivalenceClasses&lt;<span class="type">int32_t</span>&gt; leader_for_node_;</span><br></pre></td></tr></table></figure>

<p>构建图的逻辑如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">BuildNodeMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 当前初始构建图，每个operation为一个node，为一个cluster的head，并leader_for_node_的并查集存储</span></span><br><span class="line">    <span class="type">int</span> num_nodes = op_list_.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> node_id = <span class="number">0</span>; node_id &lt; num_nodes; ++node_id) &#123;</span><br><span class="line">      <span class="comment">// 针对当前operation，构建一个cluster</span></span><br><span class="line">      <span class="comment">// 并设定当前op为cluster的头leader</span></span><br><span class="line">      Operation* op = op_list_[node_id];</span><br><span class="line">      <span class="built_in">MakeCluster</span>(node_id);</span><br><span class="line">      op_to_node_id_[op] = node_id;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// learder_for_node_是一个UnionFind set</span></span><br><span class="line">      leader_for_node_.<span class="built_in">insert</span>(node_id);</span><br><span class="line">      <span class="keyword">for</span> (Value operand : op-&gt;<span class="built_in">getOperands</span>()) &#123;</span><br><span class="line">        Operation* operand_op = operand.<span class="built_in">getDefiningOp</span>();</span><br><span class="line">        <span class="keyword">if</span> (operand_op == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">          <span class="comment">// skip block argument</span></span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 检查operand的def point是否属于别的融合组</span></span><br><span class="line">        <span class="comment">// 显示构建依赖关系</span></span><br><span class="line">        <span class="keyword">auto</span> iter = op_to_node_id_.<span class="built_in">find</span>(operand_op);</span><br><span class="line">        <span class="built_in">assert</span>(iter != op_to_node_id_.<span class="built_in">end</span>());</span><br><span class="line">        cycle_detector_.<span class="built_in">InsertEdge</span>(iter-&gt;second, node_id);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>遍历每一个op，在unionfind中，每一个op为一个cluster，后续fusion操作才会融合cluster。</li>
<li>初始化op_to_node_id_等的映射方式，unionfind中存储的是该op的node_id，即在当前fusionplan中的次序号。</li>
<li>operand的define op和当前op，在cycle_detector中显示插入依赖链条。</li>
</ul>
<p>上述整体逻辑是十分清楚的。</p>
<p>在FusionPlanner中，有一个私有类是<code>Cluster</code>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Represent a (partial) fused pattern</span></span><br><span class="line">  <span class="comment">// 根据注释，这个cluster类并不是完整的融合模式，而是一个融合模式的一部分</span></span><br><span class="line">  <span class="comment">// 这是unionfind的思想，每个cluster都是一个融合模式的一部分，最终通过unionfind合并</span></span><br><span class="line">  <span class="keyword">class</span> <span class="title class_">Cluster</span> &#123;</span><br><span class="line">   <span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Cluster</span>(<span class="type">int</span> node_id, FusionPlanner* planner) : <span class="built_in">node_id_</span>(node_id) &#123;</span><br><span class="line">      <span class="type">const</span> SmallVectorImpl&lt;Operation*&gt;&amp; op_list = planner-&gt;<span class="built_in">op_list</span>();</span><br><span class="line">      pattern_.<span class="built_in">push_back</span>(op_list[node_id]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Merges `other` into this cluster, and clears `other`.</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Merge</span><span class="params">(Cluster* other)</span> </span>&#123;</span><br><span class="line">      pattern_.<span class="built_in">insert</span>(pattern_.<span class="built_in">end</span>(), other-&gt;pattern_.<span class="built_in">begin</span>(),</span><br><span class="line">                      other-&gt;pattern_.<span class="built_in">end</span>());</span><br><span class="line">      other-&gt;pattern_.<span class="built_in">clear</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The number of nodes in this cluster.</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">cluster_size</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> pattern_.<span class="built_in">size</span>(); &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The ID of the cluster as represented in `cycle_detector_`.</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">cycles_graph_node_id</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> node_id_; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Sets the ID of the cluster as represented in `cycle_detector_`.</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">set_cycles_graph_node_id</span><span class="params">(<span class="type">int</span> cycles_graph_node_id)</span> </span>&#123;</span><br><span class="line">      node_id_ = cycles_graph_node_id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Currently the fused pattern this cluster holds.</span></span><br><span class="line">    <span class="function"><span class="type">const</span> FusionPattern&amp; <span class="title">fused_pattern</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> pattern_; &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// ID of the representative node of this cluster.</span></span><br><span class="line">    <span class="type">int</span> node_id_;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the fused pattern this cluster holds.</span></span><br><span class="line">    FusionPattern pattern_;</span><br><span class="line">  &#125;;</span><br></pre></td></tr></table></figure>

<p>上述cluster最主要的功能，就是可以对于cluster中的operation，显示记录他们可以应用的<code>FusionPattern</code>。同时还支持merge操作，将cluster之间进行fusion。该原理是将另一个cluster的pattern拷贝入当前cluster，并清空另一个cluster的pattern。</p>
<p><img src="/images/2.png" alt="2"></p>
<h4 id="planner运行"><a href="#planner运行" class="headerlink" title="planner运行"></a>planner运行</h4><p>核心部分，主要作用是构建cluster融合，并给对应cluster赋予fusion pattern。</p>
<p>主函数如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Returns a fusion plan if success, otherwise none.</span></span><br><span class="line">  <span class="comment">// 返回一个fusion plan，如果没有找到则返回none</span></span><br><span class="line">  <span class="function">llvm::Optional&lt;FusionPlan&gt; <span class="title">Run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Greedily search connected fusible pattern, and ops belonging to</span></span><br><span class="line">    <span class="comment">// a same fusion pattern are grouped into a cluster.</span></span><br><span class="line">    <span class="comment">// 每一个op有一个可融合的pattern，找寻compatible的pattern并合并对应的operation</span></span><br><span class="line">    <span class="built_in">RunEdgeContractionLoop</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// After doing edge contraction, each unique cluster having size</span></span><br><span class="line">    <span class="comment">// more than one represents a potential fusion pattern.</span></span><br><span class="line">    <span class="comment">// We collect all these clusters and construct a fusion plan.</span></span><br><span class="line">    <span class="comment">// union find中，每一个有大于1的size的cluster都是一个融合模式</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Note that the ops in a fusion pattern are in topological ordering.</span></span><br><span class="line">    <span class="comment">// fusion pattern中的operation是按照拓扑排序的</span></span><br><span class="line">    <span class="comment">// 得到一个fusion plan集合后，后续apply这些fusion plan即可</span></span><br><span class="line">    FusionPlan plan;</span><br><span class="line">    DenseMap&lt;<span class="type">int</span>, <span class="type">int</span>&gt; pattern_ids;</span><br><span class="line">    <span class="keyword">for</span> (Operation* op : op_list_) &#123;</span><br><span class="line">      <span class="comment">// 获取该op所属的cluster</span></span><br><span class="line">      Cluster* cluster = <span class="built_in">GetClusterForNode</span>(op);</span><br><span class="line">      <span class="type">int</span> node_id = cluster-&gt;<span class="built_in">cycles_graph_node_id</span>();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 不可融合或是融合模式的size小于等于1，跳过</span></span><br><span class="line">      <span class="keyword">if</span> (!<span class="built_in">IsFusible</span>(op_list_[node_id]) ||</span><br><span class="line">          <span class="built_in">EffectiveSize</span>(<span class="built_in">GetClusterForNode</span>(op)-&gt;<span class="built_in">fused_pattern</span>()) &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (!pattern_ids.<span class="built_in">count</span>(node_id)) &#123;</span><br><span class="line">        <span class="type">int</span> pattern_id = pattern_ids.<span class="built_in">size</span>();</span><br><span class="line">        pattern_ids[node_id] = pattern_id;</span><br><span class="line">        plan.<span class="built_in">emplace_back</span>();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 特定的plan后添加operation</span></span><br><span class="line">      plan[pattern_ids[node_id]].<span class="built_in">push_back</span>(op);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> plan;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这里需要理解一个重要的点：每一个cluster都有一个list，该list存储所有的fusion Pattern，一个cluster是否可以做融合，其实就是看发现了多少个fusion Pattern。</p>
<ul>
<li>如果fusion pattern &gt; 1，则其<strong>内部可以融合</strong>。</li>
<li>如果cluster之间有兼容的fusion pattern，则<strong>intra cluster 融合</strong>是ok的。</li>
</ul>
<p><font color =red>识别出潜在的fusion后，构造fusion plan：一个fusion pattern的vector存储结构。</font></p>
</blockquote>
<p>上述code可以分为两大阶段：<code>RunEdgeContractionLoop()</code>和融合pattern收集。</p>
<p><img src="/images/1.png" alt="1"></p>
<p>上述是一个完整的流程图。可以看出，run()函数最重要的function是<code>RunEdgeContractionLoop()</code>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Greedily fuse connected node.</span></span><br><span class="line"><span class="comment">// 贪心算法，融合可融合的node</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">RunEdgeContractionLoop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">using</span> std::placeholders::_1;</span><br><span class="line">    <span class="keyword">using</span> std::placeholders::_2;</span><br><span class="line">    <span class="comment">// 理解std::bind操作</span></span><br><span class="line">    <span class="comment">// 给TryToContractEdge函数绑定了两个参数，第一个参数是this指针，第二个参数是_1和_2，是占位符</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">ForEachEdgeInPostOrder</span>(</span><br><span class="line">        std::<span class="built_in">bind</span>(&amp;FusionPlanner::TryToContractEdge, <span class="keyword">this</span>, _1, _2));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对于graph做后序遍历，并<strong>贪心引用边收缩算法</strong>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 按照后序遍历的顺序，对每一个edge执行fn函数</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> FnTy&gt;</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">ForEachEdgeInPostOrder</span><span class="params">(FnTy fn)</span> </span>&#123;</span><br><span class="line"><span class="type">bool</span> changed = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int32_t</span> node : cycle_detector_.<span class="built_in">AllNodesInPostOrder</span>()) &#123;</span><br><span class="line">  Cluster* cluster_from = <span class="built_in">GetClusterForCyclesGraphNode</span>(node);</span><br><span class="line">  <span class="comment">// Make a copy of the set of successors because we may modify the graph in</span></span><br><span class="line">  <span class="comment">// TryToContractEdge.</span></span><br><span class="line">  <span class="comment">// 可能在TryToContractEdge函数中修改后续的node，所以这里需要拷贝一份</span></span><br><span class="line">  std::vector&lt;<span class="type">int32_t</span>&gt; successors_copy =</span><br><span class="line">      cycle_detector_.<span class="built_in">SuccessorsCopy</span>(cluster_from-&gt;<span class="built_in">cycles_graph_node_id</span>());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 对该节点的后续分别尝试做融合</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> to : successors_copy) &#123;</span><br><span class="line">    Cluster* cluster_to = <span class="built_in">GetClusterForCyclesGraphNode</span>(to);</span><br><span class="line">    <span class="comment">// 这里传入的fn是TryToContractEdge函数，传入cluster_from和cluster_to两个参数，通过std::bind绑定。</span></span><br><span class="line">    <span class="type">bool</span> contracted_edge = <span class="built_in">fn</span>(cluster_from, cluster_to);</span><br><span class="line">    changed |= contracted_edge;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> changed;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该逻辑是，后续访问每个node，并尝试对后续的每个op尝试引用fn函数，即<code>TryToContractEdge</code>函数。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// This function check if fusing `from` with `to` is valid and if so perform</span></span><br><span class="line"><span class="comment">// the merge. The validity is based on the operations in the clusters and</span></span><br><span class="line"><span class="comment">// the compatibility of the shapes of the outputs of the would-be fused</span></span><br><span class="line"><span class="comment">// clusters.</span></span><br><span class="line"><span class="comment">// Returns true is the merge was performed.</span></span><br><span class="line"><span class="comment">// 尝试合并两个cluster，如果合并成功则返回true</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">TryToContractEdge</span><span class="params">(Cluster* from, Cluster* to)</span> </span>&#123;</span><br><span class="line"><span class="type">int</span> node_to = to-&gt;<span class="built_in">cycles_graph_node_id</span>();</span><br><span class="line"><span class="type">int</span> node_from = from-&gt;<span class="built_in">cycles_graph_node_id</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Both node_to and node_from should be fusible</span></span><br><span class="line"><span class="keyword">if</span> (!<span class="built_in">IsFusible</span>(op_list_[node_to]) || !<span class="built_in">IsFusible</span>(op_list_[node_from])) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判断node from是否可以和consumer融合</span></span><br><span class="line"><span class="comment">// 即该node是否是const或是elementwise</span></span><br><span class="line"><span class="keyword">if</span> (!<span class="built_in">IsFusibleWithConsumer</span>(op_list_[node_from])) &#123;</span><br><span class="line">  <span class="comment">// This op cannot be fused with its consumers.</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判断node to是否可以和operand融合</span></span><br><span class="line"><span class="comment">// 即该node是否是element wise或是const或是reduce</span></span><br><span class="line"><span class="keyword">if</span> (!<span class="built_in">IsFusibleWithOperand</span>(op_list_[node_to])) &#123;</span><br><span class="line">  <span class="comment">// This op cannot be fused with its operands.</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Output shapes of a fusion pattern should be compatible as described in</span></span><br><span class="line"><span class="comment">// the document of this class.</span></span><br><span class="line"><span class="comment">// 判断两个cluster的输出是否shape相同</span></span><br><span class="line">SmallVector&lt;Value, <span class="number">4</span>&gt; results = <span class="built_in">GetResultsOfFusedPattern</span>(from, to);</span><br><span class="line"></span><br><span class="line">Value ref = <span class="built_in">InferEffectiveWorkloadShape</span>(results[<span class="number">0</span>]);</span><br><span class="line"><span class="keyword">if</span> (!llvm::<span class="built_in">all_of</span>(results, [&amp;](Value result) &#123;</span><br><span class="line">      Value val = <span class="built_in">InferEffectiveWorkloadShape</span>(result);</span><br><span class="line">      <span class="keyword">return</span> shape_analysis_.<span class="built_in">HasSameShape</span>(ref, val);</span><br><span class="line">    &#125;)) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实际的fusion操作，将cluster做fusion</span></span><br><span class="line"><span class="keyword">return</span> <span class="built_in">MergeClusters</span>(from, to);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意，如果op是reduceOp，则其只能是to，不能是from，所以<code>reduceOp</code>一定在sub graph的end point。</p>
<ul>
<li><p>判断from和to是否可fuse：isfusable()</p>
</li>
<li><p><code>GetResultsOfFusedPattern</code>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// returns the outputs if two cluster were merged</span></span><br><span class="line"><span class="function">SmallVector&lt;Value, 4&gt; <span class="title">GetResultsOfFusedPattern</span><span class="params">(Cluster* from, Cluster* to)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 将两个cluster的fused_pattern合并</span></span><br><span class="line">FusionPattern fused_pattern =</span><br><span class="line">    <span class="built_in">MergeFusionPattern</span>(from-&gt;<span class="built_in">fused_pattern</span>(), to-&gt;<span class="built_in">fused_pattern</span>());</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">GetOutputsOfFusionPattern</span>(fused_pattern);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>尝试强行融合两个cluster的pattern，并获取一个fusion厚的output。</p>
</li>
<li><p>显示做shape 判断，来判断前一步的fusion是否是合法的：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Value ref = <span class="built_in">InferEffectiveWorkloadShape</span>(results[<span class="number">0</span>]);</span><br><span class="line"><span class="keyword">if</span> (!llvm::<span class="built_in">all_of</span>(results, [&amp;](Value result) &#123;</span><br><span class="line">      Value val = <span class="built_in">InferEffectiveWorkloadShape</span>(result);</span><br><span class="line">      <span class="keyword">return</span> shape_analysis_.<span class="built_in">HasSameShape</span>(ref, val);</span><br><span class="line">    &#125;)) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个inferworkload逻辑如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 根据value的类型，判断workload的shape的推导方式</span></span><br><span class="line"><span class="comment">// 主要针对reduce op做特殊化处理</span></span><br><span class="line"><span class="function">Value <span class="title">InferEffectiveWorkloadShape</span><span class="params">(Value v)</span> </span>&#123;</span><br><span class="line">  Operation* op = v.<span class="built_in">getDefiningOp</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 如果是reduce op，则返回operand的shape</span></span><br><span class="line">  <span class="comment">// 否则，v本身用于推导shape</span></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">isa_and_nonnull</span>&lt;ReduceOp&gt;(op) ? op-&gt;<span class="built_in">getOperand</span>(<span class="number">0</span>) : v;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>取融合后第一个输出的“有效工作负载形状”作为参考。</p>
</li>
<li><p>对普通操作，有效形状即输出本身的形状；对 <code>ReduceOp</code>，有效形状是操作数的形状（因为融合需基于其输入数据的形状）。</p>
</li>
<li><p>对融合后的所有输出结果，逐一检查它们的有效形状是否与参考形状一致。</p>
</li>
<li><p>若存在任意一个输出形状不匹配，返回 <code>false</code>，拒绝合并。</p>
</li>
</ul>
<p>这背后的原理如下:</p>
<blockquote>
<p><strong>kLoop 融合</strong>：要求所有输出形状一致，以放入同一并行循环。</p>
<p><strong>kInput 融合</strong>：</p>
<p>允许包含 <code>ReduceOp</code>，但其有效形状需与其他输出的有效形状一致（即 <code>ReduceOp</code> 的输入形状需与其他输出形状一致）。例如，若融合模式包含一个reduceOp和elementwiseOp，做如下操作：</p>
<ol>
<li><p><code>ReduceOp</code> 的有效形状是其输入（操作数）的形状。</p>
</li>
<li><p><code>ElementWise</code> 的有效形状是其输出的形状。</p>
</li>
<li><p>两者必须相同才能融合。</p>
</li>
</ol>
</blockquote>
</li>
</ul>
<p><img src="/images/3.png" alt="3"></p>
<h4 id="ApplyFusionPlan"><a href="#ApplyFusionPlan" class="headerlink" title="ApplyFusionPlan"></a>ApplyFusionPlan</h4><p>源码如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">ApplyFusionPlan</span><span class="params">(<span class="type">const</span> FusionPlan&amp; plan)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 遍历每个融合模式</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> FusionPattern&amp; pattern : plan) &#123;</span><br><span class="line">        <span class="comment">// 在pattern最后一个操作位置创建Builder</span></span><br><span class="line">        <span class="function">OpBuilder <span class="title">b</span><span class="params">(pattern.back())</span></span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 收集所有操作的位置信息</span></span><br><span class="line">        SmallVector&lt;Location, <span class="number">4</span>&gt; locations;</span><br><span class="line">        locations.<span class="built_in">reserve</span>(pattern.<span class="built_in">size</span>());</span><br><span class="line">        <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">            locations.<span class="built_in">push_back</span>(op-&gt;<span class="built_in">getLoc</span>());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 创建融合位置标识（用于调试）</span></span><br><span class="line">        Location fused_loc = FusedLoc::<span class="built_in">get</span>(pattern.<span class="built_in">back</span>()-&gt;<span class="built_in">getContext</span>(), locations);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取外部输入和输出</span></span><br><span class="line">        SmallVector&lt;Value, <span class="number">4</span>&gt; inputs = <span class="built_in">GetInputsOfFusionPattern</span>(pattern);</span><br><span class="line">        SmallVector&lt;Value, <span class="number">4</span>&gt; outputs = <span class="built_in">GetOutputsOfFusionPattern</span>(pattern);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 构建输出类型列表</span></span><br><span class="line">        SmallVector&lt;Type, <span class="number">4</span>&gt; output_types;</span><br><span class="line">        output_types.<span class="built_in">reserve</span>(outputs.<span class="built_in">size</span>());</span><br><span class="line">        <span class="keyword">for</span> (Value v : outputs) &#123;</span><br><span class="line">            output_types.<span class="built_in">push_back</span>(v.<span class="built_in">getType</span>());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 消费者调整阶段 */</span></span><br><span class="line">        <span class="comment">// 记录融合操作集合</span></span><br><span class="line">        <span class="function">DenseSet&lt;Operation*&gt; <span class="title">fused_set</span><span class="params">(pattern.begin(), pattern.end())</span></span>;</span><br><span class="line">        DenseSet&lt;Operation*&gt; consumers_set;  <span class="comment">// 已处理的消费者</span></span><br><span class="line">        SmallVector&lt;Operation*, <span class="number">4</span>&gt; consumers_vec; <span class="comment">// 待移动的消费者</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 确定原始代码范围：第一个融合操作到最后一个的迭代器范围</span></span><br><span class="line">        <span class="keyword">auto</span> first_iter = pattern.<span class="built_in">front</span>()-&gt;<span class="built_in">getIterator</span>();</span><br><span class="line">        <span class="keyword">auto</span> last_iter = pattern.<span class="built_in">back</span>()-&gt;<span class="built_in">getIterator</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 扫描区间内的所有操作</span></span><br><span class="line">        <span class="keyword">for</span> (Operation&amp; cur_op : llvm::<span class="built_in">make_range</span>(first_iter, last_iter)) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!fused_set.<span class="built_in">contains</span>(&amp;cur_op)) &#123; <span class="comment">// 非融合操作</span></span><br><span class="line">                <span class="comment">// 检查是否是消费者：操作数来自融合集或已标记的消费者</span></span><br><span class="line">                <span class="type">bool</span> is_consumer = llvm::<span class="built_in">any_of</span>(cur_op.<span class="built_in">getOperands</span>(), </span><br><span class="line">                    [&amp;](Value v) &#123;</span><br><span class="line">                        Operation* def_op = v.<span class="built_in">getDefiningOp</span>();</span><br><span class="line">                        <span class="keyword">return</span> fused_set.<span class="built_in">contains</span>(def_op) || consumers_set.<span class="built_in">contains</span>(def_op);</span><br><span class="line">                    &#125;);</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> (is_consumer) &#123;</span><br><span class="line">                    consumers_set.<span class="built_in">insert</span>(&amp;cur_op); <span class="comment">// 标记为已处理</span></span><br><span class="line">                    consumers_vec.<span class="built_in">push_back</span>(&amp;cur_op); <span class="comment">// 加入移动队列</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 逆序移动消费者到融合点之后（防止顺序移动导致迭代器失效）</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span>* op : llvm::<span class="built_in">reverse</span>(consumers_vec)) &#123;</span><br><span class="line">            op-&gt;<span class="built_in">moveAfter</span>(pattern.<span class="built_in">back</span>()); <span class="comment">// 重定位到融合操作末尾</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 创建融合操作 */</span></span><br><span class="line">        FusionOp fusion = b.<span class="built_in">create</span>&lt;mhlo::FusionOp&gt;(fused_loc, output_types, inputs);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 构建融合计算区域</span></span><br><span class="line">        Region&amp; region = fusion.<span class="built_in">fused_computation</span>();</span><br><span class="line">        region.<span class="built_in">push_back</span>(<span class="keyword">new</span> Block); <span class="comment">// 创建基本块</span></span><br><span class="line">        Block&amp; block = region.<span class="built_in">front</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 将原始操作移入融合区域</span></span><br><span class="line">        <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">            op-&gt;<span class="built_in">moveBefore</span>(&amp;block, block.<span class="built_in">end</span>()); <span class="comment">// 保持原有顺序</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 在区域末尾插入ReturnOp</span></span><br><span class="line">        b.<span class="built_in">setInsertionPoint</span>(&amp;block, block.<span class="built_in">end</span>());</span><br><span class="line">        b.<span class="built_in">create</span>&lt;mhlo::ReturnOp&gt;(fused_loc, outputs);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 结果替换阶段 */</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> [output, fusion_result] : llvm::<span class="built_in">zip</span>(outputs, fusion.<span class="built_in">getResults</span>())) &#123;</span><br><span class="line">            <span class="comment">// 替换所有外部使用点</span></span><br><span class="line">            <span class="keyword">for</span> (OpOperand&amp; use : llvm::<span class="built_in">make_early_inc_range</span>(output.<span class="built_in">getUses</span>())) &#123;</span><br><span class="line">                <span class="keyword">if</span> (use.<span class="built_in">getOwner</span>()-&gt;<span class="built_in">getBlock</span>() != &amp;block) &#123; <span class="comment">// 外部使用</span></span><br><span class="line">                    use.<span class="built_in">set</span>(fusion_result); <span class="comment">// 替换为融合结果</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如下是<code>ApplyFusionPlan</code>的流程图</p>
<p><img src="/images/4.png" alt="4"></p>
<p>其中比较核心的是识别消费者操作，该consumer要求是直接或间接依赖fusion里的operation，但本身并不是fusion operation，并且其location在fusionOp的范围内，<strong>因此需要显示地移动</strong>。</p>
<p><img src="/images/4-1743436524621-10.png" alt="4"></p>
<h2 id="BladeDISC-source-code分析"><a href="#BladeDISC-source-code分析" class="headerlink" title="BladeDISC source code分析"></a><font color = brown>BladeDISC source code分析</font></h2><p><code>BladeDISC</code>的kernel 融合主要参考<code>AStitch</code>和<a target="_blank" rel="noopener" href="http://arxiv.org/abs/2009.10924">titch fusion</a>。</p>
<img src="/images/image-20250326111430445.png" alt="4" style="zoom:67%;" />

<p>上述很好地阐述了应用XLA和fusion stitich技术的差异。<font color = red>XLA编译器无法对middle reduce操作做fusion</font>，fusion stitch划分四类memory intensive op融合方式，起到有效扩展作用：</p>
<img src="/images/image-20250326114004653.png" style="zoom:67%;" />

<h3 id="Source-code解读"><a href="#Source-code解读" class="headerlink" title="Source code解读"></a><font color = green>Source code解读</font></h3><p>一个总的框架：</p>
<img src="/images/image-20250327221745561.png" style="zoom:67%;" />

<p>上述详情参考<a target="_blank" rel="noopener" href="http://arxiv.org/abs/2009.10924">BladeDISC slide</a>。</p>
<h4 id="节点类型划分"><a href="#节点类型划分" class="headerlink" title="节点类型划分"></a>节点类型划分</h4><p>stich的fusion pattern中，相比xla，其重点是将node划分为不同的类：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Represents a list of lmhlo ops that are going to be fused.</span></span><br><span class="line"><span class="comment">// Concepts for a fusion pattern:</span></span><br><span class="line"><span class="comment">//   - Root op: the op whose output is the fusion-pattern&#x27;s output.</span></span><br><span class="line"><span class="comment">//     Sub-root op可以理解为stich fusion的缝合点，为用shared-memory缝合的op bound</span></span><br><span class="line"><span class="comment">//   - Sub-root op: the op whose output is to be maintained on shared-memory for</span></span><br><span class="line"><span class="comment">//     kStitch fusion. Currently, we only support row-reduction to be a sub-root</span></span><br><span class="line"><span class="comment">//     op.</span></span><br><span class="line"><span class="comment">//   - Regular xroot op: either a root op or a sub-root op, for whose operands</span></span><br><span class="line"><span class="comment">//     we successfully build tile information during kStitch fusion-pattern init</span></span><br><span class="line"><span class="comment">//     phase.</span></span><br><span class="line"><span class="comment">//   - Irregular xroot op: an root op for whose operands we fail to build tile</span></span><br><span class="line"><span class="comment">//     information durint kStitch fusion-pattern init phase.</span></span><br><span class="line"><span class="comment">//   - Skeleton op: the op who will be used to build the loop skeleton when</span></span><br><span class="line"><span class="comment">//     lowering a kStitch fusion to parallel loops. Currently, sub-root ops, and</span></span><br><span class="line"><span class="comment">//     regular xroot ops who generate external only results, are skeleton ops.</span></span><br><span class="line"><span class="comment">//     Other xroot ops are lowered with input-inline fusion phase.</span></span><br><span class="line"><span class="comment">//   Note: for an regular xroot op which is not an skeleton op, the output data</span></span><br><span class="line"><span class="comment">//     to be written should be coverred by its corresponding skeleton op.</span></span><br><span class="line"><span class="comment">//     Otherwise, this xroot are regared as irregular.</span></span><br></pre></td></tr></table></figure>

<p>上述注释中详细解读了node的分类：</p>
<ul>
<li>Root op：<code>fusion-pattern</code>的output node，即fusion的边界。</li>
<li>Sub-root op：通过shared-memory fuse的op。</li>
<li>xroot op：在astich论文中，每个op的thread感知分配信息，都是通过分析sub-root或是root，然后反向传播到整个fusion区域。xroot op是分析出thread信息的root或sub-root</li>
<li>Irregular xroot：没有分析出thread信息的sub root或是root op。</li>
<li>Skeleton op：负责构建<strong>动态shape的并行循环骨架</strong>，是GPU kernel代码生成的模板基础。通过选择具有典型计算特征的子根操作（如行归约）作为骨架，能够自动推导出循环维度、分块策略等关键参数。主要负责<strong>codegen</strong>部分。</li>
</ul>
<h4 id="Shape-analysis"><a href="#Shape-analysis" class="headerlink" title="Shape analysis"></a>Shape analysis</h4><h4 id="GPU-Stitch策略"><a href="#GPU-Stitch策略" class="headerlink" title="GPU Stitch策略"></a>GPU Stitch策略</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 重点关注如何将stitch技术用在gpu上</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StitchGpuFusionStrategy</span> : <span class="keyword">public</span> FusionStrategy &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">StitchGpuFusionStrategy</span>(<span class="type">const</span> FusionOptions&amp; options)</span><br><span class="line">      : <span class="built_in">FusionStrategy</span>(options) &#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">isFusible</span><span class="params">(Operation* op)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">tryFuse</span><span class="params">(ShapeAnalysis&amp; shapeAnalysis, FusionPattern&amp; lhs,</span></span></span><br><span class="line"><span class="params"><span class="function">                       FusionPattern&amp; rhs, FusionPattern&amp; target)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">initFusionPattern</span><span class="params">(ShapeAnalysis&amp; shapeAnalysis,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 FusionPattern&amp; fusion_pattern)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> StringRef <span class="title">getName</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;StitchGpuFusionStrategy&quot;</span>; &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Value <span class="title">getEffectiveShape</span><span class="params">(FusionPattern&amp; target, Value value)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">tileCoverInfoPropagateO2I</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      ShapeAnalysis&amp; shapeAnalysis, DenseMap&lt;Value, TileInfo&gt;&amp; tile_plan,</span></span></span><br><span class="line"><span class="params"><span class="function">      Operation* op, SmallVector&lt;std::pair&lt;Value, TileInfo&gt;, <span class="number">4</span>&gt;&amp; in_info,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">bool</span>&amp; cover)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">findFusionPatternTypeAndSubroot</span><span class="params">(ShapeAnalysis&amp; shapeAnalysis,</span></span></span><br><span class="line"><span class="params"><span class="function">                                       FusionPattern&amp; fusion_pattern)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">tileXroots</span><span class="params">(ShapeAnalysis&amp; shapeAnalysis, FusionPattern&amp; fusion_pattern)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">backtraceTileAndCover</span><span class="params">(ShapeAnalysis&amp; shapeAnalysis,</span></span></span><br><span class="line"><span class="params"><span class="function">                             FusionPattern&amp; fusion_pattern, Value value)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>整体的流程框架如下：</p>
<p><img src="/images/6.png" alt="6"></p>
<p>上述流程图很好的表达了整个流程框架：</p>
<ul>
<li><p><code>initFusionPatter</code>负责初始化fusion的option信息</p>
</li>
<li><p><code>findFusionPatternTypeAndSubroot</code>负责引用fusion，找寻subroot等特殊节点，其整体逻辑如下：</p>
<p><img src="/images/7.png" alt="7"></p>
</li>
<li><p><code>tileXroots</code>针对sub root做线程分配算法</p>
<p><img src="/images/8.png" alt="8"></p>
</li>
<li><p><code>backtraceTileAndCover</code>在一个fusion中，从不同sub root出发，做反向thread分配推导</p>
<p><img src="/images/9.png" alt="9"></p>
</li>
</ul>
<p>对应论文中的图片：</p>
<p><img src="/images/image-20250327184033247.png" alt="image-20250327184033247"></p>
<p>上述source code和论文中的对应描述参考论文中的chapter4.3的steps。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/" rel="tag"># 机器学习编译器</a>
              <a href="/tags/mlir/" rel="tag"># mlir</a>
              <a href="/tags/%E7%AE%97%E5%AD%90%E8%9E%8D%E5%90%88%E6%8A%80%E6%9C%AF/" rel="tag"># 算子融合技术</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/03/31/%E8%AE%A1%E7%AE%97%E5%AF%86%E9%9B%86%E7%AE%97%E5%AD%90%E8%9E%8D%E5%90%88/" rel="prev" title="计算密集算子融合">
      <i class="fa fa-chevron-left"></i> 计算密集算子融合
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/04/01/BladeDISC%E5%88%9D%E6%8E%A2/" rel="next" title="BladeDISC初探">
      BladeDISC初探 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#XLA%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90"><span class="nav-number">1.</span> <span class="nav-text">XLA代码解析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Source-Code%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90"><span class="nav-number">1.1.</span> <span class="nav-text">Source Code源码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="nav-number">1.1.1.</span> <span class="nav-text">基础知识</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#planner%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="nav-number">1.1.2.</span> <span class="nav-text">planner的初始化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#planner%E8%BF%90%E8%A1%8C"><span class="nav-number">1.1.3.</span> <span class="nav-text">planner运行</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ApplyFusionPlan"><span class="nav-number">1.1.4.</span> <span class="nav-text">ApplyFusionPlan</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BladeDISC-source-code%E5%88%86%E6%9E%90"><span class="nav-number">2.</span> <span class="nav-text">BladeDISC source code分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Source-code%E8%A7%A3%E8%AF%BB"><span class="nav-number">2.1.</span> <span class="nav-text">Source code解读</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%8A%82%E7%82%B9%E7%B1%BB%E5%9E%8B%E5%88%92%E5%88%86"><span class="nav-number">2.1.1.</span> <span class="nav-text">节点类型划分</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Shape-analysis"><span class="nav-number">2.1.2.</span> <span class="nav-text">Shape analysis</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#GPU-Stitch%E7%AD%96%E7%95%A5"><span class="nav-number">2.1.3.</span> <span class="nav-text">GPU Stitch策略</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Leon Dou</p>
  <div class="site-description" itemprop="description">关注领域：体系结构，编译技术</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leon Dou</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">331k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">5:01</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : 'Ov23liFsw1lTgh0R8s8H',
      clientSecret: '1f947cb0d107ba1ffbcad8c25688c075224fff36',
      repo        : 'micropuma.github.io',
      owner       : 'micropuma',
      admin       : ['micropuma'],
      id          : '9daf8c9f26c526a42bc2b314a962c955',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>
</body>
</html>
