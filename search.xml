<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Allo项目初探</title>
    <url>/2025/03/29/Allo%E9%A1%B9%E7%9B%AE%E5%88%9D%E6%8E%A2/</url>
    <content><![CDATA[<p><img src="/images/image-20250330205827771.png" alt="image-20250330205827771"></p>
<span id="more"></span>
<h2 id="项目构建"><a href="#项目构建" class="headerlink" title="项目构建"></a><font color = brown>项目构建</font></h2><p>主要参考<a href="https://cornell-zhang.github.io/allo/setup/index.html">Allo doc</a>的set up章节，这里我选择源码构建的方式。项目构建流程如下：</p>
<ol>
<li><p>clone项目</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone --recursive git@github.com:micropuma/allo.git</span><br></pre></td></tr></table></figure>
</li>
<li><p>构建llvm子项目</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd allo/externals/llvm-project</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Apply our patch</span></span><br><span class="line">git apply ../llvm_patch</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Python 3.12 is required</span></span><br><span class="line">mkdir -p build</span><br></pre></td></tr></table></figure>
<p>由于需要python bind11，以及后续需要pip install很多python库，因此这里推荐用conda创建虚拟环境：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda create -n allo python=3.12         # python版本一定是3.12</span><br><span class="line">conda activate allo</span><br><span class="line">pip install pybind11</span><br></pre></td></tr></table></figure>
<p>编写shell脚本，一键构建llvm：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd build</span><br><span class="line">cmake -G Ninja ../llvm \</span><br><span class="line">    -DLLVM_ENABLE_PROJECTS=&quot;clang;mlir;openmp&quot; \</span><br><span class="line">    -DLLVM_BUILD_EXAMPLES=ON \</span><br><span class="line">    -DLLVM_TARGETS_TO_BUILD=&quot;host&quot; \</span><br><span class="line">    -DCMAKE_BUILD_TYPE=Release \</span><br><span class="line">    -DLLVM_ENABLE_ASSERTIONS=ON \</span><br><span class="line">    -DLLVM_INSTALL_UTILS=ON \</span><br><span class="line">    -DMLIR_ENABLE_BINDINGS_PYTHON=ON \</span><br><span class="line">    -DPython3_EXECUTABLE=`which python3`</span><br><span class="line">ninja -j $(nproc)</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">export</span> environment variable</span></span><br><span class="line">export LLVM_BUILD_DIR=$(pwd)</span><br></pre></td></tr></table></figure>
</li>
<li><p>构建Allo项目，首先回退到项目根目录，运行如下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python3 -m pip install -v -e . -i https://pypi.tuna.tsinghua.edu.cn/simple  # 建议用清华镜像，否则容易拉取失败</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Allo项目使用"><a href="#Allo项目使用" class="headerlink" title="Allo项目使用"></a><font color = brown>Allo项目使用</font></h2><h3 id="Pytorch集成例子"><a href="#Pytorch集成例子" class="headerlink" title="Pytorch集成例子"></a><font color = green>Pytorch集成例子</font></h3><p>Allo项目除了使用ADL（加速定义语言）来描述计算任务外，也可以集成在pytorch中使用。具体参考<a href="https://cornell-zhang.github.io/allo/dive/pytorch.html">allo pytorch集成例子</a>。</p>
<p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, <span class="variable language_">self</span>).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        x = x + y</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> allo</span><br><span class="line">example_inputs = [torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">10</span>, <span class="number">10</span>), torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">10</span>, <span class="number">10</span>)]</span><br><span class="line">llvm_mod = allo.frontend.from_pytorch(model, example_inputs=example_inputs)</span><br><span class="line"></span><br><span class="line">golden = model(*example_inputs)</span><br><span class="line">np_inputs = [x.detach().numpy() <span class="keyword">for</span> x <span class="keyword">in</span> example_inputs]</span><br><span class="line">res = llvm_mod(*np_inputs)</span><br><span class="line">torch.testing.assert_close(res, golden.detach().numpy())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Passed!&quot;</span>)</span><br><span class="line"></span><br><span class="line">mod = allo.frontend.from_pytorch(model, example_inputs=example_inputs, target=<span class="string">&quot;vhls&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(mod.hls_code)</span><br></pre></td></tr></table></figure>
<p>执行如下scirpt：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libstdc++.so.6 python test.py</span><br></pre></td></tr></table></figure>
<blockquote>
<p>:key:注意，由于conda环境中的libstdc++版本低，可能会在import allo的时候报错。强制指定系统libstdc++版本即可。</p>
</blockquote>
<h3 id="Allo-AIE集成"><a href="#Allo-AIE集成" class="headerlink" title="Allo AIE集成"></a><font color = green>Allo AIE集成</font></h3><p>Allo项目目前可以集成AIE后端了，目前只局限于aie2（NPU）。该流程是端到端的编译流程，支持从pytorch或是huggingface上的模型lower到aie后端，并执行。具体流程如下：</p>
<p><img src="/images/image-20250407111644037.png" alt="image-20250407111644037"></p>
<p>目前存在的流程问题：</p>
<ul>
<li><p>Pytorch只能target到cpu和fpga上，目前没有支持pytorch到aie的端到端流程。</p>
<p><img src="/images/image-20250407124451930.png" alt="image-20250407124451930"></p>
</li>
<li><p>对于aie，目前allo支持用python编写算子，并且只能支持aie2（NPU），没有支持VCK190。</p>
<p><img src="/images/image-20250407124501753.png" alt="image-20250407124501753"></p>
</li>
<li><p>Pytorch算子支持受局限。</p>
<p><img src="/images/image-20250407124509106.png" alt="image-20250407124509106"></p>
</li>
</ul>
<h2 id="Allo项目架构"><a href="#Allo项目架构" class="headerlink" title="Allo项目架构"></a><font color = brown>Allo项目架构</font></h2><p><img src="/images/image-20250331184126715.png" alt="image-20250331184126715"></p>
<h3 id="前端"><a href="#前端" class="headerlink" title="前端"></a><font color = green>前端</font></h3><p><code>Allo</code>项目在前端使用python语言编写，主要完成<strong>python系统</strong>和<strong>pytorch系统</strong>到mlir系统的接入。针对pytorch系统，用于可以使用<code>torch.compile(model, &quot;allo&quot;)</code>将pytorch代码编译成allo的中间表达形式，借助于TorchDynamo系统。具体的，基于<code>torch.fx</code>作为高层ir，将其中的每一个pytorch计算单元翻译成allo的function call，后续转换和优化交由allo来完成。硬件无关优化比如算子融合在torch系统中完成，而硬件相关优化则由allo完成，两者是正交关系。</p>
<h2 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a><font color = green>代码生成</font></h2><p>用户通过<code>s.build(&lt;target&gt;)</code>来针对指定硬件生成代码。目前支持的后端硬件有：CPU，AMD的fpga以及AMD AIE（Ryzen AI）。</p>
<h2 id="中间优化"><a href="#中间优化" class="headerlink" title="中间优化"></a><font color = green>中间优化</font></h2><p>这一部分完全在mlir系统中完成所有的优化。</p>
<blockquote>
<p>Allo项目的框架是比较简单的，后续会结合源代码详细解读。</p>
</blockquote>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color = brown>参考资料</font></h2><ol>
<li><a href="https://cornell-zhang.github.io/allo/">Allo doc</a></li>
<li><a href="http://arxiv.org/abs/2404.04815">Allo paper</a></li>
<li><a href="https://github.com/cornell-zhang/allo">Allo project</a></li>
</ol>
]]></content>
      <categories>
        <category>编译技术</category>
        <category>机器学习编译</category>
        <category>异构设计</category>
      </categories>
      <tags>
        <tag>机器学习编译器</tag>
        <tag>mlir</tag>
        <tag>异构计算系统</tag>
      </tags>
  </entry>
  <entry>
    <title>BladeDISC初探</title>
    <url>/2025/04/01/BladeDISC%E5%88%9D%E6%8E%A2/</url>
    <content><![CDATA[<p><img src="/images/image-20250401195537142.png" alt="image-20250401195537142"></p>
<span id="more"></span>
<blockquote>
<p>在大模型训练推理场景中，一个十分大的瓶颈是动态shape问题。比如nlp领域，处理的句子长短不一，tensor的shape是动态变化的，到runtime才能确定。这给机器学习编译器带来很大的困扰，以XLA为首的sota编译器均是静态shape的，在性能上会有一定损失。BladeDISC是阿里提出的针对动态shape的机器学习编译器，并且经过大量实验和实际生产检验。本文重点关注BladeDISC的构建，pytorch使用方式以及基础架构解读。后续文章会讲解优化流程和论文解读。</p>
</blockquote>
<h2 id="源码构建"><a href="#源码构建" class="headerlink" title="源码构建"></a><font color = brown>源码构建</font></h2><h4 id="Build-from-source"><a href="#Build-from-source" class="headerlink" title="Build from source"></a>Build from source</h4><ul>
<li><p>下载<a href="https://hub.docker.com/r/bladedisc/bladedisc/tags?page=1&amp;name=devel">BladeDisc</a>镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull bladedisc/bladedisc:latest-devel-cu118</span><br></pre></td></tr></table></figure>
<ul>
<li>使用cu118版本</li>
</ul>
</li>
<li><p>运行该镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --gpus all -it -v $PWD:/disc bladedisc/bladedisc:latest-devel-cu118 bash</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改一下<code>pytorch_blade/scripts/build_pytorch_blade.sh</code>里面的<code>TORCH_BLADE_CI_BUILD_TORCH_VERSION</code>。修改为存在的<code>requirements.txt</code>即可。</p>
<blockquote>
<p>构建过程中，onnx由于带宽等问题，可能会报error，添加-i <a href="https://pypi.tuna.tsinghua.edu.cn/simple指定pypi镜像即可。">https://pypi.tuna.tsinghua.edu.cn/simple指定pypi镜像即可。</a></p>
</blockquote>
</li>
<li><p>pytorch版本构建</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd pytorch_blade &amp;&amp; bash ./scripts/build_pytorch_blade.sh</span><br><span class="line">python setup.py bdist_wheel</span><br><span class="line">pip install ./pytorch_blade/dist/torch_blade-0.2.0+2.0.1.cu118-cp38-cp38-linux_x86_64.whl</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a><font color = green>错误处理</font></h3><p>如果报错没有安全git，在docker中用：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git config --global --add safe.directory /disc</span><br></pre></td></tr></table></figure>
<h4 id="quick-install"><a href="#quick-install" class="headerlink" title="quick install"></a>quick install</h4><p>参考<a href="https://github.com/alibaba/BladeDISC/blob/main/docs/install_with_docker.md">docker install</a></p>
<h2 id="Pytorch部署BERT模型"><a href="#Pytorch部署BERT模型" class="headerlink" title="Pytorch部署BERT模型"></a><font color = brown>Pytorch部署BERT模型</font></h2><h3 id="Hugging-Face模型下载"><a href="#Hugging-Face模型下载" class="headerlink" title="Hugging Face模型下载"></a><font color = green>Hugging Face模型下载</font></h3><ul>
<li><p>手动下载模型（适合服务器联网不稳定的情况使用）</p>
<p>找到<a href="https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/tree/main">Bert sentiment inference 模型</a>，主要手动下载如下几个文件：</p>
<p><img src="/images/image-20250306203839463.png" alt="image-20250306203839463"></p>
<p>在python代码中使用离线下载的模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model_path = <span class="string">&quot;./model&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path)</span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_path).cuda().<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>
</li>
<li><p>直接通过transformers 包下载，该下载方式通过huggingface对应模型网页的<code>use this model</code>获取</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Load model directly</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification</span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>)</span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(<span class="string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>确保环境有transformers包即可</p>
</li>
<li><p>通过<code>huggingface-cli</code>下载</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">huggingface-cli download nlptown/bert-base-multilingual-uncased-sentiment</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="做BERT-Inference的testbench"><a href="#做BERT-Inference的testbench" class="headerlink" title="做BERT Inference的testbench"></a><font color = green>做BERT Inference的testbench</font></h3><p>我的测试codes如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch_blade</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> (</span><br><span class="line">    pipeline,</span><br><span class="line">    AutoTokenizer,</span><br><span class="line">    AutoModelForSequenceClassification,</span><br><span class="line">    TextClassificationPipeline,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">############################################# download model from huggingface #############################################</span></span><br><span class="line">model_path = <span class="string">&quot;./model&quot;</span></span><br><span class="line"></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_path)</span><br><span class="line"></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_path).cuda().<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plain_tokenizer</span>(<span class="params">inputs_str, return_tensors</span>):</span><br><span class="line">    inputs = tokenizer(inputs_str, return_tensors=return_tensors, padding=<span class="literal">True</span>)</span><br><span class="line">    inputs = &#123;key: value.cuda() <span class="keyword">for</span> key, value <span class="keyword">in</span> inputs.items()&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># torch_blade.optimize 不支持 None 作为输入</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;token_type_ids&quot;</span> <span class="keyword">in</span> inputs <span class="keyword">and</span> inputs[<span class="string">&quot;token_type_ids&quot;</span>] <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">del</span> inputs[<span class="string">&quot;token_type_ids&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (inputs[<span class="string">&#x27;input_ids&#x27;</span>], inputs[<span class="string">&#x27;attention_mask&#x27;</span>], inputs.get(<span class="string">&#x27;token_type_ids&#x27;</span>, <span class="literal">None</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PlainTextClassificationPipeline</span>(<span class="title class_ inherited__">TextClassificationPipeline</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_forward</span>(<span class="params">self, model_inputs</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.model(*model_inputs)</span><br><span class="line"></span><br><span class="line">classifier = pipeline(</span><br><span class="line">    <span class="string">&#x27;sentiment-analysis&#x27;</span>,</span><br><span class="line">    model=model,</span><br><span class="line">    tokenizer=plain_tokenizer,</span><br><span class="line">    pipeline_class=PlainTextClassificationPipeline,</span><br><span class="line">    device=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">input_strs = [</span><br><span class="line">    <span class="string">&quot;We are very happy to show you the story.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;We hope you don&#x27;t hate it.&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">results = classifier(input_strs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> inp_str, result <span class="keyword">in</span> <span class="built_in">zip</span>(input_strs, results):</span><br><span class="line">    <span class="built_in">print</span>(inp_str)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot; label: <span class="subst">&#123;result[<span class="string">&#x27;label&#x27;</span>]&#125;</span>, with a score: <span class="subst">&#123;<span class="built_in">round</span>(result[<span class="string">&#x27;score&#x27;</span>], <span class="number">4</span>)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">############################################# Use BladeDISC for optimization #############################################</span></span><br><span class="line">inputs_str = <span class="string">&quot;Hey, the cat is cute.&quot;</span></span><br><span class="line">inputs = plain_tokenizer(inputs_str, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line">torch_config = torch_blade.config.Config()</span><br><span class="line">torch_config.enable_mlir_amp = <span class="literal">False</span>  <span class="comment"># disable mix-precision</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Ensure inputs are properly formatted for optimization</span></span><br><span class="line">model_inputs = <span class="built_in">tuple</span>(i <span class="keyword">for</span> i <span class="keyword">in</span> inputs <span class="keyword">if</span> i <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad(), torch_config:</span><br><span class="line">    optimized_ts = torch_blade.optimize(model, allow_tracing=<span class="literal">True</span>, model_inputs=model_inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Move optimized model to CUDA</span></span><br><span class="line">optimized_ts = optimized_ts.cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the optimized TorchScript model</span></span><br><span class="line">torch.jit.save(optimized_ts, <span class="string">&quot;opt.disc.pt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">############################################# testbench #############################################</span></span><br><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">benchmark</span>(<span class="params">model, inputs, num_iters=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        model(*inputs)</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_iters):</span><br><span class="line">        model(*inputs)</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line">    end = time.time()</span><br><span class="line">    <span class="keyword">return</span> (end - start) / num_iters * <span class="number">1000.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bench_and_report</span>(<span class="params">input_strs</span>):</span><br><span class="line">    inputs = plain_tokenizer(input_strs, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">    model_inputs = <span class="built_in">tuple</span>(i <span class="keyword">for</span> i <span class="keyword">in</span> inputs <span class="keyword">if</span> i <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    avg_latency_baseline = benchmark(model, model_inputs)</span><br><span class="line">    avg_latency_bladedisc = benchmark(optimized_ts, model_inputs)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Seqlen: <span class="subst">&#123;[<span class="built_in">len</span>(s) <span class="keyword">for</span> s <span class="keyword">in</span> input_strs]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Baseline: <span class="subst">&#123;avg_latency_baseline:<span class="number">.4</span>f&#125;</span> ms&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;BladeDISC: <span class="subst">&#123;avg_latency_bladedisc:<span class="number">.4</span>f&#125;</span> ms&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;BladeDISC speedup: <span class="subst">&#123;avg_latency_baseline / avg_latency_bladedisc:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">input_strs = [</span><br><span class="line">    <span class="string">&quot;We are very happy to show you the story.&quot;</span>,</span><br><span class="line">    <span class="string">&quot;We hope you don&#x27;t hate it.&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">bench_and_report(input_strs)</span><br></pre></td></tr></table></figure>
<p>上述codes中，BladeDISC的核心如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad(), torch_config:</span><br><span class="line">    optimized_ts = torch_blade.optimize(model, allow_tracing=<span class="literal">True</span>, model_inputs=model_inputs)</span><br></pre></td></tr></table></figure>
<p>通过编译手段，生成优化后的pytorch script，注意：<strong>目前pytorch仅仅支持inference，尚不支持train</strong>。对于<code>HuggingFace</code>模型的pipeline有更深层兴趣的，参考<a href="https://huggingface.co/docs/transformers/quicktour">HuggingFace quick tour</a>。</p>
<h3 id="Pytorch-WorkFlow"><a href="#Pytorch-WorkFlow" class="headerlink" title="Pytorch WorkFlow"></a><font color = green>Pytorch WorkFlow</font></h3><p><img src="/images/image-20250311211223452.png" alt="image-20250311211223452"></p>
<p><img src="/images/image-20250311220823276.png" alt="image-20250311220823276"></p>
<p>参考<a href="https://github.com/alibaba/BladeDISC/blob/main/docs/developers/bladedisc_torch_overview.md">Torch-Blade教程</a>即可。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color = brown>参考资料</font></h2><ol>
<li><a href="https://github.com/alibaba/BladeDISC">BladeDisc github</a></li>
</ol>
]]></content>
      <categories>
        <category>编译技术</category>
        <category>机器学习编译</category>
        <category>动态shape</category>
      </categories>
      <tags>
        <tag>机器学习编译器</tag>
        <tag>mlir</tag>
        <tag>动态shape</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch新特性解读</title>
    <url>/2025/04/05/Pytorch%E6%96%B0%E7%89%B9%E6%80%A7%E8%A7%A3%E8%AF%BB/</url>
    <content><![CDATA[<p><img src="/images/image-20250405105059068.png" alt="image-20250405105059068"></p>
<span id="more"></span>
<blockquote>
<p>在pytorch2中，pytorch增加了许多新的特性，其中最重要的是<code>torchdynamo</code>和<code>torchinductor</code>。本篇博客结合pytorch2在asplos的paper，解读新特性背后的编译技术。</p>
</blockquote>
]]></content>
      <categories>
        <category>编译技术</category>
        <category>机器学习编译</category>
        <category>机器学习系统</category>
      </categories>
      <tags>
        <tag>机器学习编译器</tag>
        <tag>pytorch技术</tag>
        <tag>静态图捕捉和编译</tag>
      </tags>
  </entry>
  <entry>
    <title>Transform Dialect tutorial1</title>
    <url>/2025/04/08/Transform-Dialect-tutorial1/</url>
    <content><![CDATA[<p><img src="/images/image-20250408184457571.png" alt="image-20250408184457571"></p>
<span id="more"></span>
<blockquote>
<p>Transform dialect是mlir基础设施实现的调度dsl。通过在同一个mlir文件中，使用标准ir定义计算任务（payload ir），利用transform ir定义调度方式（schedule ir），最后借助于transform-interpreter注册和使用整个pass。</p>
</blockquote>
<h2 id="Motivation-of-Transform-Dialect"><a href="#Motivation-of-Transform-Dialect" class="headerlink" title="Motivation of Transform Dialect"></a><font color = brown>Motivation of Transform Dialect</font></h2><p>总结许多成熟编译器，比如Halide，TVM，TC等，可以发现如下规律：</p>
<ol>
<li><strong>调度表示</strong>（Schedule Representation）：以结构化数据描述优化流程的元信息集合</li>
<li><strong>声明式规范</strong>（Declarative Specification）：通过定义预期目标状态而非具体操作步骤进行配置</li>
<li><strong>多版本化</strong>（Multi-Versioning）：针对不同硬件/场景生成多个优化方案分支</li>
<li><strong>运行时调度</strong>（Runtime Dispatch）：通过动态决策机制选择最优版本执行</li>
<li><strong>垂直时序控制</strong>（Vertical Sequencing）：在单一功能域内进行深度优化组合</li>
</ol>
<p>MLIR基础设施中，也希望提供用户类似TVM的计算调度分离的能力，从而方便用户对于一个计算任务自定义调度优化策略。在MLIR中，一切都是<code>op</code>操作，调度操作也是<code>op</code>，封装在transform这个dialect中，这便是transform dialect的由来。</p>
<blockquote>
<p>后续教程主要来源于<a href="https://mlir.llvm.org/docs/Tutorials/transform/">transform tutorial</a></p>
</blockquote>
<h2 id="Chapter1：利用transform-op组建pipeline"><a href="#Chapter1：利用transform-op组建pipeline" class="headerlink" title="Chapter1：利用transform op组建pipeline"></a><font color = brown>Chapter1：利用transform op组建pipeline</font></h2><p>transform dialect内置丰富的schedule op，计算调度分离机制使得用户需要定义payload ir以及schedule ir。在transform的官方tutorial中给的例子，是将一个矩阵乘-逐项加-relu操作，利用transform op做调度优化。</p>
<ul>
<li><p>payload ir（详细定义计算任务）：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Original function to optimize.</span></span><br><span class="line">func.func @<span class="built_in">fc_relu</span>(%lhs: tensor&lt;<span class="number">512</span>x512xf32&gt;, %rhs: tensor&lt;<span class="number">512</span>x512xf32&gt;,</span><br><span class="line">                   %bias: tensor&lt;<span class="number">512</span>x512xf32&gt;, %output: tensor&lt;<span class="number">512</span>x512xf32&gt;)</span><br><span class="line">                   -&gt; tensor&lt;<span class="number">512</span>x512xf32&gt; &#123;</span><br><span class="line">  <span class="comment">// Matrix-matrix multiplication.</span></span><br><span class="line">  %matmul = linalg.matmul <span class="built_in">ins</span>(%lhs, %rhs: tensor&lt;<span class="number">512</span>x512xf32&gt;, tensor&lt;<span class="number">512</span>x512xf32&gt;)</span><br><span class="line">                          <span class="built_in">outs</span>(%output: tensor&lt;<span class="number">512</span>x512xf32&gt;) -&gt; tensor&lt;<span class="number">512</span>x512xf32&gt;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Elementwise addition.</span></span><br><span class="line">  %biased = linalg.elemwise_binary &#123; fun = <span class="meta">#linalg.binary_fn<span class="string">&lt;add&gt;</span> &#125;</span></span><br><span class="line">    <span class="built_in">ins</span>(%matmul, %bias : tensor&lt;<span class="number">512</span>x512xf32&gt;, tensor&lt;<span class="number">512</span>x512xf32&gt;)</span><br><span class="line">    <span class="built_in">outs</span>(%output : tensor&lt;<span class="number">512</span>x512xf32&gt;) -&gt; tensor&lt;<span class="number">512</span>x512xf32&gt;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Elementwise max with 0 (ReLU).</span></span><br><span class="line">  %c0f = arith.constant <span class="number">0.0</span> : f32</span><br><span class="line">  %relued = linalg.elemwise_binary &#123; fun = <span class="meta">#linalg.binary_fn<span class="string">&lt;max_signed&gt;</span> &#125;</span></span><br><span class="line">    <span class="built_in">ins</span>(%biased, %c0f : tensor&lt;<span class="number">512</span>x512xf32&gt;, f32)</span><br><span class="line">    <span class="built_in">outs</span>(%output : tensor&lt;<span class="number">512</span>x512xf32&gt;) -&gt; tensor&lt;<span class="number">512</span>x512xf32&gt;</span><br><span class="line">  func.<span class="keyword">return</span> %relued : tensor&lt;<span class="number">512</span>x512xf32&gt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>payload ir的定义就使用linalg等标准mlir ir定义即可。</p>
</li>
<li><p>schedule ir（调度原语）</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">module</span> attributes &#123;transform.with_named_sequence&#125; &#123;  </span><br><span class="line">  transform.named_sequence @__transform_main(</span><br><span class="line">      %arg0: !transform.any_op,</span><br><span class="line">      %arg1: !transform.op&lt;<span class="string">&quot;linalg.matmul&quot;</span>&gt;,</span><br><span class="line">      %arg2: !transform.op&lt;<span class="string">&quot;linalg.elemwise_binary&quot;</span>&gt;) &#123;</span><br><span class="line">    <span class="comment">// Since the %arg2 handle is associated with both elementwise operations,</span></span><br><span class="line">    <span class="comment">// we need to split it into two handles so we can target only the second</span></span><br><span class="line">    <span class="comment">// elementwise operation.</span></span><br><span class="line">    %add, %max = transform.split_handle %arg2 : (!transform.op&lt;<span class="string">&quot;linalg.elemwise_binary&quot;</span>&gt;)</span><br><span class="line">        -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// The actual tiling transformation takes tile sizes as attributes. It produces a</span></span><br><span class="line">    <span class="comment">// handle to the loop generated during tiling.</span></span><br><span class="line">    %tiled, %loop = transform.structured.tile_using_forall %max tile_sizes [<span class="number">8</span>, <span class="number">32</span>]</span><br><span class="line">        : (!transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// We can now fuse the other operations into the loop. Here, we fuse</span></span><br><span class="line">    <span class="comment">// operations one-by-one. This requires the operation that is being fused</span></span><br><span class="line">    <span class="comment">// to define the value used within the loop, so the order of such fusions</span></span><br><span class="line">    <span class="comment">// is important. We could also use &quot;transform.merge_handles&quot; to obtain</span></span><br><span class="line">    <span class="comment">// a single handle to all operations and give it to `fuse_into_containing_op`</span></span><br><span class="line">    <span class="comment">// that would take care of the ordering in this case</span></span><br><span class="line">    %add_fused, %loop2 = transform.structured.fuse_into_containing_op %add into %loop</span><br><span class="line">        : (!transform.any_op, !transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">    %matmul_fused, %loop3 = transform.structured.fuse_into_containing_op %arg1 into %loop2</span><br><span class="line">        : (!transform.op&lt;<span class="string">&quot;linalg.matmul&quot;</span>&gt;, !transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// Tile again to get the desired size. Note that this time this tiles the</span></span><br><span class="line">    <span class="comment">// &quot;add&quot; operation and fuses matmul into the loop, but doesn&#x27;t affect the</span></span><br><span class="line">    <span class="comment">// &quot;max&quot; operation. This illustrates the precise targeting with the transform</span></span><br><span class="line">    <span class="comment">// dialect. Otherwise, it is difficult to differentiate &quot;add&quot; and &quot;max&quot;, both</span></span><br><span class="line">    <span class="comment">// of which having the same kind.</span></span><br><span class="line">    %tiled_second, %loop_second = transform.structured.tile_using_forall %add_fused tile_sizes [<span class="number">4</span>, <span class="number">4</span>]</span><br><span class="line">        : (!transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">    %matmul_fused_2, %loop_second_2 =</span><br><span class="line">        transform.structured.fuse_into_containing_op %matmul_fused into %loop_second</span><br><span class="line">        : (!transform.any_op, !transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// // Since outlining is currently only implemented for region-holding operations</span></span><br><span class="line">    <span class="comment">// // such as loops, use tiling to size 1 to materialize the outer loop that is</span></span><br><span class="line">    <span class="comment">// // going to be outlined.</span></span><br><span class="line">    <span class="comment">// %_0, %loop_third = transform.structured.tile_using_forall %tiled_second tile_sizes [1]</span></span><br><span class="line">    <span class="comment">//     : (!transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span></span><br><span class="line">    <span class="comment">// %_1, %outline_target = transform.structured.fuse_into_containing_op %matmul_fused_2 into %loop_third</span></span><br><span class="line">    <span class="comment">//     : (!transform.any_op, !transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span></span><br><span class="line">    <span class="comment">// %func, %call = transform.loop.outline %outline_target &#123;func_name = &quot;outlined&quot;&#125;</span></span><br><span class="line">    <span class="comment">//     : (!transform.any_op) -&gt; (!transform.any_op, !transform.op&lt;&quot;func.call&quot;&gt;)</span></span><br><span class="line">  </span><br><span class="line">    transform.yield</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>完整代码片段如下。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// RUN: mlir-opt %s \</span></span><br><span class="line"><span class="comment">// RUN:   --pass-pipeline=&quot;builtin.module(transform-interpreter&#123; \</span></span><br><span class="line"><span class="comment">// RUN:        debug-bind-trailing-args=linalg.matmul,linalg.elemwise_binary&#125;,\</span></span><br><span class="line"><span class="comment">// RUN:        canonicalize,cse,symbol-dce)&quot; |\</span></span><br><span class="line"><span class="comment">// RUN: FileCheck %s</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ****************************** IMPORTANT NOTE ******************************</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If you are changing this file, you may also need to change</span></span><br><span class="line"><span class="comment">// mlir/docs/Tutorials/Transform accordingly.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// ****************************************************************************</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Original function to optimize.</span></span><br><span class="line">func.func @<span class="built_in">fc_relu</span>(%lhs: tensor&lt;<span class="number">512</span>x512xf32&gt;, %rhs: tensor&lt;<span class="number">512</span>x512xf32&gt;,</span><br><span class="line">                   %bias: tensor&lt;<span class="number">512</span>x512xf32&gt;, %output: tensor&lt;<span class="number">512</span>x512xf32&gt;)</span><br><span class="line">                   -&gt; tensor&lt;<span class="number">512</span>x512xf32&gt; &#123;</span><br><span class="line">  <span class="comment">// Matrix-matrix multiplication.</span></span><br><span class="line">  %matmul = linalg.matmul <span class="built_in">ins</span>(%lhs, %rhs: tensor&lt;<span class="number">512</span>x512xf32&gt;, tensor&lt;<span class="number">512</span>x512xf32&gt;)</span><br><span class="line">                          <span class="built_in">outs</span>(%output: tensor&lt;<span class="number">512</span>x512xf32&gt;) -&gt; tensor&lt;<span class="number">512</span>x512xf32&gt;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Elementwise addition.</span></span><br><span class="line">  %biased = linalg.elemwise_binary &#123; fun = <span class="meta">#linalg.binary_fn<span class="string">&lt;add&gt;</span> &#125;</span></span><br><span class="line">    <span class="built_in">ins</span>(%matmul, %bias : tensor&lt;<span class="number">512</span>x512xf32&gt;, tensor&lt;<span class="number">512</span>x512xf32&gt;)</span><br><span class="line">    <span class="built_in">outs</span>(%output : tensor&lt;<span class="number">512</span>x512xf32&gt;) -&gt; tensor&lt;<span class="number">512</span>x512xf32&gt;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Elementwise max with 0 (ReLU).</span></span><br><span class="line">  %c0f = arith.constant <span class="number">0.0</span> : f32</span><br><span class="line">  %relued = linalg.elemwise_binary &#123; fun = <span class="meta">#linalg.binary_fn<span class="string">&lt;max_signed&gt;</span> &#125;</span></span><br><span class="line">    <span class="built_in">ins</span>(%biased, %c0f : tensor&lt;<span class="number">512</span>x512xf32&gt;, f32)</span><br><span class="line">    <span class="built_in">outs</span>(%output : tensor&lt;<span class="number">512</span>x512xf32&gt;) -&gt; tensor&lt;<span class="number">512</span>x512xf32&gt;</span><br><span class="line">  func.<span class="keyword">return</span> %relued : tensor&lt;<span class="number">512</span>x512xf32&gt;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// CHECK: func @outlined</span></span><br><span class="line"><span class="comment">// CHECK:   linalg.matmul</span></span><br><span class="line"><span class="comment">// CHECK:   linalg.elemwise_binary &#123;fun = #linalg.binary_fn&lt;add&gt;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CHECK-LABEL: func @fc_relu</span></span><br><span class="line"><span class="comment">// CHECK: scf.forall</span></span><br><span class="line"><span class="comment">// CHECK:   scf.forall</span></span><br><span class="line"><span class="comment">// CHECK:     %[[SLICE4:.+]] = tensor.extract_slice</span></span><br><span class="line"><span class="comment">// CHECK:     %[[SLICE5:.+]] = tensor.extract_slice</span></span><br><span class="line"><span class="comment">// CHECK:     %[[SLICE6:.+]] = tensor.extract_slice</span></span><br><span class="line"><span class="comment">// CHECK:     %[[SLICE7:.+]] = tensor.extract_slice</span></span><br><span class="line"><span class="comment">// CHECK:     %[[SLICE8:.+]] = tensor.extract_slice</span></span><br><span class="line"><span class="comment">// CHECK:     func.call @outlined(%[[SLICE4]], %[[SLICE5]], %[[SLICE6]], %[[SLICE7]], %[[SLICE8]])</span></span><br><span class="line"><span class="comment">// CHECK-NOT: linalg.matmul</span></span><br><span class="line"><span class="comment">// CHECK-NOT: linalg.elemwise_binary</span></span><br><span class="line"><span class="comment">// CHECK:     scf.forall.in_parallel</span></span><br><span class="line"><span class="comment">// CHECK:   linalg.elemwise_binary &#123;fun = #linalg.binary_fn&lt;max_signed&gt;&#125;</span></span><br><span class="line"><span class="comment">// CHECK:   scf.forall.in_parallel</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Declaration of the &quot;microkernel&quot; function that we will be targeting.</span></span><br><span class="line">func.func <span class="keyword">private</span> @<span class="built_in">microkernel</span>(</span><br><span class="line">    %lhs: tensor&lt;<span class="number">4</span>x512xf32&gt;,</span><br><span class="line">    %rhs: tensor&lt;<span class="number">512</span>x4xf32&gt;,</span><br><span class="line">    %bias: tensor&lt;<span class="number">4</span>x4xf32&gt;,</span><br><span class="line">    %init: tensor&lt;<span class="number">4</span>x4xf32&gt;,</span><br><span class="line">    %output: tensor&lt;<span class="number">4</span>x4xf32&gt;) -&gt; tensor&lt;<span class="number">4</span>x4xf32&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">module</span> attributes &#123;transform.with_named_sequence&#125; &#123;  </span><br><span class="line">  transform.named_sequence @__transform_main(</span><br><span class="line">      %arg0: !transform.any_op,</span><br><span class="line">      %arg1: !transform.op&lt;<span class="string">&quot;linalg.matmul&quot;</span>&gt;,</span><br><span class="line">      %arg2: !transform.op&lt;<span class="string">&quot;linalg.elemwise_binary&quot;</span>&gt;) &#123;</span><br><span class="line">    <span class="comment">// Since the %arg2 handle is associated with both elementwise operations,</span></span><br><span class="line">    <span class="comment">// we need to split it into two handles so we can target only the second</span></span><br><span class="line">    <span class="comment">// elementwise operation.</span></span><br><span class="line">    %add, %max = transform.split_handle %arg2 : (!transform.op&lt;<span class="string">&quot;linalg.elemwise_binary&quot;</span>&gt;)</span><br><span class="line">        -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// The actual tiling transformation takes tile sizes as attributes. It produces a</span></span><br><span class="line">    <span class="comment">// handle to the loop generated during tiling.</span></span><br><span class="line">    %tiled, %loop = transform.structured.tile_using_forall %max tile_sizes [<span class="number">8</span>, <span class="number">32</span>]</span><br><span class="line">        : (!transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// We can now fuse the other operations into the loop. Here, we fuse</span></span><br><span class="line">    <span class="comment">// operations one-by-one. This requires the operation that is being fused</span></span><br><span class="line">    <span class="comment">// to define the value used within the loop, so the order of such fusions</span></span><br><span class="line">    <span class="comment">// is important. We could also use &quot;transform.merge_handles&quot; to obtain</span></span><br><span class="line">    <span class="comment">// a single handle to all operations and give it to `fuse_into_containing_op`</span></span><br><span class="line">    <span class="comment">// that would take care of the ordering in this case</span></span><br><span class="line">    %add_fused, %loop2 = transform.structured.fuse_into_containing_op %add into %loop</span><br><span class="line">        : (!transform.any_op, !transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">    %matmul_fused, %loop3 = transform.structured.fuse_into_containing_op %arg1 into %loop2</span><br><span class="line">        : (!transform.op&lt;<span class="string">&quot;linalg.matmul&quot;</span>&gt;, !transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// Tile again to get the desired size. Note that this time this tiles the</span></span><br><span class="line">    <span class="comment">// &quot;add&quot; operation and fuses matmul into the loop, but doesn&#x27;t affect the</span></span><br><span class="line">    <span class="comment">// &quot;max&quot; operation. This illustrates the precise targeting with the transform</span></span><br><span class="line">    <span class="comment">// dialect. Otherwise, it is difficult to differentiate &quot;add&quot; and &quot;max&quot;, both</span></span><br><span class="line">    <span class="comment">// of which having the same kind.</span></span><br><span class="line">    %tiled_second, %loop_second = transform.structured.tile_using_forall %add_fused tile_sizes [<span class="number">4</span>, <span class="number">4</span>]</span><br><span class="line">        : (!transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">    %matmul_fused_2, %loop_second_2 =</span><br><span class="line">        transform.structured.fuse_into_containing_op %matmul_fused into %loop_second</span><br><span class="line">        : (!transform.any_op, !transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// // Since outlining is currently only implemented for region-holding operations</span></span><br><span class="line">    <span class="comment">// // such as loops, use tiling to size 1 to materialize the outer loop that is</span></span><br><span class="line">    <span class="comment">// // going to be outlined.</span></span><br><span class="line">    <span class="comment">// %_0, %loop_third = transform.structured.tile_using_forall %tiled_second tile_sizes [1]</span></span><br><span class="line">    <span class="comment">//     : (!transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span></span><br><span class="line">    <span class="comment">// %_1, %outline_target = transform.structured.fuse_into_containing_op %matmul_fused_2 into %loop_third</span></span><br><span class="line">    <span class="comment">//     : (!transform.any_op, !transform.any_op) -&gt; (!transform.any_op, !transform.any_op)</span></span><br><span class="line">    <span class="comment">// %func, %call = transform.loop.outline %outline_target &#123;func_name = &quot;outlined&quot;&#125;</span></span><br><span class="line">    <span class="comment">//     : (!transform.any_op) -&gt; (!transform.any_op, !transform.op&lt;&quot;func.call&quot;&gt;)</span></span><br><span class="line">  </span><br><span class="line">    transform.yield</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Chapter2：自定义一个简单的transform-operation"><a href="#Chapter2：自定义一个简单的transform-operation" class="headerlink" title="Chapter2：自定义一个简单的transform operation"></a><font color = brown>Chapter2：自定义一个简单的transform operation</font></h2><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a><font color = green>目的</font></h3><p>很多时候，transform dialect中的operation无法满足我们调度优化需求。比如在chapter1中，我们最后tiling的小块可以替换成手写的算子microkernel，这个替换操作在transform中没有直接的op。可以实现自定义operation（<code>transform.my.change_call_target</code>），使用方法如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Rewrite the call target.</span></span><br><span class="line">transform.my.change_call_target %call, <span class="string">&quot;microkernel&quot;</span> : !transform.any_op</span><br></pre></td></tr></table></figure>
<p>即将%call这个handle（一个operation）转变成microkernel调用。</p>
<blockquote>
<p>在实际编译开发中，microkernel相当于微内核算子，一般为手写，编译器可以自动发现可以替换的op做替换，以进一步提高性能。</p>
</blockquote>
<h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a><font color = green>项目结构</font></h3><p>transform extension的写法，和mlir的一个standalone项目的结构是类似的。项目结构可以参考<a href="https://github.com/llvm/llvm-project/tree/main/mlir/examples/standalone">mlir standalone项目框架</a>。</p>
<p>如下是chapter2的项目结构：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">├── build.sh</span><br><span class="line">├── CMakeLists.txt</span><br><span class="line">├── include</span><br><span class="line">│   ├── CMakeLists.txt</span><br><span class="line">│   ├── MyExtension.h</span><br><span class="line">│   └── MyExtension.td</span><br><span class="line">├── lib</span><br><span class="line">│   ├── CMakeLists.txt</span><br><span class="line">│   └── MyExtension.cpp</span><br><span class="line">├── test</span><br><span class="line">│   ├── invalid.mlir</span><br><span class="line">│   ├── sequence.mlir</span><br><span class="line">│   └── test.sh</span><br><span class="line">└── transform-opt</span><br><span class="line">    ├── CMakeLists.txt</span><br><span class="line">    └── transform-opt.cpp</span><br></pre></td></tr></table></figure>
<p>为transform dialect定义一个operation，主要需要思考如下几个点：</p>
<ul>
<li>利用ods系统定义一个operation，自动生成.h和.cpp文件。</li>
<li>该operation需要重载几个interface。<ul>
<li>TransformOpInterface是transform dialect的op必须实现的interface，主要实现<code>apply</code>方法。</li>
<li>MemoryEffectsOpInterface是内存side effect定义interface，需要实现<code>getEffects</code>方法。</li>
</ul>
</li>
<li>注册operation。</li>
</ul>
<h3 id="代码框架讲解"><a href="#代码框架讲解" class="headerlink" title="代码框架讲解"></a><font color = green>代码框架讲解</font></h3><p>后续按照这个顺序来罗列代码，代码注释十分全面了。</p>
<h4 id="定义operation"><a href="#定义operation" class="headerlink" title="定义operation"></a>定义operation</h4><p><code>/include/MyExtension.td</code></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//===-- MyExtension.td - Transform dialect tutorial --------*- tablegen -*-===//</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.</span></span><br><span class="line"><span class="comment">// See https://llvm.org/LICENSE.txt for license information.</span></span><br><span class="line"><span class="comment">// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//===----------------------------------------------------------------------===//</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// This file defines Transform dialect extension operations used in the</span></span><br><span class="line"><span class="comment">// Chapter 2 of the Transform dialect tutorial.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//===----------------------------------------------------------------------===//</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> MY_EXTENSION</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MY_EXTENSION</span></span><br><span class="line"></span><br><span class="line">include <span class="string">&quot;mlir/Dialect/Transform/IR/TransformDialect.td&quot;</span></span><br><span class="line">include <span class="string">&quot;mlir/Dialect/Transform/Interfaces/TransformInterfaces.td&quot;</span></span><br><span class="line">include <span class="string">&quot;mlir/IR/OpBase.td&quot;</span></span><br><span class="line">include <span class="string">&quot;mlir/Interfaces/SideEffectInterfaces.td&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Define the new operation. By convention, prefix its name with the name of the dialect </span></span><br><span class="line"><span class="comment">// extension, &quot;my.&quot;. The full operation name will be further prefixed with &quot;transform.&quot;.</span></span><br><span class="line">def ChangeCallTargetOp : Op&lt;Transform_Dialect, <span class="string">&quot;my.change_call_target&quot;</span>,</span><br><span class="line">    <span class="comment">// Indicate that the operation implements the required TransformOpInterface and</span></span><br><span class="line">    <span class="comment">// MemoryEffectsOpInterface.</span></span><br><span class="line">    [DeclareOpInterfaceMethods&lt;TransformOpInterface&gt;,</span><br><span class="line">     DeclareOpInterfaceMethods&lt;MemoryEffectsOpInterface&gt;]&gt; &#123;</span><br><span class="line">  <span class="comment">// Provide a brief and a full description. It is recommended that the latter describes </span></span><br><span class="line">  <span class="comment">// the effects on the operands and how the operation processes various failure modes.</span></span><br><span class="line">  let summary = <span class="string">&quot;Changes the callee of a call operation to the specified one&quot;</span>;</span><br><span class="line">  let description = [&#123;</span><br><span class="line">    For each `func.call` payload operation associated with the handle, changes its </span><br><span class="line">    callee to be the symbol whose name is provided as an attribute to <span class="keyword">this</span> operation.</span><br><span class="line"></span><br><span class="line">    Generates a silenceable failure <span class="keyword">if</span> the operand is associated with payload operations </span><br><span class="line">    that are <span class="keyword">not</span> `func.call`.</span><br><span class="line">    Only reads the operand.</span><br><span class="line">  &#125;];</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The arguments include the handle to the payload operations and the attribute that </span></span><br><span class="line">  <span class="comment">// specifies the new callee. The handle must implement TransformHandleTypeInterface.   </span></span><br><span class="line">  <span class="comment">// We use a string attribute as the symbol may not exist in the transform IR so the </span></span><br><span class="line">  <span class="comment">// verification may fail. </span></span><br><span class="line">  let arguments = (ins</span><br><span class="line">    TransformHandleTypeInterface:$call,</span><br><span class="line">    StrAttr:$new_target);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The results are empty as the transformation does not produce any new payload.</span></span><br><span class="line">  let results = (outs);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Provide nice syntax.</span></span><br><span class="line">  let assemblyFormat = <span class="string">&quot;$call `,` $new_target attr-dict `:` type($call)&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">// MY_EXTENSION</span></span></span><br></pre></td></tr></table></figure>
<p>上述td定义和mlir op定义是一样的，需要注意如下几点：</p>
<ul>
<li><p>定义interface：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">[DeclareOpInterfaceMethods&lt;TransformOpInterface&gt;,</span><br><span class="line"> DeclareOpInterfaceMethods&lt;MemoryEffectsOpInterface&gt;]</span><br></pre></td></tr></table></figure>
</li>
<li><p>operation的定义：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// The arguments include the handle to the payload operations and the attribute that </span></span><br><span class="line"><span class="comment">// specifies the new callee. The handle must implement TransformHandleTypeInterface.   </span></span><br><span class="line"><span class="comment">// We use a string attribute as the symbol may not exist in the transform IR so the </span></span><br><span class="line"><span class="comment">// verification may fail. </span></span><br><span class="line">let arguments = (ins</span><br><span class="line">  TransformHandleTypeInterface:$call,</span><br><span class="line">  StrAttr:$new_target);</span><br></pre></td></tr></table></figure>
<p>重点是argument中需要传入一个handle，该handle必须实现TransformHandleTypeInterface，即这个handle可以通过transform op来操纵。</p>
</li>
</ul>
<p><code>MyExtension.h</code></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//===-- MyExtension.h - Transform dialect tutorial --------------*- c++ -*-===//</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.</span></span><br><span class="line"><span class="comment">// See https://llvm.org/LICENSE.txt for license information.</span></span><br><span class="line"><span class="comment">// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//===----------------------------------------------------------------------===//</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// This file defines Transform dialect extension operations used in the</span></span><br><span class="line"><span class="comment">// Chapter 2 of the Transform dialect tutorial.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//===----------------------------------------------------------------------===//</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;mlir/Bytecode/BytecodeOpInterface.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;mlir/Dialect/Transform/IR/TransformDialect.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;mlir/Dialect/Transform/Interfaces/TransformInterfaces.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GET_OP_CLASSES</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;MyExtension.h.inc&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Registers our Transform dialect extension.</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">registerMyExtension</span><span class="params">(::mlir::DialectRegistry &amp;registry)</span></span>;</span><br></pre></td></tr></table></figure>
<p>这个头文件和mlir基础操作一样，利用宏定义获取.h.inc中的op定义，并定义一个extension的注册函数。</p>
<p>CmakeLists.txt如下：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Tell Tablegen to use MyExtension.td as input.</span></span><br><span class="line"><span class="keyword">set</span>(LLVM_TARGET_DEFINITIONS MyExtension.td)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ask Tablegen to generate op declarations and definitions from ODS.</span></span><br><span class="line">mlir_tablegen(MyExtension.h.inc -gen-op-decls)</span><br><span class="line">mlir_tablegen(MyExtension.cpp.inc -gen-op-defs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add a CMakeTarget we can depend on to ensure the generation happens before the compilation.</span></span><br><span class="line">add_public_tablegen_target(MyExtensionCh2IncGen)</span><br></pre></td></tr></table></figure>
<h4 id="实现operation需要重载的interface操作"><a href="#实现operation需要重载的interface操作" class="headerlink" title="实现operation需要重载的interface操作"></a>实现operation需要重载的interface操作</h4><p><code>/lib/MyExtension.cpp</code>中的代码可以做拆分</p>
<ul>
<li><p>定义transform dialect的extension：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Define a new transform dialect extension. This uses the CRTP idiom to</span></span><br><span class="line"><span class="comment">// identify extensions.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyExtension</span></span><br><span class="line">    : <span class="keyword">public</span> ::mlir::transform::TransformDialectExtension&lt;MyExtension&gt; &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// The TypeID of this extension.</span></span><br><span class="line">  <span class="built_in">MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID</span>(MyExtension)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The extension must derive the base constructor.</span></span><br><span class="line">  <span class="keyword">using</span> Base::Base;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// This function initializes the extension, similarly to `initialize` in</span></span><br><span class="line">  <span class="comment">// dialect definitions. List individual operations and dependent dialects</span></span><br><span class="line">  <span class="comment">// here.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">init</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>extension的初始化：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">MyExtension::init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Similarly to dialects, an extension can declare a dependent dialect. This</span></span><br><span class="line">  <span class="comment">// dialect will be loaded along with the extension and, therefore, along with</span></span><br><span class="line">  <span class="comment">// the Transform dialect. Only declare as dependent the dialects that contain</span></span><br><span class="line">  <span class="comment">// the attributes or types used by transform operations. Do NOT declare as</span></span><br><span class="line">  <span class="comment">// dependent the dialects produced during the transformation.</span></span><br><span class="line">  <span class="comment">// declareDependentDialect&lt;MyDialect&gt;();</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// When transformations are applied, they may produce new operations from</span></span><br><span class="line">  <span class="comment">// previously unloaded dialects. Typically, a pass would need to declare</span></span><br><span class="line">  <span class="comment">// itself dependent on the dialects containing such new operations. To avoid</span></span><br><span class="line">  <span class="comment">// confusion with the dialects the extension itself depends on, the Transform</span></span><br><span class="line">  <span class="comment">// dialects differentiates between:</span></span><br><span class="line">  <span class="comment">//   - dependent dialects, which are used by the transform operations, and</span></span><br><span class="line">  <span class="comment">//   - generated dialects, which contain the entities (attributes, operations,</span></span><br><span class="line">  <span class="comment">//     types) that may be produced by applying the transformation even when</span></span><br><span class="line">  <span class="comment">//     not present in the original payload IR.</span></span><br><span class="line">  <span class="comment">// In the following chapter, we will be add operations that generate function</span></span><br><span class="line">  <span class="comment">// calls and structured control flow operations, so let&#x27;s declare the</span></span><br><span class="line">  <span class="comment">// corresponding dialects as generated.</span></span><br><span class="line">  <span class="built_in">declareGeneratedDialect</span>&lt;::mlir::scf::SCFDialect&gt;();</span><br><span class="line">  <span class="built_in">declareGeneratedDialect</span>&lt;::mlir::func::FuncDialect&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Finally, we register the additional transform operations with the dialect.</span></span><br><span class="line">  <span class="comment">// List all operations generated from ODS. This call will perform additional</span></span><br><span class="line">  <span class="comment">// checks that the operations implement the transform and memory effect</span></span><br><span class="line">  <span class="comment">// interfaces required by the dialect interpreter and assert if they do not.</span></span><br><span class="line">  <span class="built_in">registerTransformOps</span>&lt;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GET_OP_LIST</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;MyExtension.cpp.inc&quot;</span></span></span><br><span class="line">      &gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>上述的一个重点是<code>declareDependentDialect</code>和<code>declareGeneratedDialect</code>的区别。<code>dependent dialects</code> 是 transform op 需要的，<code>generated dialects</code> 是 transform 执行后生成的。这里scf和func均是可能生成的dialect。</p>
</li>
<li><p>另一个重点是，<code>registerTransformOps</code>会注册ods定义的operation，同时会有检测机制check是否完成transform和sideeffect的interface。</p>
</li>
</ul>
</li>
<li><p>对特定op做interface重写：</p>
<ul>
<li><p>transform interface的apply方法重写：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">::mlir::DiagnosedSilenceableFailure mlir::transform::ChangeCallTargetOp::<span class="built_in">apply</span>(</span><br><span class="line">    <span class="comment">// The rewriter that should be used when modifying IR.</span></span><br><span class="line">    ::mlir::transform::TransformRewriter &amp;rewriter,</span><br><span class="line">    <span class="comment">// The list of payload IR entities that will be associated with the</span></span><br><span class="line">    <span class="comment">// transform IR values defined by this transform operation. In this case, it</span></span><br><span class="line">    <span class="comment">// can remain empty as there are no results.</span></span><br><span class="line">    ::mlir::transform::TransformResults &amp;results,</span><br><span class="line">    <span class="comment">// The transform application state. This object can be used to query the</span></span><br><span class="line">    <span class="comment">// current associations between transform IR values and payload IR entities.</span></span><br><span class="line">    <span class="comment">// It can also carry additional user-defined state.</span></span><br><span class="line">    ::mlir::transform::TransformState &amp;state) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// First, we need to obtain the list of payload operations that are associated</span></span><br><span class="line">  <span class="comment">// with the operand handle.</span></span><br><span class="line">  <span class="keyword">auto</span> payload = state.<span class="built_in">getPayloadOps</span>(<span class="built_in">getCall</span>());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Then, we iterate over the list of operands and call the actual IR-mutating</span></span><br><span class="line">  <span class="comment">// function. We also check the preconditions here.</span></span><br><span class="line">  <span class="keyword">for</span> (Operation *payloadOp : payload) &#123;</span><br><span class="line">    <span class="keyword">auto</span> call = <span class="built_in">dyn_cast</span>&lt;::mlir::func::CallOp&gt;(payloadOp);</span><br><span class="line">    <span class="keyword">if</span> (!call) &#123;</span><br><span class="line">      DiagnosedSilenceableFailure diag =</span><br><span class="line">          <span class="built_in">emitSilenceableError</span>() &lt;&lt; <span class="string">&quot;only applies to func.call payloads&quot;</span>;</span><br><span class="line">      diag.<span class="built_in">attachNote</span>(payloadOp-&gt;<span class="built_in">getLoc</span>()) &lt;&lt; <span class="string">&quot;offending payload&quot;</span>;</span><br><span class="line">      <span class="keyword">return</span> diag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">updateCallee</span>(call, <span class="built_in">getNewTarget</span>());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If everything went well, return success.</span></span><br><span class="line">  <span class="keyword">return</span> DiagnosedSilenceableFailure::<span class="built_in">success</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>side effect的interface重写：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> mlir::transform::ChangeCallTargetOp::<span class="built_in">getEffects</span>(</span><br><span class="line">    ::llvm::SmallVectorImpl&lt;::mlir::MemoryEffects::EffectInstance&gt; &amp;effects) &#123;</span><br><span class="line">  <span class="comment">// Indicate that the `call` handle is only read by this operation because the</span></span><br><span class="line">  <span class="comment">// associated operation is not erased but rather modified in-place, so the</span></span><br><span class="line">  <span class="comment">// reference to it remains valid.</span></span><br><span class="line">  <span class="built_in">onlyReadsHandle</span>(<span class="built_in">getCallMutable</span>(), effects);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Indicate that the payload is modified by this operation.</span></span><br><span class="line">  <span class="built_in">modifiesPayload</span>(effects);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>注册整个myextension：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">registerMyExtension</span><span class="params">(::mlir::DialectRegistry &amp;registry)</span> </span>&#123;</span><br><span class="line">  registry.<span class="built_in">addExtensions</span>&lt;MyExtension&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>CmakeLists.txt如下：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Outside examples, this should be `add_mlir_library`.</span></span><br><span class="line">add_mlir_dialect_library(</span><br><span class="line">  <span class="comment"># Library called MyExtension.</span></span><br><span class="line">  MyExtensionCh2</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Built from the following source files.</span></span><br><span class="line">  MyExtension.cpp</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Make includes visible without top-level path.</span></span><br><span class="line">  ADDITIONAL_HEADER_DIRS</span><br><span class="line">  <span class="variable">$&#123;PROJECT_SOURCE_DIR&#125;</span>/<span class="keyword">include</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Make sure ODS declaration and definitions are generated before compiling this.</span></span><br><span class="line">  DEPENDS</span><br><span class="line">  MyExtensionCh2IncGen</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Link in the transform dialect, an all generated dialects.</span></span><br><span class="line">  LINK_LIBS PRIVATE</span><br><span class="line">  MLIRTransformDialect</span><br><span class="line">  MLIRFuncDialect</span><br><span class="line">  MLIRSCFDialect</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h4 id="transform-opt-驱动编写"><a href="#transform-opt-驱动编写" class="headerlink" title="transform-opt 驱动编写"></a>transform-opt 驱动编写</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">//===-- transform-opt.cpp - Transform dialect tutorial entry point --------===//</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.</span></span><br><span class="line"><span class="comment">// See https://llvm.org/LICENSE.txt for license information.</span></span><br><span class="line"><span class="comment">// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//===----------------------------------------------------------------------===//</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// This is the top-level file for the Transform dialect tutorial chapter 2.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//===----------------------------------------------------------------------===//</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;MyExtension.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;mlir/Dialect/Transform/Transforms/Passes.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;mlir/IR/DialectRegistry.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;mlir/IR/MLIRContext.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;mlir/InitAllDialects.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;mlir/InitAllExtensions.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;mlir/Tools/mlir-opt/MlirOptMain.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;mlir/Transforms/Passes.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> test &#123;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">registerTestTransformDialectExtension</span><span class="params">(mlir::DialectRegistry &amp;)</span></span>;</span><br><span class="line">&#125; <span class="comment">// namespace test</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Register all &quot;core&quot; dialects and our transform dialect extension.</span></span><br><span class="line">  mlir::DialectRegistry registry;</span><br><span class="line">  mlir::<span class="built_in">registerAllDialects</span>(registry);</span><br><span class="line">  mlir::<span class="built_in">registerAllExtensions</span>(registry);</span><br><span class="line">  <span class="built_in">registerMyExtension</span>(registry);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Register transform interpreter pass.</span></span><br><span class="line">  mlir::transform::<span class="built_in">registerInterpreterPass</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Register a handful of cleanup passes that we can run to make the output IR</span></span><br><span class="line">  <span class="comment">// look nicer.</span></span><br><span class="line">  mlir::<span class="built_in">registerCanonicalizerPass</span>();</span><br><span class="line">  mlir::<span class="built_in">registerCSEPass</span>();</span><br><span class="line">  mlir::<span class="built_in">registerSymbolDCEPass</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Delegate to the MLIR utility for parsing and pass management.</span></span><br><span class="line">  <span class="keyword">return</span> mlir::<span class="built_in">MlirOptMain</span>(argc, argv, <span class="string">&quot;transform-opt-ch2&quot;</span>, registry)</span><br><span class="line">                 .<span class="built_in">succeeded</span>()</span><br><span class="line">             ? EXIT_SUCCESS</span><br><span class="line">             : EXIT_FAILURE;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>CmakeLists.txt如下：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">get_property</span>(dialect_libs GLOBAL PROPERTY MLIR_DIALECT_LIBS)</span><br><span class="line"><span class="keyword">get_property</span>(conversion_libs GLOBAL PROPERTY MLIR_CONVERSION_LIBS)</span><br><span class="line"><span class="keyword">set</span>(LIBS</span><br><span class="line">        <span class="variable">$&#123;dialect_libs&#125;</span></span><br><span class="line">        <span class="variable">$&#123;conversion_libs&#125;</span></span><br><span class="line">        MLIRIR</span><br><span class="line">        MLIRMlirOptMain</span><br><span class="line">        MLIRSideEffectInterfaces</span><br><span class="line">        MyExtensionCh2</span><br><span class="line">        )</span><br><span class="line">add_llvm_executable(transform-opt transform-opt.cpp)</span><br><span class="line"></span><br><span class="line"><span class="keyword">target_link_libraries</span>(transform-opt PRIVATE <span class="variable">$&#123;LIBS&#125;</span>)</span><br></pre></td></tr></table></figure>
<p>这部分代码和mlir代码没有区别，注册我们的myextension，然后注册各种pass，<strong>重点是注册<code>registerInterpreterPass</code>这个pass</strong>。</p>
<p>顶层CmakeLists.txt如下：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">3.20</span>.<span class="number">0</span>)</span><br><span class="line"><span class="keyword">project</span>(standalone-dialect LANGUAGES CXX C)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(CMAKE_BUILD_WITH_INSTALL_NAME_DIR <span class="keyword">ON</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_STANDARD <span class="number">17</span> CACHE <span class="keyword">STRING</span> <span class="string">&quot;C++ standard to conform to&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(CMAKE_SOURCE_DIR <span class="keyword">STREQUAL</span> CMAKE_CURRENT_SOURCE_DIR)</span><br><span class="line">  <span class="keyword">find_package</span>(MLIR REQUIRED CONFIG)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">message</span>(STATUS <span class="string">&quot;Using MLIRConfig.cmake in: $&#123;MLIR_DIR&#125;&quot;</span>)</span><br><span class="line">  <span class="keyword">message</span>(STATUS <span class="string">&quot;Using LLVMConfig.cmake in: $&#123;LLVM_DIR&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">set</span>(LLVM_RUNTIME_OUTPUT_INTDIR <span class="variable">$&#123;CMAKE_BINARY_DIR&#125;</span>/bin)</span><br><span class="line">  <span class="keyword">set</span>(LLVM_LIBRARY_OUTPUT_INTDIR <span class="variable">$&#123;CMAKE_BINARY_DIR&#125;</span>/lib)</span><br><span class="line">  <span class="keyword">set</span>(MLIR_BINARY_DIR <span class="variable">$&#123;CMAKE_BINARY_DIR&#125;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">list</span>(APPEND CMAKE_MODULE_PATH <span class="string">&quot;$&#123;MLIR_CMAKE_DIR&#125;&quot;</span>)</span><br><span class="line">  <span class="keyword">list</span>(APPEND CMAKE_MODULE_PATH <span class="string">&quot;$&#123;LLVM_CMAKE_DIR&#125;&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">include</span>(TableGen)</span><br><span class="line">  <span class="keyword">include</span>(AddLLVM)</span><br><span class="line">  <span class="keyword">include</span>(AddMLIR)</span><br><span class="line">  <span class="keyword">include</span>(HandleLLVMOptions)</span><br><span class="line"><span class="keyword">else</span>()</span><br><span class="line">  <span class="comment"># Build via external projects mechanism</span></span><br><span class="line">  <span class="keyword">set</span>(MLIR_MAIN_SRC_DIR <span class="variable">$&#123;LLVM_MAIN_SRC_DIR&#125;</span>/../mlir)</span><br><span class="line">  <span class="keyword">set</span>(MLIR_INCLUDE_DIR <span class="variable">$&#123;MLIR_MAIN_SRC_DIR&#125;</span>/<span class="keyword">include</span>)</span><br><span class="line">  <span class="keyword">set</span>(MLIR_GENERATED_INCLUDE_DIR <span class="variable">$&#123;LLVM_BINARY_DIR&#125;</span>/tools/mlir/<span class="keyword">include</span>)</span><br><span class="line">  <span class="keyword">set</span>(MLIR_INCLUDE_DIRS <span class="string">&quot;$&#123;MLIR_INCLUDE_DIR&#125;;$&#123;MLIR_GENERATED_INCLUDE_DIR&#125;&quot;</span>)</span><br><span class="line"><span class="keyword">endif</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(MLIR_ENABLE_BINDINGS_PYTHON)</span><br><span class="line">  <span class="keyword">include</span>(MLIRDetectPythonEnv)</span><br><span class="line">  mlir_configure_python_dev_packages()</span><br><span class="line"><span class="keyword">endif</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">set</span>(STANDALONE_SOURCE_DIR <span class="variable">$&#123;PROJECT_SOURCE_DIR&#125;</span>)</span><br><span class="line"><span class="keyword">set</span>(STANDALONE_BINARY_DIR <span class="variable">$&#123;PROJECT_BINARY_DIR&#125;</span>)</span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;LLVM_INCLUDE_DIRS&#125;</span>)</span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;MLIR_INCLUDE_DIRS&#125;</span>)</span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;STANDALONE_SOURCE_DIR&#125;</span>/<span class="keyword">include</span>)</span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;STANDALONE_BINARY_DIR&#125;</span>/<span class="keyword">include</span>)</span><br><span class="line"><span class="keyword">link_directories</span>(<span class="variable">$&#123;LLVM_BUILD_LIBRARY_DIR&#125;</span>)</span><br><span class="line"><span class="keyword">add_definitions</span>(<span class="variable">$&#123;LLVM_DEFINITIONS&#125;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">add_subdirectory</span>(<span class="keyword">include</span>)</span><br><span class="line"><span class="keyword">add_subdirectory</span>(lib)</span><br><span class="line"><span class="keyword">add_subdirectory</span>(transform-opt)</span><br></pre></td></tr></table></figure>
<h3 id="Transform-extension的核心实现"><a href="#Transform-extension的核心实现" class="headerlink" title="Transform extension的核心实现"></a><font color = green>Transform extension的核心实现</font></h3><p>transform extension的核心操作，就是实现<code>transform.my.change_call_target</code> op的apply方法和getEffect方法，这两个方法决定了tranform之后生成的代码等。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> mlir::transform::ChangeCallTargetOp::<span class="built_in">getEffects</span>(</span><br><span class="line">    ::llvm::SmallVectorImpl&lt;::mlir::MemoryEffects::EffectInstance&gt; &amp;effects) &#123;</span><br><span class="line">  <span class="comment">// Indicate that the `call` handle is only read by this operation because the</span></span><br><span class="line">  <span class="comment">// associated operation is not erased but rather modified in-place, so the</span></span><br><span class="line">  <span class="comment">// reference to it remains valid.</span></span><br><span class="line">  <span class="built_in">onlyReadsHandle</span>(<span class="built_in">getCallMutable</span>(), effects);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Indicate that the payload is modified by this operation.</span></span><br><span class="line">  <span class="built_in">modifiesPayload</span>(effects);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Implementation of our transform dialect operation.</span></span><br><span class="line"><span class="comment">// This operation returns a tri-state result that can be one of:</span></span><br><span class="line"><span class="comment">// - success when the transformation succeeded;</span></span><br><span class="line"><span class="comment">// - definite failure when the transformation failed in such a way that</span></span><br><span class="line"><span class="comment">//   following transformations are impossible or undesirable, typically it could</span></span><br><span class="line"><span class="comment">//   have left payload IR in an invalid state; it is expected that a diagnostic</span></span><br><span class="line"><span class="comment">//   is emitted immediately before returning the definite error;</span></span><br><span class="line"><span class="comment">// - silenceable failure when the transformation failed but following</span></span><br><span class="line"><span class="comment">//   transformations are still applicable, typically this means a precondition</span></span><br><span class="line"><span class="comment">//   for the transformation is not satisfied and the payload IR has not been</span></span><br><span class="line"><span class="comment">//   modified. The silenceable failure additionally carries a Diagnostic that</span></span><br><span class="line"><span class="comment">//   can be emitted to the user.</span></span><br><span class="line">::mlir::DiagnosedSilenceableFailure mlir::transform::ChangeCallTargetOp::<span class="built_in">apply</span>(</span><br><span class="line">    <span class="comment">// The rewriter that should be used when modifying IR.</span></span><br><span class="line">    ::mlir::transform::TransformRewriter &amp;rewriter,</span><br><span class="line">    <span class="comment">// The list of payload IR entities that will be associated with the</span></span><br><span class="line">    <span class="comment">// transform IR values defined by this transform operation. In this case, it</span></span><br><span class="line">    <span class="comment">// can remain empty as there are no results.</span></span><br><span class="line">    ::mlir::transform::TransformResults &amp;results,</span><br><span class="line">    <span class="comment">// The transform application state. This object can be used to query the</span></span><br><span class="line">    <span class="comment">// current associations between transform IR values and payload IR entities.</span></span><br><span class="line">    <span class="comment">// It can also carry additional user-defined state.</span></span><br><span class="line">    ::mlir::transform::TransformState &amp;state) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// First, we need to obtain the list of payload operations that are associated</span></span><br><span class="line">  <span class="comment">// with the operand handle.</span></span><br><span class="line">  <span class="keyword">auto</span> payload = state.<span class="built_in">getPayloadOps</span>(<span class="built_in">getCall</span>());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Then, we iterate over the list of operands and call the actual IR-mutating</span></span><br><span class="line">  <span class="comment">// function. We also check the preconditions here.</span></span><br><span class="line">  <span class="keyword">for</span> (Operation *payloadOp : payload) &#123;</span><br><span class="line">    <span class="keyword">auto</span> call = <span class="built_in">dyn_cast</span>&lt;::mlir::func::CallOp&gt;(payloadOp);</span><br><span class="line">    <span class="keyword">if</span> (!call) &#123;</span><br><span class="line">      DiagnosedSilenceableFailure diag =</span><br><span class="line">          <span class="built_in">emitSilenceableError</span>() &lt;&lt; <span class="string">&quot;only applies to func.call payloads&quot;</span>;</span><br><span class="line">      diag.<span class="built_in">attachNote</span>(payloadOp-&gt;<span class="built_in">getLoc</span>()) &lt;&lt; <span class="string">&quot;offending payload&quot;</span>;</span><br><span class="line">      <span class="keyword">return</span> diag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">updateCallee</span>(call, <span class="built_in">getNewTarget</span>());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If everything went well, return success.</span></span><br><span class="line">  <span class="keyword">return</span> DiagnosedSilenceableFailure::<span class="built_in">success</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">updateCallee</span><span class="params">(mlir::func::CallOp call, llvm::StringRef newTarget)</span> </span>&#123;</span><br><span class="line">  call.<span class="built_in">setCallee</span>(newTarget);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述两段代码注释已经非常详尽了，再次不多赘述。</p>
<h2 id="Chapter3：实现更加复杂的transform-operation"><a href="#Chapter3：实现更加复杂的transform-operation" class="headerlink" title="Chapter3：实现更加复杂的transform operation"></a><font color = brown>Chapter3：实现更加复杂的transform operation</font></h2><p>这一部分的tutorial完成两件事：</p>
<ul>
<li>给chapter2实现的transform operation针对的payload handle添加constraint trait，通过使用trait的方式简化遍历匹配<code>func::call</code>这一流程。</li>
<li>添加一个新的op，复习整个transform的流程。实现一个callOpInterface，使得handle不局限于func.call，而是只要实现了callOpInterface的op均可。</li>
</ul>
<h2 id="Chapter4：利用transform-op来做payload的匹配"><a href="#Chapter4：利用transform-op来做payload的匹配" class="headerlink" title="Chapter4：利用transform op来做payload的匹配"></a><font color = brown>Chapter4：利用transform op来做payload的匹配</font></h2><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color = brown>参考资料</font></h2><ol>
<li><a href="https://llvm.org/devmtg/2023-05/slides/Tutorial-May11/02-Zinenko-TransformDialectTutorial.pdf">transform dialect tutorial talk - EuroLLVM</a></li>
</ol>
]]></content>
      <categories>
        <category>编译技术</category>
        <category>mlir</category>
        <category>dialect学习</category>
      </categories>
      <tags>
        <tag>mlir</tag>
        <tag>dialect学习</tag>
      </tags>
  </entry>
  <entry>
    <title>tpu-mlir初探</title>
    <url>/2025/04/08/tpu-mlir%E5%88%9D%E6%8E%A2/</url>
    <content><![CDATA[<p><img src="/images/image-20250411150531193.png" alt="image-20250411150531193"></p>
<span id="more"></span>
<blockquote>
<p>TPU-MLIR是算能开发的一套端到端编译框架，支持将onnx模型编译到多款tpu上运行。该项目基于mlir，写法标准，是极佳的mlir学习项目。从中可以学到mlir的各种语法，多层级ir的设计，以及如何完成runtime的接入。</p>
</blockquote>
<h2 id="项目构建"><a href="#项目构建" class="headerlink" title="项目构建"></a><font color = brown>项目构建</font></h2><h2 id="项目架构以及技术点解读"><a href="#项目架构以及技术点解读" class="headerlink" title="项目架构以及技术点解读"></a><font color = brown>项目架构以及技术点解读</font></h2><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a><font color  = green>整体架构</font></h3><p>这一部分主要参考<a href="http://arxiv.org/abs/2210.15016">TPU-MLIR论文</a>。</p>
<p><img src="/images/image-20250411151435735.png" alt="image-20250411151435735"></p>
<p>上图中的框架，对应代码是<code>tpu-mlir/regression/run_model.py</code>。该顶层模块中调用<code>model_transfer.py</code>和<code>model_deploy.py</code>， 分别完成模型 —&gt; top ir —&gt; tpu ir 和tpu ir到<a href="https://doc.sophgo.com/docs/3.0.0/docs_latest_release/nntc/html/usage/bmodel.html">bmodel部署</a>。</p>
<p>接下来先简要用流程图的方式解读一下两个phase的驱动程序做了什么</p>
<p><code>model_transfer.py</code></p>
<pre class="mermaid">graph TD
    A[开始] --> B[初始化模型转换器]
    B --> C{选择框架类型}
    C -->|ONNX| D[创建OnnxConverter实例]
    C -->|Caffe| E[创建CaffeConverter实例]
    C -->|TFLite| F[创建TFLiteConverter实例]
    C -->|PyTorch| G[创建TorchConverter实例]
    C -->|MLIR| H[创建MlirTransformer实例]

    D --> I[生成原始MLIR]
    E --> I
    F --> I
    G --> I
    H --> I

    I --> J[执行图优化]
    J --> K[应用模式匹配优化]
    K --> L{是否验证模型}
    L -->|是| M[加载测试数据]
    M --> N[原始模型推理]
    N --> O[MLIR模型推理]
    O --> P[结果对比验证]
    P --> Q[输出验证结果]
    L -->|否| R[跳过验证]

    Q --> S[清理临时文件]
    R --> S
    S --> T[结束]

    style A fill:#90EE90,stroke:#4CAF50
    style B fill:#FFD700,stroke:#FFA500
    style C fill:#87CEEB,stroke:#1E90FF
    style D,E,F,G,H fill:#E1BEE7,stroke:#9C27B0
    style I,J,K fill:#BBDEFB,stroke:#2196F3
    style L fill:#FFCCCC,stroke:#FF5252
    style M,N,O,P,Q fill:#C8E6C9,stroke:#4CAF50
    style R,S,T fill:#FFE0B2,stroke:#FF9800</pre>

<p><code>model_deploy.py</code></p>
<pre class="mermaid">graph TD
    A[开始] --> B[解析命令行参数]
    B --> C{芯片类型?}
    C --> |CPU| D[生成TOSA MLIR]
    C --> |其他芯片| E[生成TPU MLIR]
    D --> F[保存TOSA MLIR]
    E --> G[执行MLIR验证]
    G --> H{验证通过?}
    H --> |是| I[编译生成BModel]
    H --> |否| Z[报错退出]
    I --> J{启用验证?}
    J --> |是| K[执行BModel推理验证]
    J --> |否| L[跳过验证]
    K --> M{验证通过?}
    M --> |是| N[清理临时文件]
    M --> |否| Z
    N --> O[保存BModel]
    L --> O
    O --> P[结束]

    style A fill:#f9f,stroke:#333
    style Z fill:#f00,stroke:#333
    style O fill:#0f0,stroke:#333</pre>

<p>上述两个流程图讲解比较宏观，参考<a href="https://tpumlir.org/docs/developer_manual/04_over_design.html">TPU-MLIR 官方文档</a>理解更细节的mlir转换图。</p>
<h3 id="架构亮点"><a href="#架构亮点" class="headerlink" title="架构亮点"></a><font color = green>架构亮点</font></h3><blockquote>
<p>TPU-MLIR项目的价值一是提供mlir学习资料，整个项目的架构和实现比较简洁，二是提供tpu设计思路，此部分值得我们重点关注</p>
</blockquote>
<ul>
<li><strong>ONNX converter</strong>：用python编写的前端工具，可以用来参考如何将高级语言快速转换为mlir ir。</li>
<li><strong>多层级ir</strong>：TPU-MLIR设计了Top dialect和Tpu dialect，是比较经典的ir设计（硬件无关ir，统一不同模型框架语义，以及硬件相关ir，负责提供硬件抽象），诸如GLOW编译器也是这种ir设计。可以用来参考如何使用mlir系统设计ir抽象。</li>
<li><strong>优化pass</strong>：这一部分是TPU-MLIR的一个重点，主要有如下方面。<ul>
<li>动态shape，TPU-MLIR是支持动态shape的inference的，可以做参考</li>
<li>高层算子融合pass</li>
<li>TPU相关pass，这一部分是后续重点关注pass。包括：<ul>
<li>TPU inference，主要借助于onnx 的runtime，后续会专门介绍</li>
<li>weight-reorder，op-reorder等tpu专属优化</li>
<li>layer group优化，类似局部缓存融合优化（<a href="https://dl.acm.org/doi/10.1145/3503222.3507723">Astitch论文</a>），后续专门介绍</li>
</ul>
</li>
<li>量化，TPU-MLIR对于量化操作做了诸多考量，包含带<strong>calibration的量化</strong>，对称量化和非对称量化等。</li>
</ul>
</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color = brown>参考资料</font></h2><ol>
<li><a href="https://github.com/micropuma/tpu-mlir">TPU-MLIR github</a></li>
<li><a href="http://arxiv.org/abs/2210.15016">TPU-MLIR论文</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/613328745">TPU-MLIR博客</a></li>
</ol>
]]></content>
      <categories>
        <category>编译技术</category>
        <category>机器学习编译</category>
        <category>TPU技术</category>
        <category>量化技术</category>
      </categories>
      <tags>
        <tag>机器学习编译器</tag>
        <tag>mlir</tag>
        <tag>异构计算系统</tag>
      </tags>
  </entry>
  <entry>
    <title>计算密集算子融合</title>
    <url>/2025/03/31/%E8%AE%A1%E7%AE%97%E5%AF%86%E9%9B%86%E7%AE%97%E5%AD%90%E8%9E%8D%E5%90%88/</url>
    <content><![CDATA[<p><img src="/images/image-20250331211738664.png" alt="image-20250331211738664"></p>
<span id="more"></span>
<blockquote>
<p>机器学习中算子可以分为<strong>计算密集算子</strong>和<strong>访存密集算子</strong>，之前的博客已经讲解了<strong>访存密集算子融合技术</strong>，本文重点解读计算密集算子融合，即针对gemm等算子的计算优化。本文主要结合BladeDISC和Rammer等文章加以解读</p>
</blockquote>
<h2 id="BladeDISC的计算密集算子融合"><a href="#BladeDISC的计算密集算子融合" class="headerlink" title="BladeDISC的计算密集算子融合"></a><font color = brown>BladeDISC的计算密集算子融合</font></h2><h3 id="计算密集算子融合pipeline-overview"><a href="#计算密集算子融合pipeline-overview" class="headerlink" title="计算密集算子融合pipeline overview"></a><font color = green>计算密集算子融合pipeline overview</font></h3><p>在<code>BladeDISC</code>项目的pipeline中，涉及计算密集算子融合有三处：</p>
<h4 id="针对简单的mhlo-dot算子做融合"><a href="#针对简单的mhlo-dot算子做融合" class="headerlink" title="针对简单的mhlo_dot算子做融合"></a>针对简单的mhlo_dot算子做融合</h4><p><img src="/images/image-20250403152318767.png" alt="image-20250403152318767"></p>
<p>具体流程图如下：</p>
<pre class="mermaid">flowchart TD
    A[开始: DiscDotMergePass] --> B[执行共享操作数合并]
    B --> C[执行批量合并]
    C --> D{合并成功?}
    D -->|是| E[结束]
    D -->|否| F[标记失败]

    subgraph 共享操作数合并流程
        B1[遍历所有基本块] --> B2[初始化ShareOperandMap]
        B2 --> B3[遍历block中的DotGeneralOp]
        B3 --> B4[提取共享操作数和维度信息]
        B4 --> B5[构建聚类映射]
        B5 --> B6[检测循环依赖]
        B6 --> B7[尝试合并聚类]
        B7 --> B8[应用合并操作]
        B8 --> B9[清理原始操作]
    end

    subgraph 批量合并流程
        C1[形状分析] --> C2[构建MergingShapeMap]
        C2 --> C3[检测可合并聚类]
        C3 --> C4[维度扩展操作]
        C4 --> C5[创建批量concat]
        C5 --> C6[生成批量dot]
        C6 --> C7[切片替换原始操作]
        C7 --> C8[清理原始操作]
    end

    B -->|核心操作| B1
    C -->|核心操作| C1
    B9 -->|清理后| C
    C8 --> D</pre>

<h4 id="混合精度优化"><a href="#混合精度优化" class="headerlink" title="混合精度优化"></a>混合精度优化</h4><p><img src="/images/image-20250402205232495.png" alt="image-20250402205232495"></p>
<h4 id="针对GEMM做layout优化"><a href="#针对GEMM做layout优化" class="headerlink" title="针对GEMM做layout优化"></a>针对GEMM做layout优化</h4><p><img src="/images/image-20250402205308725.png" alt="image-20250402205308725"></p>
<p>具体流程图如下：</p>
<pre class="mermaid">graph TD
    A[原始卷积操作 mhlo::ConvolutionOp] --> B[转换为 DynamicConvOp]
    B --> C[提取卷积参数]
    C --> D[推断预期布局]
    D --> E{当前布局符合预期?}
    E -->|是| F[保持原布局]
    E -->|否| G[插入转置操作调整布局]
    G --> H[输入布局调整]
    G --> I[滤波器布局调整]
    G --> J[输出布局调整]
    H --> K[更新输入布局]
    I --> L[更新滤波器布局]
    J --> M[更新输出布局]
    K --> N[更新卷积属性]
    L --> N
    M --> N
    N --> O[优化后的卷积操作]

    P[量化卷积操作 QuantizedDynamicConvOp] --> C
    Q[GPU/CUDA环境] --> D
    R[CPU环境] --> D

    style A fill:#f9d,stroke:#333
    style P fill:#f9d,stroke:#333
    style B fill:#bbf,stroke:#333
    style C fill:#cfc,stroke:#333
    style D fill:#cfc,stroke:#333
    style E fill:#ffd,stroke:#333
    style G fill:#fcc,stroke:#333
    style N fill:#cfc,stroke:#333
    style O fill:#9f9,stroke:#333</pre>

]]></content>
      <categories>
        <category>编译技术</category>
        <category>机器学习编译</category>
        <category>计算优化</category>
      </categories>
      <tags>
        <tag>机器学习编译器</tag>
        <tag>mlir</tag>
        <tag>算子融合技术</tag>
      </tags>
  </entry>
  <entry>
    <title>访存密集算子融合</title>
    <url>/2025/04/01/%E8%AE%BF%E5%AD%98%E5%AF%86%E9%9B%86%E7%AE%97%E5%AD%90%E8%9E%8D%E5%90%88/</url>
    <content><![CDATA[<p><img src="/images/image-20250331214150737.png" alt="image-20250331214150737"></p>
<span id="more"></span>
<blockquote>
<p>这是算子优化系列的第一篇，主要聚焦于存储密集型算子的融合优化。探讨这一主题的动机源于 BladeDISC 编译器，这个由阿里云开发的编译器专注于解决动态 shape 问题，并在大模型业务中实现了显著的优化。BladeDISC 的一大亮点是复用了 astitch 论文中提出的多元访存算子融合方法，因此，本文将对这一问题展开深入讨论，从两方面来分析：XLA传统融合和BladeDISC使用的stich融合。</p>
</blockquote>
<h2 id="XLA代码解析"><a href="#XLA代码解析" class="headerlink" title="XLA代码解析"></a><font color = brown>XLA代码解析</font></h2><p>在阿里的bladedisc的ppt中，可以看到如下总结：</p>
<p><img src="/images/image-20250325195503234.png" alt="image-20250325195503234"></p>
<p>先考虑从<code>mlir-hlo</code>项目入手，理解xla alike的fusion是如何做的。具体代码在<a href="https://github.com/tensorflow/mlir-hlo/blob/1857b1eac21ef5b30b088ccc79ef2fa0e3161621/lib/Dialect/mhlo/transforms/mhlo_fusion.cc#L549">mhlo_fusion.cc</a>中。上述图片其实已经总结了XLA可以做的两种kernel fusion方式：<code>KLoop</code>和<code>KInput</code>。可以看出，<code>XLA</code>还是重点关注的算子pattern是比较简单的。</p>
<h3 id="Source-Code源码分析"><a href="#Source-Code源码分析" class="headerlink" title="Source Code源码分析"></a><font color = green>Source Code源码分析</font></h3><blockquote>
<p>核心原理是通过<strong>形状约束分析</strong>和图论中的<strong>边收缩算法</strong>，动态识别可融合的操作组，并生成高效的融合计划。</p>
<font color = red>形状约束是阿里团队提出的动态shape约束。</font>

</blockquote>
<p>该代码是典型的两阶段code，第一阶段分析出fusion plan，第二阶段应用fusion plan做相应的fusion：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">runOnOperation</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    FuncOp func = <span class="built_in">getOperation</span>();</span><br><span class="line">    <span class="keyword">if</span> (!<span class="built_in">IsTargetFunc</span>(func)) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// process each block and do fusion within a block.</span></span><br><span class="line">    <span class="keyword">for</span> (Block&amp; block : func) &#123;</span><br><span class="line">      <span class="comment">// 收集一个block内部的所有operation list</span></span><br><span class="line">      SmallVector&lt;Operation*, <span class="number">4</span>&gt; op_list;</span><br><span class="line">      <span class="keyword">for</span> (Operation&amp; op : block) &#123;</span><br><span class="line">        op_list.<span class="built_in">push_back</span>(&amp;op);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="function">FusionPlanner <span class="title">planner</span><span class="params">(op_list)</span></span>;</span><br><span class="line">      llvm::Optional&lt;FusionPlan&gt; plan = planner.<span class="built_in">Run</span>();</span><br><span class="line">      <span class="keyword">if</span> (!plan) &#123;</span><br><span class="line">        <span class="built_in">emitError</span>(func.<span class="built_in">getLoc</span>(), <span class="string">&quot;can&#x27;t find a fusion plan&quot;</span>);</span><br><span class="line">        <span class="built_in">signalPassFailure</span>();</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (!<span class="built_in">ApplyFusionPlan</span>(*plan)) &#123;</span><br><span class="line">        <span class="built_in">emitError</span>(func.<span class="built_in">getLoc</span>(), <span class="string">&quot;apply fusion plan failed&quot;</span>);</span><br><span class="line">        <span class="built_in">signalPassFailure</span>();</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>上述代码段时整个pass的入口，也是整体流程控制。</p>
<ul>
<li><code>FusionPlanner planner(op_list)</code>针对一个block的oplist，初始化一个fusion plan。</li>
<li><code>planner.Run()</code>根据planner构建的图，做子图划分，生成潜在的fusion pattern集和。</li>
<li><code>ApplyFusionPlan</code>为第二阶段，将fusion pattern list用于代码改写，完成最终的fusion操作。</li>
</ul>
<p>接下来分别展开这三个函数。</p>
<h4 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h4><p>下面先来介绍一些辅助函数：</p>
<ol>
<li><p>首先，先明确<code>XLA Fusion</code>的几个<strong>基本数据结构概念</strong>：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> FusionPattern = std::vector&lt;Operation*&gt;;</span><br><span class="line"><span class="keyword">using</span> FusionPlan = std::vector&lt;FusionPattern&gt;;</span><br></pre></td></tr></table></figure>
<p>FusionPattern是可融合的operation集和。FusionPlan是FusionPattern集和。</p>
</li>
<li><p><code>XLA</code>针对memory-intensive的算子，主要考虑如下两个算子：<code>ReduceOp</code>和<code>element-wiseOp</code>。分别有如下可能的融合方案：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// reduceOp主要判断，其operand的define point的op是否shape相同</span></span><br><span class="line"><span class="comment">// 如果相同，reduceOp考虑的模式是operand融合</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">IsFusibleWithOperand</span><span class="params">(Operation* op)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 相比IsFusibleWithConsumer，支持reduce op</span></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">IsMhlo</span>(op) &amp;&amp;</span><br><span class="line">         (op-&gt;<span class="built_in">hasTrait</span>&lt;::mlir::OpTrait::Elementwise&gt;() || <span class="built_in">isa</span>&lt;ReduceOp&gt;(op));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// element-wise操作或是常量操作，可以考虑是否可以和consumer融合</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">IsFusibleWithConsumer</span><span class="params">(Operation* op)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 必须是MHLO操作，并且是elementwise操作，或是常量操作</span></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">IsMhlo</span>(op) &amp;&amp; (op-&gt;<span class="built_in">hasTrait</span>&lt;::mlir::OpTrait::Elementwise&gt;() ||</span><br><span class="line">                        <span class="built_in">matchPattern</span>(op, <span class="built_in">m_Constant</span>()));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局的isFusible判断</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">IsFusible</span><span class="params">(Operation* op)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 只有常量操作或是能和consumer融合的操作才是可融合的，或是能和operand融合的操作</span></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">matchPattern</span>(op, <span class="built_in">m_Constant</span>()) || <span class="built_in">IsFusibleWithConsumer</span>(op) ||</span><br><span class="line">         <span class="built_in">IsFusibleWithOperand</span>(op);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>针对<code>FusionPattern</code>和其他block的交互：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">SmallVector&lt;Value, 4&gt; <span class="title">GetInputsOfFusionPattern</span><span class="params">(<span class="type">const</span> FusionPattern&amp; pattern)</span> </span>&#123;</span><br><span class="line">  SmallVector&lt;Value, <span class="number">4</span>&gt; inputs;</span><br><span class="line">  DenseSet&lt;Value&gt; input_set;</span><br><span class="line">  DenseSet&lt;Operation*&gt; op_set;</span><br><span class="line">  <span class="comment">// 收集一个fusion pattern里的所有operation</span></span><br><span class="line">  <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">    <span class="type">bool</span> inserted = op_set.<span class="built_in">insert</span>(op).second;</span><br><span class="line">    (<span class="type">void</span>)inserted;</span><br><span class="line">    <span class="built_in">assert</span>(inserted &amp;&amp; <span class="string">&quot;FusionPattern contains duplicate operations&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">    <span class="keyword">for</span> (Value operand : op-&gt;<span class="built_in">getOperands</span>()) &#123;</span><br><span class="line">      Operation* operand_op = operand.<span class="built_in">getDefiningOp</span>();</span><br><span class="line">      <span class="comment">// 如果defining op在pattern里，则跳过</span></span><br><span class="line">      <span class="comment">// 否则加入到inputs中，表示是该潜在的fusion pattern的输入</span></span><br><span class="line">      <span class="keyword">if</span> (op_set.<span class="built_in">find</span>(operand_op) != op_set.<span class="built_in">end</span>()) &#123;</span><br><span class="line">        <span class="comment">// skip if defining op is in the pattern</span></span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (input_set.<span class="built_in">insert</span>(operand).second) &#123;</span><br><span class="line">        inputs.<span class="built_in">push_back</span>(operand);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> inputs;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 收集融合操作中所有被外部使用的输出，作为融合后的输出</span></span><br><span class="line"><span class="function">SmallVector&lt;Value, 4&gt; <span class="title">GetOutputsOfFusionPattern</span><span class="params">(<span class="type">const</span> FusionPattern&amp; pattern)</span> </span>&#123;</span><br><span class="line">  SmallVector&lt;Value, <span class="number">4</span>&gt; outputs;</span><br><span class="line">  DenseSet&lt;Operation*&gt; op_set;</span><br><span class="line">  <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">    <span class="comment">// 检查是否有重复的operation</span></span><br><span class="line">    <span class="type">bool</span> inserted = op_set.<span class="built_in">insert</span>(op).second;</span><br><span class="line">    (<span class="type">void</span>)inserted;</span><br><span class="line">    <span class="built_in">assert</span>(inserted &amp;&amp; <span class="string">&quot;FusionPattern contains duplicate operations&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 尝试做融合的operation</span></span><br><span class="line">  <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">    <span class="keyword">for</span> (Value result : op-&gt;<span class="built_in">getResults</span>()) &#123;</span><br><span class="line">      <span class="comment">// 判断该operation是否result有被外部使用</span></span><br><span class="line">      <span class="type">bool</span> has_external_user = llvm::<span class="built_in">any_of</span>(</span><br><span class="line">          result.<span class="built_in">getUses</span>(),</span><br><span class="line">          [&amp;](OpOperand&amp; use) &#123; <span class="keyword">return</span> !op_set.<span class="built_in">count</span>(use.<span class="built_in">getOwner</span>()); &#125;);</span><br><span class="line">      <span class="comment">// 显示收集被外部使用的output</span></span><br><span class="line">      <span class="keyword">if</span> (has_external_user) &#123;</span><br><span class="line">        outputs.<span class="built_in">push_back</span>(result);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> outputs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述两个函数支持获取FusionPattern的外部输入和输出。</p>
</li>
<li><p>合并两个<code>FusionPattern</code>，这个函数比较重要，其实就是发现可以合并融合的operation list，扩大单个fusion region：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">FusionPattern <span class="title">MergeFusionPattern</span><span class="params">(<span class="type">const</span> FusionPattern&amp; lhs,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 <span class="type">const</span> FusionPattern&amp; rhs)</span> </span>&#123;</span><br><span class="line">  <span class="function">FusionPattern <span class="title">pattern</span><span class="params">(lhs)</span></span>;</span><br><span class="line">  pattern.<span class="built_in">insert</span>(pattern.<span class="built_in">end</span>(), rhs.<span class="built_in">begin</span>(), rhs.<span class="built_in">end</span>());</span><br><span class="line">  <span class="keyword">return</span> pattern;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>并查集用于做shape推导，<font color = red>注意，XLA的fusion中，shape 推导是比较简单的</font>:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ShapeConstraintAnalysis</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">ShapeConstraintAnalysis</span><span class="params">(<span class="type">const</span> SmallVectorImpl&lt;Operation*&gt;&amp; op_list)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">PropagateEquality</span>(op_list);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Returns true is `lhs` and `rhs` are supposed to have same shape.</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">HasSameShape</span><span class="params">(Value lhs, Value rhs)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 单纯判断两者在unionfind中的位置是否相同</span></span><br><span class="line">    <span class="keyword">return</span> impl_.<span class="built_in">isEquivalent</span>(<span class="built_in">ValueWrapper</span>(lhs), <span class="built_in">ValueWrapper</span>(rhs));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// shape equality propagation based on the shape constrains of</span></span><br><span class="line">  <span class="comment">// elementwise ops.</span></span><br><span class="line">  <span class="comment">// 针对elementwise操作，做shape相等传播</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">PropagateEquality</span><span class="params">(<span class="type">const</span> SmallVectorImpl&lt;Operation*&gt;&amp; op_list)</span> </span>&#123;</span><br><span class="line">    <span class="type">bool</span> converged = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">      converged = <span class="literal">true</span>;</span><br><span class="line">      <span class="comment">// 显示对两个value做unionfind</span></span><br><span class="line">      <span class="keyword">auto</span> update = [&amp;](Value lhs, Value rhs) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!impl_.<span class="built_in">isEquivalent</span>(<span class="built_in">ValueWrapper</span>(lhs), <span class="built_in">ValueWrapper</span>(rhs))) &#123;</span><br><span class="line">          <span class="comment">// 有更改，说明还没有完全收敛</span></span><br><span class="line">          converged = <span class="literal">false</span>;</span><br><span class="line">          impl_.<span class="built_in">unionSets</span>(<span class="built_in">ValueWrapper</span>(lhs), <span class="built_in">ValueWrapper</span>(rhs));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;;</span><br><span class="line">      <span class="keyword">for</span> (Operation* op : op_list) &#123;</span><br><span class="line">        <span class="comment">// 只对有InferShapeEqualityOpInterface trait的operation做shape相等传播</span></span><br><span class="line">        <span class="keyword">auto</span> op_fusibility = <span class="built_in">dyn_cast</span>&lt;InferShapeEqualityOpInterface&gt;(op);</span><br><span class="line">        <span class="keyword">if</span> (!op_fusibility) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> numInput = op-&gt;<span class="built_in">getNumOperands</span>();</span><br><span class="line">        <span class="type">int</span> numOutput = op-&gt;<span class="built_in">getNumResults</span>();</span><br><span class="line">        <span class="comment">// shape equality propagation between inputs.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> input1 = <span class="number">0</span>; input1 &lt; numInput; ++input1)</span><br><span class="line">          <span class="keyword">for</span> (<span class="type">int</span> input2 = input1 + <span class="number">1</span>; input2 &lt; numInput; ++input2)</span><br><span class="line">            <span class="comment">// 通过op_fusibility.inferInputsShapeEquality函数判断两个input是否shape相等</span></span><br><span class="line">            <span class="keyword">if</span> (op_fusibility.<span class="built_in">inferInputsShapeEquality</span>(input1, input2))</span><br><span class="line">              <span class="built_in">update</span>(op-&gt;<span class="built_in">getOperand</span>(input1), op-&gt;<span class="built_in">getOperand</span>(input2));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// shape equality propagation between outputs.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> output1 = <span class="number">0</span>; output1 &lt; numOutput; ++output1)</span><br><span class="line">          <span class="keyword">for</span> (<span class="type">int</span> output2 = output1 + <span class="number">1</span>; output2 &lt; numOutput; ++output2)</span><br><span class="line">            <span class="comment">// 同理，判断两个output是否shape相等</span></span><br><span class="line">            <span class="keyword">if</span> (op_fusibility.<span class="built_in">inferOutputsShapeEquality</span>(output1, output2))</span><br><span class="line">              <span class="built_in">update</span>(op-&gt;<span class="built_in">getResult</span>(output1), op-&gt;<span class="built_in">getResult</span>(output2));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// shape equality propagation between input and output.</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> input = <span class="number">0</span>; input &lt; numInput; ++input)</span><br><span class="line">          <span class="keyword">for</span> (<span class="type">int</span> output = <span class="number">0</span>; output &lt; numOutput; ++output)</span><br><span class="line">            <span class="comment">// 最关键的步骤，判断input和output是否shape相等</span></span><br><span class="line">            <span class="keyword">if</span> (op_fusibility.<span class="built_in">inferInputOutputShapeEquality</span>(input, output))</span><br><span class="line">              <span class="comment">// 如果相等，则调用lambda函数，将两者做unionfind</span></span><br><span class="line">              <span class="built_in">update</span>(op-&gt;<span class="built_in">getOperand</span>(input), op-&gt;<span class="built_in">getResult</span>(output));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> (!converged);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// a UnionFind set</span></span><br><span class="line">  <span class="comment">// 使用LLVM提供的内置UF集和</span></span><br><span class="line">  EquivalenceClasses&lt;ValueWrapper&gt; impl_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="planner的初始化"><a href="#planner的初始化" class="headerlink" title="planner的初始化"></a>planner的初始化</h4><p>FusionPlanner的初始化逻辑是比较简单的：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FusionPlanner</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">FusionPlanner</span><span class="params">(<span class="type">const</span> SmallVectorImpl&lt;Operation*&gt;&amp; op_list)</span></span></span><br><span class="line"><span class="function">      : op_list_(op_list),</span></span><br><span class="line"><span class="function">        shape_analysis_(op_list),</span></span><br><span class="line"><span class="function">        cycle_detector_(op_list.size()) &#123;</span></span><br><span class="line">    <span class="comment">// 构建初始的cluster图</span></span><br><span class="line">    <span class="built_in">BuildNodeMap</span>();</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>主要干了如下事情：</p>
<ol>
<li>初始化op<em>list</em>，用于后续的fusion</li>
<li>初始化shape<em>analysis</em>工具，用于知道fusion的shape compatible analysis</li>
<li>初始化cycle detector，<code>XLA</code>的fusion中，一个条件是不能引入loop</li>
</ol>
<p>最后构建一个nodemap，构建一个cluster图，用于后续子图生成，op遍历。</p>
<p>成员变量如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">const</span> SmallVectorImpl&lt;Operation*&gt;&amp; op_list_;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Shape equality checker</span></span><br><span class="line">ShapeConstraintAnalysis shape_analysis_;</span><br><span class="line"></span><br><span class="line"><span class="comment">// op -&gt; node_id</span></span><br><span class="line">std::unordered_map&lt;Operation*, <span class="type">int</span>&gt; op_to_node_id_;</span><br><span class="line"></span><br><span class="line"><span class="comment">// make sure not introduce cycle after fusion</span></span><br><span class="line">GraphCycles cycle_detector_;</span><br><span class="line">std::vector&lt;std::unique_ptr&lt;Cluster&gt;&gt; cluster_storage_;</span><br><span class="line"></span><br><span class="line"><span class="comment">// a UnionFind set. Each set represents a (partial) fused pattern</span></span><br><span class="line"><span class="comment">// and has a leader as representation.</span></span><br><span class="line">EquivalenceClasses&lt;<span class="type">int32_t</span>&gt; leader_for_node_;</span><br></pre></td></tr></table></figure>
<p>构建图的逻辑如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">BuildNodeMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 当前初始构建图，每个operation为一个node，为一个cluster的head，并leader_for_node_的并查集存储</span></span><br><span class="line">    <span class="type">int</span> num_nodes = op_list_.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> node_id = <span class="number">0</span>; node_id &lt; num_nodes; ++node_id) &#123;</span><br><span class="line">      <span class="comment">// 针对当前operation，构建一个cluster</span></span><br><span class="line">      <span class="comment">// 并设定当前op为cluster的头leader</span></span><br><span class="line">      Operation* op = op_list_[node_id];</span><br><span class="line">      <span class="built_in">MakeCluster</span>(node_id);</span><br><span class="line">      op_to_node_id_[op] = node_id;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// learder_for_node_是一个UnionFind set</span></span><br><span class="line">      leader_for_node_.<span class="built_in">insert</span>(node_id);</span><br><span class="line">      <span class="keyword">for</span> (Value operand : op-&gt;<span class="built_in">getOperands</span>()) &#123;</span><br><span class="line">        Operation* operand_op = operand.<span class="built_in">getDefiningOp</span>();</span><br><span class="line">        <span class="keyword">if</span> (operand_op == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">          <span class="comment">// skip block argument</span></span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 检查operand的def point是否属于别的融合组</span></span><br><span class="line">        <span class="comment">// 显示构建依赖关系</span></span><br><span class="line">        <span class="keyword">auto</span> iter = op_to_node_id_.<span class="built_in">find</span>(operand_op);</span><br><span class="line">        <span class="built_in">assert</span>(iter != op_to_node_id_.<span class="built_in">end</span>());</span><br><span class="line">        cycle_detector_.<span class="built_in">InsertEdge</span>(iter-&gt;second, node_id);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>遍历每一个op，在unionfind中，每一个op为一个cluster，后续fusion操作才会融合cluster。</li>
<li>初始化op<em>to_node_id</em>等的映射方式，unionfind中存储的是该op的node_id，即在当前fusionplan中的次序号。</li>
<li>operand的define op和当前op，在cycle_detector中显示插入依赖链条。</li>
</ul>
<p>上述整体逻辑是十分清楚的。</p>
<p>在FusionPlanner中，有一个私有类是<code>Cluster</code>：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Represent a (partial) fused pattern</span></span><br><span class="line">  <span class="comment">// 根据注释，这个cluster类并不是完整的融合模式，而是一个融合模式的一部分</span></span><br><span class="line">  <span class="comment">// 这是unionfind的思想，每个cluster都是一个融合模式的一部分，最终通过unionfind合并</span></span><br><span class="line">  <span class="keyword">class</span> <span class="title class_">Cluster</span> &#123;</span><br><span class="line">   <span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Cluster</span>(<span class="type">int</span> node_id, FusionPlanner* planner) : <span class="built_in">node_id_</span>(node_id) &#123;</span><br><span class="line">      <span class="type">const</span> SmallVectorImpl&lt;Operation*&gt;&amp; op_list = planner-&gt;<span class="built_in">op_list</span>();</span><br><span class="line">      pattern_.<span class="built_in">push_back</span>(op_list[node_id]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Merges `other` into this cluster, and clears `other`.</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">Merge</span><span class="params">(Cluster* other)</span> </span>&#123;</span><br><span class="line">      pattern_.<span class="built_in">insert</span>(pattern_.<span class="built_in">end</span>(), other-&gt;pattern_.<span class="built_in">begin</span>(),</span><br><span class="line">                      other-&gt;pattern_.<span class="built_in">end</span>());</span><br><span class="line">      other-&gt;pattern_.<span class="built_in">clear</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The number of nodes in this cluster.</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">cluster_size</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> pattern_.<span class="built_in">size</span>(); &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The ID of the cluster as represented in `cycle_detector_`.</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">cycles_graph_node_id</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> node_id_; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Sets the ID of the cluster as represented in `cycle_detector_`.</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">set_cycles_graph_node_id</span><span class="params">(<span class="type">int</span> cycles_graph_node_id)</span> </span>&#123;</span><br><span class="line">      node_id_ = cycles_graph_node_id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Currently the fused pattern this cluster holds.</span></span><br><span class="line">    <span class="function"><span class="type">const</span> FusionPattern&amp; <span class="title">fused_pattern</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> pattern_; &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span>:</span><br><span class="line">    <span class="comment">// ID of the representative node of this cluster.</span></span><br><span class="line">    <span class="type">int</span> node_id_;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the fused pattern this cluster holds.</span></span><br><span class="line">    FusionPattern pattern_;</span><br><span class="line">  &#125;;</span><br></pre></td></tr></table></figure>
<p>上述cluster最主要的功能，就是可以对于cluster中的operation，显示记录他们可以应用的<code>FusionPattern</code>。同时还支持merge操作，将cluster之间进行fusion。该原理是将另一个cluster的pattern拷贝入当前cluster，并清空另一个cluster的pattern。</p>
<p><img src="images/2.png" alt="2"></p>
<h4 id="planner运行"><a href="#planner运行" class="headerlink" title="planner运行"></a>planner运行</h4><p>核心部分，主要作用是构建cluster融合，并给对应cluster赋予fusion pattern。</p>
<p>主函数如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Returns a fusion plan if success, otherwise none.</span></span><br><span class="line">  <span class="comment">// 返回一个fusion plan，如果没有找到则返回none</span></span><br><span class="line">  <span class="function">llvm::Optional&lt;FusionPlan&gt; <span class="title">Run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Greedily search connected fusible pattern, and ops belonging to</span></span><br><span class="line">    <span class="comment">// a same fusion pattern are grouped into a cluster.</span></span><br><span class="line">    <span class="comment">// 每一个op有一个可融合的pattern，找寻compatible的pattern并合并对应的operation</span></span><br><span class="line">    <span class="built_in">RunEdgeContractionLoop</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// After doing edge contraction, each unique cluster having size</span></span><br><span class="line">    <span class="comment">// more than one represents a potential fusion pattern.</span></span><br><span class="line">    <span class="comment">// We collect all these clusters and construct a fusion plan.</span></span><br><span class="line">    <span class="comment">// union find中，每一个有大于1的size的cluster都是一个融合模式</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Note that the ops in a fusion pattern are in topological ordering.</span></span><br><span class="line">    <span class="comment">// fusion pattern中的operation是按照拓扑排序的</span></span><br><span class="line">    <span class="comment">// 得到一个fusion plan集合后，后续apply这些fusion plan即可</span></span><br><span class="line">    FusionPlan plan;</span><br><span class="line">    DenseMap&lt;<span class="type">int</span>, <span class="type">int</span>&gt; pattern_ids;</span><br><span class="line">    <span class="keyword">for</span> (Operation* op : op_list_) &#123;</span><br><span class="line">      <span class="comment">// 获取该op所属的cluster</span></span><br><span class="line">      Cluster* cluster = <span class="built_in">GetClusterForNode</span>(op);</span><br><span class="line">      <span class="type">int</span> node_id = cluster-&gt;<span class="built_in">cycles_graph_node_id</span>();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 不可融合或是融合模式的size小于等于1，跳过</span></span><br><span class="line">      <span class="keyword">if</span> (!<span class="built_in">IsFusible</span>(op_list_[node_id]) ||</span><br><span class="line">          <span class="built_in">EffectiveSize</span>(<span class="built_in">GetClusterForNode</span>(op)-&gt;<span class="built_in">fused_pattern</span>()) &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (!pattern_ids.<span class="built_in">count</span>(node_id)) &#123;</span><br><span class="line">        <span class="type">int</span> pattern_id = pattern_ids.<span class="built_in">size</span>();</span><br><span class="line">        pattern_ids[node_id] = pattern_id;</span><br><span class="line">        plan.<span class="built_in">emplace_back</span>();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 特定的plan后添加operation</span></span><br><span class="line">      plan[pattern_ids[node_id]].<span class="built_in">push_back</span>(op);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> plan;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里需要理解一个重要的点：每一个cluster都有一个list，该list存储所有的fusion Pattern，一个cluster是否可以做融合，其实就是看发现了多少个fusion Pattern。</p>
<ul>
<li>如果fusion pattern &gt; 1，则其<strong>内部可以融合</strong>。</li>
<li>如果cluster之间有兼容的fusion pattern，则<strong>intra cluster 融合</strong>是ok的。</li>
</ul>
<font color =red>识别出潜在的fusion后，构造fusion plan：一个fusion pattern的vector存储结构。</font>

</blockquote>
<p>上述code可以分为两大阶段：<code>RunEdgeContractionLoop()</code>和融合pattern收集。</p>
<p><img src="/images/1.png" alt="1"></p>
<p>上述是一个完整的流程图。可以看出，run()函数最重要的function是<code>RunEdgeContractionLoop()</code>。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Greedily fuse connected node.</span></span><br><span class="line"><span class="comment">// 贪心算法，融合可融合的node</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">RunEdgeContractionLoop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">using</span> std::placeholders::_1;</span><br><span class="line">    <span class="keyword">using</span> std::placeholders::_2;</span><br><span class="line">    <span class="comment">// 理解std::bind操作</span></span><br><span class="line">    <span class="comment">// 给TryToContractEdge函数绑定了两个参数，第一个参数是this指针，第二个参数是_1和_2，是占位符</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">ForEachEdgeInPostOrder</span>(</span><br><span class="line">        std::<span class="built_in">bind</span>(&amp;FusionPlanner::TryToContractEdge, <span class="keyword">this</span>, _1, _2));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于graph做后序遍历，并<strong>贪心引用边收缩算法</strong>。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 按照后序遍历的顺序，对每一个edge执行fn函数</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> FnTy&gt;</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">ForEachEdgeInPostOrder</span><span class="params">(FnTy fn)</span> </span>&#123;</span><br><span class="line"><span class="type">bool</span> changed = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int32_t</span> node : cycle_detector_.<span class="built_in">AllNodesInPostOrder</span>()) &#123;</span><br><span class="line">  Cluster* cluster_from = <span class="built_in">GetClusterForCyclesGraphNode</span>(node);</span><br><span class="line">  <span class="comment">// Make a copy of the set of successors because we may modify the graph in</span></span><br><span class="line">  <span class="comment">// TryToContractEdge.</span></span><br><span class="line">  <span class="comment">// 可能在TryToContractEdge函数中修改后续的node，所以这里需要拷贝一份</span></span><br><span class="line">  std::vector&lt;<span class="type">int32_t</span>&gt; successors_copy =</span><br><span class="line">      cycle_detector_.<span class="built_in">SuccessorsCopy</span>(cluster_from-&gt;<span class="built_in">cycles_graph_node_id</span>());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 对该节点的后续分别尝试做融合</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> to : successors_copy) &#123;</span><br><span class="line">    Cluster* cluster_to = <span class="built_in">GetClusterForCyclesGraphNode</span>(to);</span><br><span class="line">    <span class="comment">// 这里传入的fn是TryToContractEdge函数，传入cluster_from和cluster_to两个参数，通过std::bind绑定。</span></span><br><span class="line">    <span class="type">bool</span> contracted_edge = <span class="built_in">fn</span>(cluster_from, cluster_to);</span><br><span class="line">    changed |= contracted_edge;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> changed;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该逻辑是，后续访问每个node，并尝试对后续的每个op尝试引用fn函数，即<code>TryToContractEdge</code>函数。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// This function check if fusing `from` with `to` is valid and if so perform</span></span><br><span class="line"><span class="comment">// the merge. The validity is based on the operations in the clusters and</span></span><br><span class="line"><span class="comment">// the compatibility of the shapes of the outputs of the would-be fused</span></span><br><span class="line"><span class="comment">// clusters.</span></span><br><span class="line"><span class="comment">// Returns true is the merge was performed.</span></span><br><span class="line"><span class="comment">// 尝试合并两个cluster，如果合并成功则返回true</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">TryToContractEdge</span><span class="params">(Cluster* from, Cluster* to)</span> </span>&#123;</span><br><span class="line"><span class="type">int</span> node_to = to-&gt;<span class="built_in">cycles_graph_node_id</span>();</span><br><span class="line"><span class="type">int</span> node_from = from-&gt;<span class="built_in">cycles_graph_node_id</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Both node_to and node_from should be fusible</span></span><br><span class="line"><span class="keyword">if</span> (!<span class="built_in">IsFusible</span>(op_list_[node_to]) || !<span class="built_in">IsFusible</span>(op_list_[node_from])) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判断node from是否可以和consumer融合</span></span><br><span class="line"><span class="comment">// 即该node是否是const或是elementwise</span></span><br><span class="line"><span class="keyword">if</span> (!<span class="built_in">IsFusibleWithConsumer</span>(op_list_[node_from])) &#123;</span><br><span class="line">  <span class="comment">// This op cannot be fused with its consumers.</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判断node to是否可以和operand融合</span></span><br><span class="line"><span class="comment">// 即该node是否是element wise或是const或是reduce</span></span><br><span class="line"><span class="keyword">if</span> (!<span class="built_in">IsFusibleWithOperand</span>(op_list_[node_to])) &#123;</span><br><span class="line">  <span class="comment">// This op cannot be fused with its operands.</span></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Output shapes of a fusion pattern should be compatible as described in</span></span><br><span class="line"><span class="comment">// the document of this class.</span></span><br><span class="line"><span class="comment">// 判断两个cluster的输出是否shape相同</span></span><br><span class="line">SmallVector&lt;Value, <span class="number">4</span>&gt; results = <span class="built_in">GetResultsOfFusedPattern</span>(from, to);</span><br><span class="line"></span><br><span class="line">Value ref = <span class="built_in">InferEffectiveWorkloadShape</span>(results[<span class="number">0</span>]);</span><br><span class="line"><span class="keyword">if</span> (!llvm::<span class="built_in">all_of</span>(results, [&amp;](Value result) &#123;</span><br><span class="line">      Value val = <span class="built_in">InferEffectiveWorkloadShape</span>(result);</span><br><span class="line">      <span class="keyword">return</span> shape_analysis_.<span class="built_in">HasSameShape</span>(ref, val);</span><br><span class="line">    &#125;)) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实际的fusion操作，将cluster做fusion</span></span><br><span class="line"><span class="keyword">return</span> <span class="built_in">MergeClusters</span>(from, to);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意，如果op是reduceOp，则其只能是to，不能是from，所以<code>reduceOp</code>一定在sub graph的end point。</p>
<ul>
<li><p>判断from和to是否可fuse：isfusable()</p>
</li>
<li><p><code>GetResultsOfFusedPattern</code>：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// returns the outputs if two cluster were merged</span></span><br><span class="line"><span class="function">SmallVector&lt;Value, 4&gt; <span class="title">GetResultsOfFusedPattern</span><span class="params">(Cluster* from, Cluster* to)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 将两个cluster的fused_pattern合并</span></span><br><span class="line">FusionPattern fused_pattern =</span><br><span class="line">    <span class="built_in">MergeFusionPattern</span>(from-&gt;<span class="built_in">fused_pattern</span>(), to-&gt;<span class="built_in">fused_pattern</span>());</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">GetOutputsOfFusionPattern</span>(fused_pattern);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>尝试强行融合两个cluster的pattern，并获取一个fusion厚的output。</p>
</li>
<li><p>显示做shape 判断，来判断前一步的fusion是否是合法的：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">Value ref = <span class="built_in">InferEffectiveWorkloadShape</span>(results[<span class="number">0</span>]);</span><br><span class="line"><span class="keyword">if</span> (!llvm::<span class="built_in">all_of</span>(results, [&amp;](Value result) &#123;</span><br><span class="line">      Value val = <span class="built_in">InferEffectiveWorkloadShape</span>(result);</span><br><span class="line">      <span class="keyword">return</span> shape_analysis_.<span class="built_in">HasSameShape</span>(ref, val);</span><br><span class="line">    &#125;)) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个inferworkload逻辑如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 根据value的类型，判断workload的shape的推导方式</span></span><br><span class="line"><span class="comment">// 主要针对reduce op做特殊化处理</span></span><br><span class="line"><span class="function">Value <span class="title">InferEffectiveWorkloadShape</span><span class="params">(Value v)</span> </span>&#123;</span><br><span class="line">  Operation* op = v.<span class="built_in">getDefiningOp</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 如果是reduce op，则返回operand的shape</span></span><br><span class="line">  <span class="comment">// 否则，v本身用于推导shape</span></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">isa_and_nonnull</span>&lt;ReduceOp&gt;(op) ? op-&gt;<span class="built_in">getOperand</span>(<span class="number">0</span>) : v;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>取融合后第一个输出的“有效工作负载形状”作为参考。</li>
<li><p>对普通操作，有效形状即输出本身的形状；对 <code>ReduceOp</code>，有效形状是操作数的形状（因为融合需基于其输入数据的形状）。</p>
</li>
<li><p>对融合后的所有输出结果，逐一检查它们的有效形状是否与参考形状一致。</p>
</li>
<li>若存在任意一个输出形状不匹配，返回 <code>false</code>，拒绝合并。</li>
</ul>
<p>这背后的原理如下:</p>
<blockquote>
<p><strong>kLoop 融合</strong>：要求所有输出形状一致，以放入同一并行循环。</p>
<p><strong>kInput 融合</strong>：</p>
<p>允许包含 <code>ReduceOp</code>，但其有效形状需与其他输出的有效形状一致（即 <code>ReduceOp</code> 的输入形状需与其他输出形状一致）。例如，若融合模式包含一个reduceOp和elementwiseOp，做如下操作：</p>
<ol>
<li><p><code>ReduceOp</code> 的有效形状是其输入（操作数）的形状。</p>
</li>
<li><p><code>ElementWise</code> 的有效形状是其输出的形状。</p>
</li>
<li><p>两者必须相同才能融合。</p>
</li>
</ol>
</blockquote>
</li>
</ul>
<p><img src="/images/3.png" alt="3"></p>
<h4 id="ApplyFusionPlan"><a href="#ApplyFusionPlan" class="headerlink" title="ApplyFusionPlan"></a>ApplyFusionPlan</h4><p>源码如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">ApplyFusionPlan</span><span class="params">(<span class="type">const</span> FusionPlan&amp; plan)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 遍历每个融合模式</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> FusionPattern&amp; pattern : plan) &#123;</span><br><span class="line">        <span class="comment">// 在pattern最后一个操作位置创建Builder</span></span><br><span class="line">        <span class="function">OpBuilder <span class="title">b</span><span class="params">(pattern.back())</span></span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 收集所有操作的位置信息</span></span><br><span class="line">        SmallVector&lt;Location, <span class="number">4</span>&gt; locations;</span><br><span class="line">        locations.<span class="built_in">reserve</span>(pattern.<span class="built_in">size</span>());</span><br><span class="line">        <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">            locations.<span class="built_in">push_back</span>(op-&gt;<span class="built_in">getLoc</span>());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 创建融合位置标识（用于调试）</span></span><br><span class="line">        Location fused_loc = FusedLoc::<span class="built_in">get</span>(pattern.<span class="built_in">back</span>()-&gt;<span class="built_in">getContext</span>(), locations);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取外部输入和输出</span></span><br><span class="line">        SmallVector&lt;Value, <span class="number">4</span>&gt; inputs = <span class="built_in">GetInputsOfFusionPattern</span>(pattern);</span><br><span class="line">        SmallVector&lt;Value, <span class="number">4</span>&gt; outputs = <span class="built_in">GetOutputsOfFusionPattern</span>(pattern);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 构建输出类型列表</span></span><br><span class="line">        SmallVector&lt;Type, <span class="number">4</span>&gt; output_types;</span><br><span class="line">        output_types.<span class="built_in">reserve</span>(outputs.<span class="built_in">size</span>());</span><br><span class="line">        <span class="keyword">for</span> (Value v : outputs) &#123;</span><br><span class="line">            output_types.<span class="built_in">push_back</span>(v.<span class="built_in">getType</span>());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 消费者调整阶段 */</span></span><br><span class="line">        <span class="comment">// 记录融合操作集合</span></span><br><span class="line">        <span class="function">DenseSet&lt;Operation*&gt; <span class="title">fused_set</span><span class="params">(pattern.begin(), pattern.end())</span></span>;</span><br><span class="line">        DenseSet&lt;Operation*&gt; consumers_set;  <span class="comment">// 已处理的消费者</span></span><br><span class="line">        SmallVector&lt;Operation*, <span class="number">4</span>&gt; consumers_vec; <span class="comment">// 待移动的消费者</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 确定原始代码范围：第一个融合操作到最后一个的迭代器范围</span></span><br><span class="line">        <span class="keyword">auto</span> first_iter = pattern.<span class="built_in">front</span>()-&gt;<span class="built_in">getIterator</span>();</span><br><span class="line">        <span class="keyword">auto</span> last_iter = pattern.<span class="built_in">back</span>()-&gt;<span class="built_in">getIterator</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 扫描区间内的所有操作</span></span><br><span class="line">        <span class="keyword">for</span> (Operation&amp; cur_op : llvm::<span class="built_in">make_range</span>(first_iter, last_iter)) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!fused_set.<span class="built_in">contains</span>(&amp;cur_op)) &#123; <span class="comment">// 非融合操作</span></span><br><span class="line">                <span class="comment">// 检查是否是消费者：操作数来自融合集或已标记的消费者</span></span><br><span class="line">                <span class="type">bool</span> is_consumer = llvm::<span class="built_in">any_of</span>(cur_op.<span class="built_in">getOperands</span>(), </span><br><span class="line">                    [&amp;](Value v) &#123;</span><br><span class="line">                        Operation* def_op = v.<span class="built_in">getDefiningOp</span>();</span><br><span class="line">                        <span class="keyword">return</span> fused_set.<span class="built_in">contains</span>(def_op) || consumers_set.<span class="built_in">contains</span>(def_op);</span><br><span class="line">                    &#125;);</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> (is_consumer) &#123;</span><br><span class="line">                    consumers_set.<span class="built_in">insert</span>(&amp;cur_op); <span class="comment">// 标记为已处理</span></span><br><span class="line">                    consumers_vec.<span class="built_in">push_back</span>(&amp;cur_op); <span class="comment">// 加入移动队列</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 逆序移动消费者到融合点之后（防止顺序移动导致迭代器失效）</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span>* op : llvm::<span class="built_in">reverse</span>(consumers_vec)) &#123;</span><br><span class="line">            op-&gt;<span class="built_in">moveAfter</span>(pattern.<span class="built_in">back</span>()); <span class="comment">// 重定位到融合操作末尾</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 创建融合操作 */</span></span><br><span class="line">        FusionOp fusion = b.<span class="built_in">create</span>&lt;mhlo::FusionOp&gt;(fused_loc, output_types, inputs);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 构建融合计算区域</span></span><br><span class="line">        Region&amp; region = fusion.<span class="built_in">fused_computation</span>();</span><br><span class="line">        region.<span class="built_in">push_back</span>(<span class="keyword">new</span> Block); <span class="comment">// 创建基本块</span></span><br><span class="line">        Block&amp; block = region.<span class="built_in">front</span>();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 将原始操作移入融合区域</span></span><br><span class="line">        <span class="keyword">for</span> (Operation* op : pattern) &#123;</span><br><span class="line">            op-&gt;<span class="built_in">moveBefore</span>(&amp;block, block.<span class="built_in">end</span>()); <span class="comment">// 保持原有顺序</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 在区域末尾插入ReturnOp</span></span><br><span class="line">        b.<span class="built_in">setInsertionPoint</span>(&amp;block, block.<span class="built_in">end</span>());</span><br><span class="line">        b.<span class="built_in">create</span>&lt;mhlo::ReturnOp&gt;(fused_loc, outputs);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 结果替换阶段 */</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> [output, fusion_result] : llvm::<span class="built_in">zip</span>(outputs, fusion.<span class="built_in">getResults</span>())) &#123;</span><br><span class="line">            <span class="comment">// 替换所有外部使用点</span></span><br><span class="line">            <span class="keyword">for</span> (OpOperand&amp; use : llvm::<span class="built_in">make_early_inc_range</span>(output.<span class="built_in">getUses</span>())) &#123;</span><br><span class="line">                <span class="keyword">if</span> (use.<span class="built_in">getOwner</span>()-&gt;<span class="built_in">getBlock</span>() != &amp;block) &#123; <span class="comment">// 外部使用</span></span><br><span class="line">                    use.<span class="built_in">set</span>(fusion_result); <span class="comment">// 替换为融合结果</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如下是<code>ApplyFusionPlan</code>的流程图</p>
<p><img src="/images/4.png" alt="4"></p>
<p>其中比较核心的是识别消费者操作，该consumer要求是直接或间接依赖fusion里的operation，但本身并不是fusion operation，并且其location在fusionOp的范围内，<strong>因此需要显示地移动</strong>。</p>
<p><img src="/images/4-1743436524621-10.png" alt="4"></p>
<h2 id="BladeDISC-source-code分析"><a href="#BladeDISC-source-code分析" class="headerlink" title="BladeDISC source code分析"></a><font color = brown>BladeDISC source code分析</font></h2><p><code>BladeDISC</code>的kernel 融合主要参考<code>AStitch</code>和<a href="http://arxiv.org/abs/2009.10924">titch fusion</a>。</p>
<p><img src="/images/image-20250326111430445.png" alt="4" style="zoom:67%;" /></p>
<p>上述很好地阐述了应用XLA和fusion stitich技术的差异。<font color = red>XLA编译器无法对middle reduce操作做fusion</font>，fusion stitch划分四类memory intensive op融合方式，起到有效扩展作用：</p>
<p><img src="/images/image-20250326114004653.png" style="zoom:67%;" /></p>
<h3 id="Source-code解读"><a href="#Source-code解读" class="headerlink" title="Source code解读"></a><font color = green>Source code解读</font></h3><p>一个总的框架：</p>
<p><img src="/images/image-20250327221745561.png" style="zoom:67%;" /></p>
<p>上述详情参考<a href="http://arxiv.org/abs/2009.10924">BladeDISC slide</a>。</p>
<h4 id="节点类型划分"><a href="#节点类型划分" class="headerlink" title="节点类型划分"></a>节点类型划分</h4><p>stich的fusion pattern中，相比xla，其重点是将node划分为不同的类：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Represents a list of lmhlo ops that are going to be fused.</span></span><br><span class="line"><span class="comment">// Concepts for a fusion pattern:</span></span><br><span class="line"><span class="comment">//   - Root op: the op whose output is the fusion-pattern&#x27;s output.</span></span><br><span class="line"><span class="comment">//     Sub-root op可以理解为stich fusion的缝合点，为用shared-memory缝合的op bound</span></span><br><span class="line"><span class="comment">//   - Sub-root op: the op whose output is to be maintained on shared-memory for</span></span><br><span class="line"><span class="comment">//     kStitch fusion. Currently, we only support row-reduction to be a sub-root</span></span><br><span class="line"><span class="comment">//     op.</span></span><br><span class="line"><span class="comment">//   - Regular xroot op: either a root op or a sub-root op, for whose operands</span></span><br><span class="line"><span class="comment">//     we successfully build tile information during kStitch fusion-pattern init</span></span><br><span class="line"><span class="comment">//     phase.</span></span><br><span class="line"><span class="comment">//   - Irregular xroot op: an root op for whose operands we fail to build tile</span></span><br><span class="line"><span class="comment">//     information durint kStitch fusion-pattern init phase.</span></span><br><span class="line"><span class="comment">//   - Skeleton op: the op who will be used to build the loop skeleton when</span></span><br><span class="line"><span class="comment">//     lowering a kStitch fusion to parallel loops. Currently, sub-root ops, and</span></span><br><span class="line"><span class="comment">//     regular xroot ops who generate external only results, are skeleton ops.</span></span><br><span class="line"><span class="comment">//     Other xroot ops are lowered with input-inline fusion phase.</span></span><br><span class="line"><span class="comment">//   Note: for an regular xroot op which is not an skeleton op, the output data</span></span><br><span class="line"><span class="comment">//     to be written should be coverred by its corresponding skeleton op.</span></span><br><span class="line"><span class="comment">//     Otherwise, this xroot are regared as irregular.</span></span><br></pre></td></tr></table></figure>
<p>上述注释中详细解读了node的分类：</p>
<ul>
<li>Root op：<code>fusion-pattern</code>的output node，即fusion的边界。</li>
<li>Sub-root op：通过shared-memory fuse的op。</li>
<li>xroot op：在astich论文中，每个op的thread感知分配信息，都是通过分析sub-root或是root，然后反向传播到整个fusion区域。xroot op是分析出thread信息的root或sub-root</li>
<li>Irregular xroot：没有分析出thread信息的sub root或是root op。</li>
<li>Skeleton op：负责构建<strong>动态shape的并行循环骨架</strong>，是GPU kernel代码生成的模板基础。通过选择具有典型计算特征的子根操作（如行归约）作为骨架，能够自动推导出循环维度、分块策略等关键参数。主要负责<strong>codegen</strong>部分。</li>
</ul>
<h4 id="Shape-analysis"><a href="#Shape-analysis" class="headerlink" title="Shape analysis"></a>Shape analysis</h4><h4 id="GPU-Stitch策略"><a href="#GPU-Stitch策略" class="headerlink" title="GPU Stitch策略"></a>GPU Stitch策略</h4><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 重点关注如何将stitch技术用在gpu上</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StitchGpuFusionStrategy</span> : <span class="keyword">public</span> FusionStrategy &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">StitchGpuFusionStrategy</span>(<span class="type">const</span> FusionOptions&amp; options)</span><br><span class="line">      : <span class="built_in">FusionStrategy</span>(options) &#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">isFusible</span><span class="params">(Operation* op)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">tryFuse</span><span class="params">(ShapeAnalysis&amp; shapeAnalysis, FusionPattern&amp; lhs,</span></span></span><br><span class="line"><span class="params"><span class="function">                       FusionPattern&amp; rhs, FusionPattern&amp; target)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">initFusionPattern</span><span class="params">(ShapeAnalysis&amp; shapeAnalysis,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 FusionPattern&amp; fusion_pattern)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> StringRef <span class="title">getName</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> <span class="string">&quot;StitchGpuFusionStrategy&quot;</span>; &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Value <span class="title">getEffectiveShape</span><span class="params">(FusionPattern&amp; target, Value value)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">tileCoverInfoPropagateO2I</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      ShapeAnalysis&amp; shapeAnalysis, DenseMap&lt;Value, TileInfo&gt;&amp; tile_plan,</span></span></span><br><span class="line"><span class="params"><span class="function">      Operation* op, SmallVector&lt;std::pair&lt;Value, TileInfo&gt;, <span class="number">4</span>&gt;&amp; in_info,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">bool</span>&amp; cover)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">findFusionPatternTypeAndSubroot</span><span class="params">(ShapeAnalysis&amp; shapeAnalysis,</span></span></span><br><span class="line"><span class="params"><span class="function">                                       FusionPattern&amp; fusion_pattern)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">tileXroots</span><span class="params">(ShapeAnalysis&amp; shapeAnalysis, FusionPattern&amp; fusion_pattern)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">backtraceTileAndCover</span><span class="params">(ShapeAnalysis&amp; shapeAnalysis,</span></span></span><br><span class="line"><span class="params"><span class="function">                             FusionPattern&amp; fusion_pattern, Value value)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>整体的流程框架如下：</p>
<p><img src="images/6.png" alt="6"></p>
<p>上述流程图很好的表达了整个流程框架：</p>
<ul>
<li><p><code>initFusionPatter</code>负责初始化fusion的option信息</p>
</li>
<li><p><code>findFusionPatternTypeAndSubroot</code>负责引用fusion，找寻subroot等特殊节点，其整体逻辑如下：</p>
<p><img src="/images/7.png" alt="7"></p>
</li>
<li><p><code>tileXroots</code>针对sub root做线程分配算法</p>
<p><img src="/images/8.png" alt="8"></p>
</li>
<li><p><code>backtraceTileAndCover</code>在一个fusion中，从不同sub root出发，做反向thread分配推导</p>
<p><img src="/images/9.png" alt="9"></p>
</li>
</ul>
<p>对应论文中的图片：</p>
<p><img src="/images/image-20250327184033247.png" alt="image-20250327184033247"></p>
<p>上述source code和论文中的对应描述参考论文中的chapter4.3的steps。</p>
]]></content>
      <categories>
        <category>编译技术</category>
        <category>机器学习编译</category>
        <category>访存优化</category>
      </categories>
      <tags>
        <tag>机器学习编译器</tag>
        <tag>mlir</tag>
        <tag>算子融合技术</tag>
      </tags>
  </entry>
  <entry>
    <title>tpu-mlir源码解读</title>
    <url>/2025/04/11/tpu-mlir%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
    <content><![CDATA[<p><img src="/images/image-20250411150531193.png" alt="image-20250411150531193"></p>
<span id="more"></span>
<blockquote>
<p>本博客主要学习TPU-MLIR的代码结构，mlir编程技术等。</p>
</blockquote>
<h2 id="多层级IR设计"><a href="#多层级IR设计" class="headerlink" title="多层级IR设计"></a><font color = brown>多层级IR设计</font></h2><h3 id="Interface设计"><a href="#Interface设计" class="headerlink" title="Interface设计"></a><font color = green>Interface设计</font></h3><h2 id="Pass优化设计"><a href="#Pass优化设计" class="headerlink" title="Pass优化设计"></a><font color = brown>Pass优化设计</font></h2><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><font color = brown>参考资料</font></h2><ol>
<li><a href="https://zhuanlan.zhihu.com/p/615180103">TPU-MLIR博客</a></li>
<li><a href="https://mlir.llvm.org/docs/Interfaces/">MLIR interface官方doc</a></li>
<li></li>
</ol>
]]></content>
      <categories>
        <category>编译技术</category>
        <category>机器学习编译</category>
        <category>TPU技术</category>
        <category>量化技术</category>
      </categories>
      <tags>
        <tag>机器学习编译器</tag>
        <tag>mlir</tag>
        <tag>异构计算系统</tag>
      </tags>
  </entry>
</search>
